<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>容灾备份 on INFINI Labs</title>
    <link>/docs/latest/console/reference/migration/</link>
    <description>Recent content in 容灾备份 on INFINI Labs</description>
    <generator>Hugo -- gohugo.io</generator><atom:link href="/docs/latest/console/reference/migration/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>数据迁移</title>
      <link>/docs/latest/console/reference/migration/migration/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/docs/latest/console/reference/migration/migration/</guid>
      <description>数据迁移 #  创建迁移任务 #  点击 INFINI Console 中左侧菜单 容灾备份》数据迁移，然后点击新建按钮创建迁移任务，如下图所示：
配置迁移集群 #  在源集群列表中选择集群 es-v5616, 在目标集群列表中选择集群 es-v7140
配置迁移索引 #  点击选择迁移索引按钮, 如下图：
这里我们选择了两个索引 test-10 和 test-15 ,然后点击确认
 选择索引的时候请确认目标集群相应索引是否创建好 mapping, setting 等元数据信息
 表格右方可以设置目标索引名称和文档 type，按需修改即可，这里我们将索引 test-10 重命名为 test-10-x, 将索引 test-15 重命名为 test-15-x，文档类型都重命名为 _doc。 选择完索引之后，点击下一步，进行迁移任务的数据范围设置和分区设置，如下图：
配置数据范围 #  如果需要过滤数据迁移，可以进行数据范围的设置，这里我们进行全量的数据迁移，就不设置了
配置数据分区 #  如果一个索引数据量特别大，可以进行数据分区的设置。数据分区根据设置的字段，以及分区步长将数据拆成多段，系统最终会将一个分段的数据作为一个子任务去运行，迁移数据， 这样的话即使，一个分段迁移过程出现异常，只需要重跑这个子任务。
数据分区设置目前支持按照日期类型字段（date）, 和数字类型 (number) 拆分分区，如上图所示，我们选择日期类型字段 now_widh_format 进行拆分分区，分区步长设置为 5分钟(5m), 然后点击预览按钮，可以看到根据设置拆分可以得到 8 个分区（文档数为0的分区最终不会生成子任务）。 根据预览信息确认分区设置无误之后，点击保存关闭分区设置并保存，然后点击下一步进行运行设置。
运行设置 #  一般情况下使用默认设置，然后执行节点选择网关实例 Dynamo，然后点击创建任务。</description>
    </item>
    
  </channel>
</rss>
