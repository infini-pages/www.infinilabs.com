'use strict';(function(){const indexCfg={encode:false,tokenize:function(str){return str.replace(/[\x00-\x7F]/g,'').split('');}};indexCfg.doc={id:'id',field:['title','content'],store:['title','href','section'],};const index=FlexSearch.create('balance',indexCfg);window.bookSearchIndex=index;index.add({'id':0,'href':'/docs/latest/gateway/references/filters/echo/','title':"echo",'section':"在线过滤器",'content':"echo #  描述 #  echo 过滤器是一个用于在返回结果里面输出指定字符信息的过滤器，常用于调试。\n功能演示 #    配置示例 #  一个简单的示例如下：\nflow: - name: hello_world filter: - echo: message: \u0026quot;hello infini\\n\u0026quot; echo 过滤器可以设置重复输出相同的字符的次数，示例如下：\n... - echo: message: \u0026quot;hello gateway\\n\u0026quot; repeat: 3 ... 参数说明 #     名称 类型 说明     message string 需要输出的字符内容   repeat int 重复次数   stdout bool 是否在终端也打印输出，默认为 false    "});index.add({'id':1,'href':'/docs/latest/gateway/','title':"INFINI Gateway",'section':"文档中心",'content':"极限网关 #  介绍 #  极限网关 (INFINI Gateway) 是一个面向 Elasticsearch 的高性能应用网关，它包含丰富的特性，使用起来也非常简单。极限网关工作的方式和普通的反向代理一样，我们一般是将网关部署在 Elasticsearch 集群前面， 将以往直接发送给 Elasticsearch 的请求都发送给网关，再由网关转发给请求到后端的 Elasticsearch 集群。因为网关位于在用户端和后端 Elasticsearch 之间，所以网关在中间可以做非常多的事情， 比如可以实现索引级别的限速限流、常见查询的缓存加速、查询请求的审计、查询结果的动态修改等等。\n了解更多  特性 #   极限网关是专为 Elasticsearch 而量身打造的应用层网关，地表最强，没有之一!\n  高可用，不停机索引，自动处理后端 Elasticsearch 的故障，不影响数据的正常摄取 写入加速，可自动合并独立的索引请求为批量请求，降低后端压力，提高索引效率 查询加速，可配置查询缓存，Kibana 分析仪表板的无缝智能加速，全面提升搜索体验 透明重试，自动处理后端 Elasticsearch 节点故障和对查询请求进行迁移重试 流量克隆，支持复制流量到多个不同的后端 Elasticsearch 集群，支持流量灰度迁移 一键重建，优化过的高速重建和增量数据的自动处理，支持新旧索引的透明无缝切换 安全传输，自动支持 TLS/HTTPS，可动态生成自签证书，也可指定自签可信证书 精准路由，多种算法的负载均衡模式，索引和查询可分别配置负载路由策略，动态灵活 限速限流，支持多种限速和限流测规则，可以实现索引级别的限速，保障后端集群的稳定性 并发控制，支持集群和节点级别的 TCP 并发连接数控制，保障后端集群和节点稳定性 无单点故障，内置基于虚拟 IP 的高可用解决方案，双机热备，故障自动迁移，避免单点故障 请求透视，内置日志和指标监控，可以对 Elasticsearch 请求做全面的数据分析  即刻开始  社区 #  谁在用? #  如果您正在使用极限网关，并且您觉得它还不错的话，请 告诉我们，所有的用户案例我们会集中放在 这里，感谢您的支持。\n"});index.add({'id':2,'href':'/docs/latest/gateway/overview/','title':"产品概述",'section':"INFINI Gateway",'content':"概述 #  介绍 #  极限网关（INFINI Gateway）是一个面向 Elasticsearch 的高性能应用网关，它包含丰富的特性，使用起来也非常简单。极限网关工作的方式和普通的反向代理一样，我们一般是将网关部署在 Elasticsearch 集群前面， 将以往直接发送给 Elasticsearch 的请求都发送给网关，再由网关转发给请求到后端的 Elasticsearch 集群。因为网关位于在用户端和后端 Elasticsearch 之间，所以网关在中间可以做非常多的事情， 比如可以实现索引级别的限速限流、常见查询的缓存加速、查询请求的审计、查询结果的动态修改等等。\n特性 #  极限网关 最懂 Elasticsearch，其在设计的时候就综合考虑了很多和 Elasticsearch 相关的业务场景及特点，基于此打造了很多完美契合 Elasticsearch 的众多非常实用的功能。\n轻量级 极限网关使用 Golang 编写，安装包很小，只有 10MB 左右，没有任何外部环境依赖，部署安装都非常简单，只需要下载对应平台的二进制可执行文件，启动网关程序的二进制程序文件执行即可。  极致性能 极限网关在编写每一行代码的时候，都会考虑如何让其运行在最佳状态，经测试，极限网关比同类主流网关类产品速度快 25% 以上，且针对 Elasticsearch 做了非常细致的优化，能成倍提升写入和查询的速度。   跨版本支持 极限网关针对不同的 Elasticsearch 版本做了兼容和针对性处理，能够让业务代码无缝的进行适配，后端 Elasticsearch 集群版本升级能够做到无缝过渡，降低版本升级和数据迁移的复杂度。  可观测性 极限网关可以动态对 Elasticsearch 运行过程中产生的任何请求进行截获和分析，通过指标和日志来了解整个集群的运行情况，用于提升性能和优化业务。还可以用于审计和慢查询分析。   高可用 极限网关内置多种高可用解决方案，前端请求入口支持基于虚拟 IP 的双机热备，后端集群支持集群拓扑的自动感知，节点上下线能自动发现，自动处理后端故障，自动进行请求的重试和迁移。  灵活可扩展 极限网关的每个模块都可以独立扩展，可灵活对每个请求进行干预和路由，支持路由的智能学习，内置丰富的过滤器，通过配置动态修改每个请求的处理逻辑，也支持通过插件来进行扩展。   无缝集成 #  极限网关对外提供的接口完全兼容 Elasticsearch 原生的接口，集成起来非常简单，只需将原本指向 Elasticsearch 的配置修改成网关的地址即可。\n为什么需要极限网关？ #  嗯，上面的集成交互图基本上看明白了，可我现在 Elasticsearch 用的好好的，我为什么需要在前面加上一个网关呢？\n好吧，如果您是一个稍微上了规模的 Elasticsearch 集群，不如试着想想下面的几个场景：\nWAF 与安全 #  相信您存储在 Elasticsearch 中的每一份数据都是很宝贵的，随着 Elasticsearch 的流行，它也正日益成为黑客们攻击的主要目标，WAF（Web Application Firewall）的需求应运而生。 不管是跨站脚本攻击还是跨站脚本注入，又或是弱密码、暴力破解，还是程序员不合理的查询参数滥用，极限网关都能对这些来自不同 Web 应用程序客户端的各类请求进行内容检测和验证， 通过执行一系列针对 Elasticsearch 的安全策略来确保其安全性与合法性，对非法的请求予以实时阻断，从而对后端 Elasticsearch 进行有效防护。\n集群升级 #  没错，相信您也知道 Elasticsearch 版本迭代的速度是非常快的，可能经常需要处理集群版本升级的事宜，而集群升级势必要考虑到以下几点：\n 保证最小的停机时间，业务的数据写入和查询不能因为集群的升级而中止，数据要能持续的进行写入，还不能因为后端重启节点而丢失数据 集群流量的切换，新旧集群在什么时候以及如何进行切换，是修改业务代码或者配置文件呢，以及如何回滚恢复呢，是不是需要重新发布一个新的部署包  借助极限网关，您的业务代码完全不用关心后端 Elasticsearch 集群是什么状况，只需要访问网关固定的地址即可，剩下的交给网关就都搞定了。\n索引重建 #  修改了 Mapping 需要重建索引，修改了分词词典需要重建索引，重建过程中还不能停止数据的写入，重建完成之后还要确保数据是一致的，有新增的数据和修改的数据也必须一一处理，自己处理起来貌似还挺麻烦。 而极限网关，可以做到一键索引重建，重建过程中的任何文档修改操作都会被自动记录，新旧索引在重建完成之后会自动无缝的进行切换，对于前端应用来说完全无感知。\n限流限速 #  有没有遇到过突发流量把集群打爆的情况，有没有遇到过个别大索引特别热闹把整个集群都连累的窘迫，其实您需要对异常的流量进行管理，这样才能保护整个 Elasticsearch 集群不会被异常的流量影响甚至是被恶意的攻击。 极限网关可以做到灵活的流量控制，可以做到索引级别的限速规则设置，一千个索引就有一千个哈姆雷特，完全没问题。\n查询太慢 #  极限网关内置缓存功能，能够将最常见的查询进行缓存，还可指定周期性的查询计划来预热特定的查询，保证前端的业务每次都能命中查询，从而提升查询速度，改进业务查询用户体验；\n索引太慢 #  极限网关可以将来自不同客户端的众多小批量的 Elasticsearch 索引请求合并成一个大的批次请求，通过精准的分片级别的路由，将索引请求合并封装直接投递到指定分片的指定节点上， 避免后端 Elasticsearch 再次进行请求转发，节省 Elasticsearch 资源和带宽，从而提升整体集群的吞吐和性能。\n请求干预 #  代码上线之后才发现查询语句写错了？有了极限网关，完全不用担心，可以在线对指定业务的指定查询进行改写，将查询语句动态修复，无需重新发布应用，方便灵活。或者您对 Elasticsearch 查询返回的 JSON 结果不满意， 也没关系，借助极限网关，您能够动态的替换查询结果为新的内容，甚至可以聚合来自其他数据源的数据，如 Hbase、MySQL 等等，融合成您需要的 JSON 数据再返回给客户端。\n请求分析 #  只知道有人抱怨 Elasticsearch 很慢，可您知道是 Elasticsearch 里面的哪些索引慢么？又是哪些查询造成的呢？ 又是哪些用户造成的呢？极限网关帮您全程跟踪，从集群到索引，从索引到查询，从应用到用户，让您对于 Elasticsearch 集群内的那点事情一清二楚。\n所以，用上极限网关之后您再用 Elasticsearch 将会变成是一件很爽的事情。\n架构 #  极限网关的核心模块见下面的架构图：\n负载外部请求代理的模块由四个主要部分组成，即：Entry、Router、Flow 和 Filter。一个 Entry 需要配置一个 Router，一个 Router 可以路由到多个 Flow，一个 Flow 由多个 Filter 组成。\nEntry #  Entry 模块主要定义网关的请求入口，极限网关支持 HTTP 和 HTTPS 两种模式，HTTPS 可以自动生成证书。\nRouter #  Router 模块主要定义请求的路由规则，根据 Method 和请求地址来进行路由到指定的 Flow 处理流程里面去。\nFlow #  Flow 模块主要定义数据的处理逻辑，每个请求会经过一系列的 Filter 操作，Flow 用来将这些 Filter 组织起来。\nFilter #  Filter 模块由若干个不同的 Filter 组件构成，每个 Filter 在设计的时候只处理一件事情，通过多个 Filter 组成变成一个 Flow。\nPipeline #  Pipeline 模块由若干个不同的 Processor 组件构成，通过多个 Processor 组成一个 Pipeline，Pipeline 和 Flow 相比，更侧重离线任务的处理。\nQueue #  Queue 模块是一个抽象的消息队列，如基于本地磁盘的可靠性消息持久化以及 Redis 和 Kafka 等适配器，根据不同的场景可以设置队列的不同后端适配器。\n此外，INFINI Gateway 使用的框架底层还有一些公共的模块，如：API 用来提供对外的编程入口，Elastic 模块用于处理不同版本的 Elasticsearch API 封装等等。\n接下来 #   查看 下载安装  "});index.add({'id':3,'href':'/docs/latest/console/reference/initialization/','title':"初始化向导",'section':"功能手册",'content':"初始化向导 #  简介 #  首次安装后打开系统，会进入初始化向导页面，在这里需要初始化一些配置，如系统集群、初始化默认用户等。\n配置 #  配置系统集群，elasticsearch 要求 7.3 或更高版本，用于存储相关数据。\n  TLS\n默认http，开启后为https。\n  Auth\n默认不需要连接认证，开启后，需要输入用户名\u0026amp;密码。\n    连接测试\n测试输入的连接配置，成功后即可进行下一步。\n  初始化 #  进入初始化步骤时，会校验集群中是否已存在旧数据，可以选择使用旧数据，也可以删除数据后再进行初始化。\n 存在旧数据  可以使用提示的脚本删除旧数据后，点击刷新，进入初始化默认用户\n也可以点击跳过，使用旧数据。\n  不存在旧数据\n将会直接进入初始化默认用户界面\n  完成 #  当初始化完成后，即可进入 Console 。\n"});index.add({'id':4,'href':'/docs/latest/console/reference/platform/overview/','title':"平台概览",'section':"平台管理",'content':"平台概览 #  简介 #  在平台概览里，可以查看集群、节点、索引、主机层面的主要指标，了解各层面的运行状态。\n集群 #  节点 #  索引 #  主机 #  主机数据来源于 INFINI Agent 数据上报和 Elasticsearch 节点发现。\n发现主机 #  点击主机列表右侧的按钮\u0026quot;Discover host\u0026quot;，勾选后，点击按钮\u0026quot;add hosts\u0026quot;即可添加主机到主机列表。\n"});index.add({'id':5,'href':'/docs/latest/console/','title':"INFINI Console",'section':"文档中心",'content':"INFINI Console #  介绍 #  INFINI Console 一款非常轻量级、功能强大的多集群、跨版本的 Elasticsearch 统一管控平台。 通过对 Elasticsearch 跨版本多集群的集中纳管，我们可以快速方便的对企业内部的所有 Elasticsearch 集群进行统一管理。\n架构 #  特性 #   INFINI Console 功能强大、轻量级、使用起来也非常简单。\n  支持多集群管理，可以在一个平台内同时纳管任意多套集群； 多版本 Elasticsearch 支持，支持 1.x、2.x、5.x、6.x、7.x、8.x； 支持以项目为单位来分组管理集群的元数据信息、支持标签； 支持动态注册添加集群，目标集群无需任何变动即可被接入管理； 支持统一的多集群层面、索引和 API 接口粒度的权限控制； 支持统一的跨集群的告警引擎，灵活配置基于阈值的告警规则； 支持查看集群元数据的历史变更信息，用于审计、追踪集群变化； 开发者工具支持多个工作区快速切换，支持智能提示，支持常用命令保存和快捷加载； 支持任意版本的集群监控，包括集群、节点、索引等详细维度的指标查看和分析； 支持索引的管理操作，支持索引的快速查看浏览，支持索引内文档的更新、删除； 支持创建索引数据视图，可以修改字段的展示格式，支持时序索引数据的快速查看； 支持跨平台部署环境，支持 MacOS(Intel 和 M1)、Windows(32位和64位)、Linux(32位和64位); 支持 x86、arm5、arm6、arm7、mips、mipsle、mips64 等 CPU 架构: 支持 Docker 容器和 K8s 云原生环境； 支持极限网关的集中管理；  INFINI Console 使用 Golang 编写，安装包很小，只有 11MB 左右，没有任何外部环境依赖，部署安装也都非常简单，只需要下载对应平台的二进制可执行文件，启动程序文件执行即可。\n即刻开始  系统截图 #  社区 #  谁在用? #  如果您正在使用 INFINI Console，并且您觉得它还不错的话，请 告诉我们，所有的用户案例我们会集中放在 这里，感谢您的支持。\n"});index.add({'id':6,'href':'/docs/latest/release-notes/','title':"Release notes",'section':"文档中心",'content':"INFINI release notes #  Find out what’s new in INFINI Search Platform! Release notes contain information about new features, improvements, known issues, and bug fixes in each release. You can find release notes for each component in the docs section. We suggest that you regularly visit the release notes to learn about updates.\n  INFINI Search  INFINI Gateway  INFINI Console  INFINI Agent  INFINI Loadgen  "});index.add({'id':7,'href':'/docs/latest/gateway/tutorial/log4j2_filtering/','title':"Apache Log4j 漏洞处置",'section':"动手教程",'content':"Apache Log4j 漏洞处置 #  【CVE 地址】\n https://github.com/advisories/GHSA-jfh8-c2jp-5v3q\n【漏洞描述】\nApache Log4j 是一款非常流行的开源的用于 Java 运行环境的日志记录工具包，大量的 Java 框架包括 Elasticsearch 的最新版本都使用了该组件，故影响范围非常之大。\n近日, 随着 Apache Log4j 的远程代码执行最新漏洞细节被公开，攻击者可通过构造恶意请求利用该漏洞实现在目标服务器上执行任意代码。可导致服务器被黑客控制，从而进行页面篡改、数据窃取、挖矿、勒索等行为。建议使用该组件的用户第一时间启动应急响应进行修复。\n简单总结一下就是，在使用 Log4j 打印输出的日志中，如果发现日志内容中包含关键词 ${，那么这个里面包含的内容会当做变量来进行替换和执行，导致攻击者可以通过恶意构造日志内容来让 Java 进程来执行任意命令，达到攻击的效果。\n【漏洞等级】：非常紧急\n此次漏洞是用于 Log4j2 提供的 lookup 功能造成的，该功能允许开发者通过一些协议去读取相应环境中的配置。但在实现的过程中，并未对输入进行严格的判断，从而造成漏洞的发生。\n【影响范围】：Java 类产品：Apache Log4j 2.x \u0026lt; 2.15.0-rc2\n【攻击检测】\n可以通过检查日志中是否存在 jndi:ldap://、jndi:rmi 等字符来发现可能的攻击行为。\n处理办法 #  如果 Elasticsearch 不能修改配置、或者替换 Log4j 的 jar 包和重启集群的，可以使用极限网关来进行拦截或者参数替换甚至是直接阻断请求。 通过在网关层对发往 Elasticsearch 的请求统一进行参数检测，将包含的敏感关键词 ${ 进行替换或者直接拒绝， 可以防止带攻击的请求到达 Elasticsearch 服务端而被 Log4j 打印相关日志的时候执行恶意攻击命令，从而避免被攻击。\n参考配置 #  下载最新的 1.5.0-SNAPSHOT 版本 http://release.elasticsearch.cn/gateway/snapshot/\n使用极限网关的 context_filter 过滤器，对请求上下文 _ctx.request.to_string 进行关键字检测，过滤掉恶意流量，从而阻断攻击。\npath.data: data path.logs: log entry: - name: es_entrypoint enabled: true router: default max_concurrency: 20000 network: binding: 0.0.0.0:8000 router: - name: default default_flow: main_flow flow: - name: main_flow filter: - context_filter: context: _ctx.request.to_string action: redirect_flow status: 403 flow: log4j_matched_flow must_not: # any match will be filtered regex: - \\$\\{.*?\\} - \u0026quot;%24%7B.*?%7D\u0026quot; #urlencode contain: - \u0026quot;jndi:\u0026quot; - \u0026quot;jndi:ldap:\u0026quot; - \u0026quot;jndi:rmi:\u0026quot; - \u0026quot;jndi%3A\u0026quot; #urlencode - \u0026quot;jndi%3Aldap%3A\u0026quot; #urlencode - \u0026quot;jndi%3Armi%3A\u0026quot; #urlencode - elasticsearch: elasticsearch: es-server - name: log4j_matched_flow filter: - echo: message: 'Apache Log4j 2, Boom!' elasticsearch: - name: es-server enabled: true endpoints: - http://localhost:9200 将测试命令 ${java:os} 使用 urlencode 转码为 %24%7Bjava%3Aos%7D\n不走网关：\n~% curl 'http://localhost:9200/index1/_search?q=%24%7Bjava%3Aos%7D' {\u0026quot;error\u0026quot;:{\u0026quot;root_cause\u0026quot;:[{\u0026quot;type\u0026quot;:\u0026quot;index_not_found_exception\u0026quot;,\u0026quot;reason\u0026quot;:\u0026quot;no such index\u0026quot;,\u0026quot;resource.type\u0026quot;:\u0026quot;index_or_alias\u0026quot;,\u0026quot;resource.id\u0026quot;:\u0026quot;index1\u0026quot;,\u0026quot;index_uuid\u0026quot;:\u0026quot;_na_\u0026quot;,\u0026quot;index\u0026quot;:\u0026quot;index1\u0026quot;}],\u0026quot;type\u0026quot;:\u0026quot;index_not_found_exception\u0026quot;,\u0026quot;reason\u0026quot;:\u0026quot;no such index\u0026quot;,\u0026quot;resource.type\u0026quot;:\u0026quot;index_or_alias\u0026quot;,\u0026quot;resource.id\u0026quot;:\u0026quot;index1\u0026quot;,\u0026quot;index_uuid\u0026quot;:\u0026quot;_na_\u0026quot;,\u0026quot;index\u0026quot;:\u0026quot;index1\u0026quot;},\u0026quot;status\u0026quot;:404}% 查看 Elasticsearch 端日志为：\n[2021-12-11T01:49:50,303][DEBUG][r.suppressed ] path: /index1/_search, params: {q=Mac OS X 10.13.4 unknown, architecture: x86_64-64, index=index1} org.elasticsearch.index.IndexNotFoundException: no such index at org.elasticsearch.cluster.metadata.IndexNameExpressionResolver$WildcardExpressionResolver.infe(IndexNameExpressionResolver.java:678) ~[elasticsearch-5.6.15.jar:5.6.15] at org.elasticsearch.cluster.metadata.IndexNameExpressionResolver$WildcardExpressionResolver.innerResolve(IndexNameExpressionResolver.java:632) ~[elasticsearch-5.6.15.jar:5.6.15] at org.elasticsearch.cluster.metadata.IndexNameExpressionResolver$WildcardExpressionResolver.resolve(IndexNameExpressionResolver.java:580) ~[elasticsearch-5.6.15.jar:5.6.15] 可以看到查询条件里面的 q=${java:os} 被执行了，变成了 q=Mac OS X 10.13.4 unknown, architecture: x86_64-64, index=index1\n走网关：\nmedcl@Medcl:~% curl 'http://localhost:8000/index1/_search?q=%24%7Bjava%3Aos%7D' Apache Log4j 2, Boom!% 可以看到请求被过滤到了。\n其他命令可以试试：\n#{java:vm} ~% curl 'http://localhost:9200/index/_search?q=%24%7Bjava%3Avm%7D' [2021-12-11T02:36:04,764][DEBUG][r.suppressed ] [Medcl-2.local] path: /index/_search, params: {q=OpenJDK 64-Bit Server VM (build 25.72-b15, mixed mode), index=index} ~% curl 'http://localhost:8000/index/_search?q=%24%7Bjava%3Avm%7D' Apache Log4j 2, Boom!% #{jndi:rmi://localhost:1099/api} ~% curl 'http://localhost:9200/index/_search?q=%24%7Bjndi%3Armi%3A%2F%2Flocalhost%3A1099%2Fapi%7D' 2021-12-11 03:35:06,493 elasticsearch[YOmFJsW][search][T#3] ERROR An exception occurred processing Appender console java.lang.SecurityException: attempt to add a Permission to a readonly Permissions object ~% curl 'http://localhost:8000/index/_search?q=%24%7Bjndi%3Armi%3A%2F%2Flocalhost%3A1099%2Fapi%7D' Apache Log4j 2, Boom!%  使用极限网关处置类似安全事件的好处是，Elasticsearch 服务器不用做任何变动，尤其是大规模集群的场景，可以节省大量的工作，提升效率，非常灵活，缩短安全处置的时间，降低企业风险。\n "});index.add({'id':8,'href':'/docs/latest/console/getting-started/install/','title':"下载安装",'section':"入门指南",'content':"安装 INFINI Console #  INFINI Console 支持主流的操作系统和平台，程序包很小，没有任何额外的外部依赖，安装起来应该是很快的 ：）\n安装前准备 #  准备一个可以存储数据的 Elasticsearch 集群，要求为 7.3 及以上版本，用于 INFINI Console 存储相关数据。\n下载安装 #  根据您所在的操作系统和平台选择下面相应的下载地址：\n https://release.infinilabs.com/console/\n容器部署 #  INFINI Console 也支持 Docker 容器方式部署。\n了解更多  配置 #  下载 INFINI Console 安装包解压之后，打开console.yml配置文件，我们可以看到 以下配置节：\n#存储 INFINI Console 相关数据的 Elasticsearch 集群信息，版本 v7.3+ elasticsearch: - name: default enabled: true monitored: true endpoint: http://192.168.3.188:9299 basic_auth: username: elastic password: ZBdkVQUUdF1Sir4X4BGB 一般情况下，我们只需要修改配置里面的 endpoint 配置，若 Elasticsearch 开启了安全验证，则需要修改 username 和 password 配置。\n这里的用户要求具备集群的元数据、索引的元数据以及 .infini* 索引的完全访问权限，以及索引模板的创建权限。\n关于索引模板的初始设置，请查看这里 了解更多。\n启动 INFINI Console #  直接运行程序即可启动 INFINI Console 了(这里使用的是 mac 版本的，不同平台的程序文件名称略有不同)，如下：\n➜ BOOTSTRAP_USERNAME=admin BOOTSTRAP_PASSWORD=123456 ./console-mac-amd64 ___ __ ___ ___ / __\\/ / /___\\/\\ /\\ / \\ / / / / // // / \\ \\/ /\\ / / /__/ /__/ \\_//\\ \\_/ / /_// \\____|____|___/ \\___/___,' ___ ___ __ __ ___ __ __ / __\\/___\\/\\ \\ \\/ _\\ /___\\/ / /__\\ / / // // \\/ /\\ \\ // // / /_\\ / /__/ \\_// /\\ / _\\ \\/ \\_// /__//__ \\____|___/\\_\\ \\/ \\__/\\___/\\____|__/ [CONSOLE] INFINI Cloud Console, The easiest way to operate your own elasticsearch platform. [CONSOLE] 0.3.0_SNAPSHOT, 2022-03-31 10:26:41, 2023-12-31 10:10:10, fa04f6010144b7c5267c71ccaee30230ddf2432d [03-31 20:27:40] [INF] [app.go:174] initializing console. [03-31 20:27:40] [INF] [app.go:175] using config: /Users/shiyang/infini/console-0.3.0_SNAPSHOT-447-mac-amd64/console.yml. [03-31 20:27:40] [INF] [instance.go:72] workspace: /Users/shiyang/infini/console-0.3.0_SNAPSHOT-447-mac-amd64/data/console/nodes/c92psf1pdamk8rdhgqpg [03-31 20:27:40] [INF] [app.go:283] console is up and running now. [03-31 20:27:40] [INF] [metrics.go:63] ip:192.168.3.12, host:shiyangdeMacBook-Pro.local, labels:, tags: [03-31 20:27:40] [INF] [elastic.go:136] loading [5] remote elasticsearch configs [03-31 20:27:40] [INF] [actions.go:280] elasticsearch [default] is available [03-31 20:27:40] [INF] [actions.go:280] elasticsearch [lsy_cluster_1] is available [03-31 20:27:40] [INF] [actions.go:280] elasticsearch [es-v710] is available [03-31 20:27:40] [INF] [actions.go:280] elasticsearch [es-v7140] is available [03-31 20:27:40] [INF] [ui.go:197] ui listen at: http://0.0.0.0:9000 [03-31 20:27:40] [INF] [module.go:116] all modules are started 看到上面的启动信息，说明 INFINI Console 已经成功运行了，并且监听了 9000 端口, 在浏览器里面访问 9000 端口就可以登陆使用了，初始的用户名和密码信息通过环境变量 BOOTSTRAP_USERNAME、BOOTSTRAP_PASSWORD 来进行设置。\n停止 INFINI Console #  如果需要停止 INFINI Console，按 Ctrl+C 即可停止 INFINI Console 平台，如下：\n^C [CONSOLE] got signal: interrupt, start shutting down [03-31 20:33:10] [INF] [module.go:145] all modules are stopped [03-31 20:33:10] [INF] [app.go:267] console now terminated. [CONSOLE] 0.3.0_SNAPSHOT, uptime: 5m30.307832s __ _ __ ____ __ _ __ __ / // |/ // __// // |/ // / / // || // _/ / // || // / /_//_/|_//_/ /_//_/|_//_/ ©INFINI.LTD, All Rights Reserved. 配置服务后台运行 #  如果希望将 INFINI Console 以后台任务的方式运行，如下：\n➜ ./console -service install Success ➜ ./console -service start Success 卸载服务也很简单，如下：\n➜ ./console -service stop Success ➜ ./console -service uninstall Success "});index.add({'id':9,'href':'/docs/latest/console/reference/agent/manage/manage/','title':"功能介绍",'section':"探针管理",'content':"功能介绍 #  简介 #  探针管理包括审核探针(INFINI Agent)、查看运行状态、分配任务等功能，是集中管理探针(INFINI Agent)的地方。 去安装探针\n审核探针 #  进入菜单探针管理 \u0026gt; 实例管理 点击按钮 Discover Agent。 可以看到待审核列表。选中对应 Agent 并点击 Add Agents 完成审核。\n删除探针 #  进入菜单探针管理 \u0026gt; 实例管理，在列表中点击对应列的删除，确认之后，探针即被删除。\n任务设置 #  任务设置，是指下发/取消采集数据的任务给探针。探针在收到任务前，会一直处于等待状态。进入菜单探针管理 \u0026gt; 实例管理，在对应Agent列，点击Task Setting，配置任务然后点击保存。\n"});index.add({'id':10,'href':'/docs/latest/gateway/tutorial/online_query_rewrite/','title':"在线查询修复的实现",'section':"动手教程",'content':"在线查询修复的实现 #  在某些情况下，您可能会碰到业务代码生成的 QueryDSL 存在不合理的情况，一般做法是需要修改业务代码并发布上线， 如果上线新版本需要很长的时间，比如没有到投产窗口，或者封网，又或者需要和其他的代码提交一起上线，往往意味着需要大量的测试， 而生产环境的故障要立马解决，客户不能等啊，怎么办？\n别着急，您可以使用极限网关来对查询进行动态修复。\n举个例子 #  比如下面的这个查询：\nGET _search { \u0026quot;size\u0026quot;: 1000000 , \u0026quot;explain\u0026quot;: true } 参数 size 设置的太大了，刚开始没有发现问题，随着数据越来越多，返回的数据太多势必会造成性能的急剧下降， 另外参数 explain 的开启也会造成不必要的性能开销，一般只在开发调试的时候才会用到这个功能。\n通过在网关里面增加一个 request_body_json_set 过滤器，可以动态替换指定请求体 JSON PATH 的值，上面的例子对应的配置如下：\nflow: - name: rewrite_query filter: - request_body_json_set: path: - explain -\u0026gt; false - size -\u0026gt; 10 - dump_request_body: - elasticsearch: elasticsearch: dev 通过重新设置 explain 和 size 参数，现在我们查询发给 Elasticsearch 前会被改写成如下格式：\n{ \u0026quot;size\u0026quot;: 10, \u0026quot;explain\u0026quot;: false } 成功修复线上问题。\n再举个例子 #  看下面的这个查询，编写代码的程序员写错了需要查询的字段名，应该是 name，但是写成了 name1，参数 size 也设置的特别大，如下：\nGET medcl/_search { \u0026quot;aggs\u0026quot;: { \u0026quot;total_num\u0026quot;: { \u0026quot;terms\u0026quot;: { \u0026quot;field\u0026quot;: \u0026quot;name1\u0026quot;, \u0026quot;size\u0026quot;: 1000000 } } } } 然后，系统居然上线了，这不查询就出问题了嘛。 哎，别着急，在网关请求流程里面增加如下过滤器配置就行了：\nflow: - name: rewrite_query filter: - request_body_json_set: path: - aggs.total_num.terms.field -\u0026gt; \u0026quot;name\u0026quot; - aggs.total_num.terms.size -\u0026gt; 10 - size -\u0026gt; 0 - dump_request_body: - elasticsearch: elasticsearch: dev 上面的配置，我们通过请求体 JSON 的路径直接替换了其数据，并且新增了一个参数来不返回查询文档，因为只需要聚合结果就行了。\n再举个例子 #  用户的查询为：\n{ \u0026quot;query\u0026quot;:{ \u0026quot;bool\u0026quot;:{ \u0026quot;should\u0026quot;:[{\u0026quot;term\u0026quot;:{\u0026quot;isDel\u0026quot;:0}},{\u0026quot;match\u0026quot;:{\u0026quot;type\u0026quot;:\u0026quot;order\u0026quot;}}] }\t} } 现在希望将其中的 term 查询换成等价的 range 查询，即如下：\n{ \u0026quot;query\u0026quot;:{ \u0026quot;bool\u0026quot;:{ \u0026quot;should\u0026quot;:[{ \u0026quot;range\u0026quot;: { \u0026quot;isDel\u0026quot;: {\u0026quot;gte\u0026quot;: 0,\u0026quot;lte\u0026quot;: 0 }}},{\u0026quot;match\u0026quot;:{\u0026quot;type\u0026quot;:\u0026quot;order\u0026quot;}}] }\t} } 使用下面的配置即可：\nflow: - name: rewrite_query filter: - request_body_json_del: path: - query.bool.should.[0] - request_body_json_set: path: - query.bool.should.[1].range.isDel.gte -\u0026gt; 0 - query.bool.should.[1].range.isDel.lte -\u0026gt; 0 - dump_request_body: - elasticsearch: elasticsearch: dev 上面的配置，首先使用了一个 request_body_json_del 来删除查询 should 里面的第一个元素，也就是要替换掉的 Term 子查询， 然后现在只剩一个 Match 查询了，现在增加一个 Should 的子查询，新增下标的注意应该为 1，分别设置 Range 查询的各个属性即可。\n进一步完善 #  上面的例子都是直接替换查询，不过一般情况下，你可能还需要进行一个判断来决定是否进行替换，比如当 _ctx.request.body_json.query.bool.should.[0].term.isDel JSON 字段存在才进行替换，网关的 条件判断非常灵活如下，配置如下：\nflow: - name: cache_first filter: - if: and: - has_fields: ['_ctx.request.body_json.query.bool.should.[0].term.isDel'] then: - request_body_json_del: path: - query.bool.should.[0] - request_body_json_set: path: - query.bool.should.[1].range.isDel.gte -\u0026gt; 0 - query.bool.should.[1].range.isDel.lte -\u0026gt; 0 - dump_request_body: - elasticsearch: elasticsearch: dev 完美！\n"});index.add({'id':11,'href':'/docs/latest/console/reference/devtool/','title':"开发工具",'section':"功能手册",'content':"开发工具 #  简介 #  使用开发工具可以快速地编写和执行 Elasticsearch 查询以及其他的 elasticsearch API。 当开启安装验证后，所有的请求都会经过 API 级别权限校验\n打开开发工具 #  使用 Ctrl+Shift+O 快捷键打开或者在 console 右上角图标打开。\n执行请求快捷键 #  Command+Enter 或者 Ctrl+Enter\n多集群多 Tab 页支持 #  开发工具支持使用 Tab 页同时打开多个集群，即使是同一个集群，也可以打开多个，Tab页之间状态是独立的。 Tab 页默认使用集群名称作为标题，双击 Tab 页标题可以修改。 开发工具下方是一个状态栏，左侧是当前集群的健康状态、http 地址、版本信息， 右侧是 elasticsearch 接口请求的响应状态以及时长。\n查看请求头信息 #  当使用开发工具执行 elasticsearch 请求之后，可以在右侧点击 headers Tab页查看请求头信息。\n"});index.add({'id':12,'href':'/docs/latest/console/reference/data/','title':"数据管理",'section':"功能手册",'content':"数据管理 #  简介 #  INFINI Console 数据管理，可以让您无缝在不同的业务集群里面遨游，支持索引的常用管理操作，快速查看和浏览索引内的文档信息，就地进行文档的编辑和删除。同时支持创建数据视图，修改字段的展示格式，时序索引数据一键快速查看。\n"});index.add({'id':13,'href':'/docs/latest/console/reference/platform/monitoring/','title':"集群监控",'section':"平台管理",'content':"集群监控 #  简介 #  当注册的集群开启了监控之后，INFINI Console 会根据相应配置去目标集群定期采集数据， 包括集群、节点、索引层面的一些指标。然后在集群监控里面可以观测到这些指标，从而了解目标集群的运行状态。\n监控所需 Elasticsearch API 权限清单 #  _cluster/health，_cluster/stats，_cat/shards, /_nodes/\u0026lt;node_id\u0026gt;/stats _cat/indices, _stats, _cluster/state, _nodes, _alias, _cluster/settings\n开启集群监控 #  在集群注册或者修改集群配置的时候，可以看到如下界面\n可以看到有一个 Monitored 的开关，当这个开关打开时，代表当前集群是开启监控的。 集群注册的时候，默认是开启监控的。监控配置里面包括集群健康指标、集群指标、节点指标和索引指标， 并且可以分别设置是否开启和采集时间间隔。\n 以上是对单个集群的设置，在配置文件console.yaml中可以设置对所有集群的监控启停，默认情况下可以看到配置文件中有如下配置：\nmetrics: enabled: true major_ip_pattern: \u0026quot;192.*\u0026quot; queue: metrics elasticsearch: enabled: true cluster_stats: true node_stats: true index_stats: true 如果 metrics\u0026gt;enable 设置为 false, 那么所有的集群监控都是没有开启的； 如果 metrics\u0026gt;elasticsearch\u0026gt;cluster_stats\u0026gt;enabled 设置为 false，那么所有的 集群就不会采集集群层面的相关指标。\n 查看集群指标监控 #  开启监控之后，在 INFINI Console 左侧菜单平台管理下面的监控报表里可以查看集群的监控信息，如下：\n点击高级 tab 页查看集群层面更多的指标；\n如图所示，可以指定一个集群的多个节点查看节点相关指标，横向对比。 默认显示 top 5 的节点指标（ top 5 节点是根据最近15分钟节点的查询 qps 和写入 qps 之和计算）。 这里切换到索引 tab 页也可以指定几个查看索引的相关指标，和节点类似。 切换到线程池 tab 页查看节点线程池的相关指标。\n查看节点指标监控 #  点击节点 tab 页查看集群节点列表。\n列表中点击节点名称查看指定节点的监控\n这里可以查看单个节点的指标监控信息和相关分片信息\n查看索引指标监控 #  点击索引 tab 页查看集群索引列表。\n列表中点击节点名称查看指定索引的监控\n这里可以查看单个节点的指标监控信息和相关分片信息\n"});index.add({'id':14,'href':'/docs/latest/console/reference/system/security/user/','title':"用户管理",'section':"安全设置",'content':"用户管理 #  简介 #  用户管理包括对用户的增删改查操作以及重置用户密码.\n创建用户 #   用户名是必填的并且需要唯一，作为登录账号名. 昵称, 手机号, 邮箱都是可选的. 给用户分配一个或者多个角色. 用户标签是可选的，可用于给用户分组.  查询用户 #  输入关键字，点击搜索按钮查询用户\n更新用户 #  按需修改，点击保存按钮保存\n重置用户密码 #  输入新密码点击保存按钮重置密码\n"});index.add({'id':15,'href':'/docs/latest/console/reference/agent/install/install/','title':"下载安装",'section':"探针管理",'content':"安装探针(INFINI Agent) #   探针(INFINI Agent) 是 INFINI Console 的子模块，负责数据抓取和 Elasticsearch 实例管理等任务，接受 Console 权限控制和统一的任务调度。 支持主流的操作系统和平台，程序包很小，没有任何额外的外部依赖。  安装前准备 #  安装并运行 INFINI Console\n下载安装 #  根据您所在的操作系统和平台选择下面相应的下载地址：\n https://release.infinilabs.com/agent/\n容器部署 #  探针(INFINI Agent) 也支持 Docker 容器方式部署。\n了解更多  配置 #  下载 探针(INFINI Agent) 安装包解压之后，打开agent.yml配置文件，我们可以看到以下配置：\n#存储 INFINI Agent 相关数据的 Elasticsearch 集群信息，版本 v7.3+ #此处的 endpoint 需和 INFINI Console 的一致 elasticsearch: - name: default enabled: true monitored: false endpoint: http://192.168.3.4:9200 basic_auth: username: elastic password: ZBdkVQUUdF1Sir4X4BGB ... #INFINI Console的地址 agent.manager.endpoint: http://192.168.3.4:9000 通常，我们只需要修改配置里面的 endpoint 配置，若 Elasticsearch 开启了安全验证，则需要修改 username 和 password 配置。\n这里的用户要求具备集群的元数据、索引的元数据以及 .infini* 索引的完全访问权限，以及索引模板的创建权限。\n启动 INFINI Agent #  直接运行程序即可启动 探针(INFINI Agent) 了(这里使用的是 Mac 版本的，不同平台的程序文件名称略有不同)，如下：\n _ ___ __ __ _____ /_\\ / _ \\ /__\\/\\ \\ \\/__ \\ //_\\\\ / /_\\//_\\ / \\/ / / /\\/ / _ \\/ /_\\\\//__/ /\\ / / / \\_/ \\_/\\____/\\__/\\_\\ \\/ \\/ [AGENT] A light-weight, powerful and high-performance elasticsearch agent. [AGENT] 0.1.0#14, 2022-08-26 14:09:29, 2025-12-31 10:10:10, 4489a8dff2b68501a0dd9ae15276cf5751d50e19 [08-31 15:52:07] [INF] [app.go:164] initializing agent. [08-31 15:52:07] [INF] [app.go:165] using config: /Users/INFINI/agent/agent-0.1.0-14-mac-arm64/agent.yml. [08-31 15:52:07] [INF] [instance.go:72] workspace: /Users/INFINI/agent/agent-0.1.0-14-mac-arm64/data/agent/nodes/cc7h5qitoaj25p2g9t20 [08-31 15:52:07] [INF] [metrics.go:63] ip:192.168.3.22, host:INFINI-MacBook.local, labels:, tags: [08-31 15:52:07] [INF] [api.go:261] api listen at: http://0.0.0.0:8080 [08-31 15:52:07] [INF] [module.go:116] all modules are started [08-31 15:52:07] [INF] [manage.go:180] register agent to console [08-31 15:52:07] [INF] [actions.go:367] elasticsearch [default] is available [08-31 15:52:07] [INF] [manage.go:203] registering, waiting for review [08-31 15:52:07] [INF] [app.go:334] agent is up and running now. 看到上面的启动信息，说明 探针(INFINI Agent) 已经成功运行了!\n但此时 探针(INFINI Agent) 处于等待审核的状态，并不能做任何事情。 去审核吧\n停止 INFINI Agent #  如果需要停止 探针(INFINI Agent) ，按 Ctrl+C 即可停止 探针(INFINI Agent)，如下：\n^C [AGENT] got signal: interrupt, start shutting down [08-31 15:57:13] [INF] [module.go:145] all modules are stopped [08-31 15:57:13] [INF] [app.go:257] agent now terminated. [AGENT] 0.1.0, uptime: 5m6.240314s __ _ __ ____ __ _ __ __ / // |/ // __// // |/ // / / // || // _/ / // || // / /_//_/|_//_/ /_//_/|_//_/ ©INFINI.LTD, All Rights Reserved. 配置服务后台运行 #  如果希望将 探针(INFINI Agent) 以后台任务的方式运行，如下：\n➜ ./agent -service install Success ➜ ./agent -service start Success 卸载服务也很简单，如下：\n➜ ./agent -service stop Success ➜ ./agent -service uninstall Success "});index.add({'id':16,'href':'/docs/latest/console/reference/agent/install/docker/','title':"容器部署",'section':"探针管理",'content':"容器部署 #  探针(INFINI Agent) 支持容器方式部署。\n下载镜像 #  探针(INFINI Agent) 的镜像发布在 Docker 的官方仓库，地址如下：\n https://hub.docker.com/r/infinilabs/agent\n使用下面的命令即可获取最新的容器镜像：\ndocker pull infinilabs/agent:latest 验证镜像 #  将镜像下载到本地之后，可以看到 探针(INFINI Agent) 的容器镜像非常小，只有不到 20MB，所以下载是非常快的。\n✗ docker images REPOSITORY TAG IMAGE ID CREATED SIZE infinilabs/agent latest c7bd9ad063d9 4 days ago 13.8MB 创建配置 #  现在需要创建一个配置文件 agent.yml，来进行基本的配置，如下：\napi: enabled: true network: binding: 0.0.0.0:8080 metrics: enabled: true queue: metrics network: enabled: true summary: true details: true memory: metrics: - swap - memory disk: metrics: - ioqs - usage cpu: metrics: - idle - system - user - iowait - load elasticsearch: enabled: true agent_mode: true node_stats: true index_stats: true cluster_stats: true elasticsearch: - name: default enabled: true endpoint: http://192.168.3.4:9200 monitored: false discovery: enabled: true pipeline: - name: metrics_ingest auto_start: true keep_running: true processor: - json_indexing: index_name: \u0026quot;.infini_metrics\u0026quot; elasticsearch: \u0026quot;default\u0026quot; input_queue: \u0026quot;metrics\u0026quot; output_queue: name: \u0026quot;metrics_requests\u0026quot; label: tag: \u0026quot;metrics\u0026quot; worker_size: 1 bulk_size_in_mb: 10 - name: consume-metrics_requests auto_start: true keep_running: true processor: - bulk_indexing: bulk: compress: true batch_size_in_mb: 10 batch_size_in_docs: 5000 consumer: fetch_max_messages: 100 queues: type: indexing_merge when: cluster_available: [ \u0026quot;default\u0026quot; ] agent: major_ip_pattern: \u0026quot;192.*\u0026quot; labels: env: dev tags: - linux - x86 - es7 - v7.5 path.data: data path.logs: log agent.manager.endpoint: http://192.168.3.4:9000 Note: 上面配置里面的 Elasticsearch 的相关配置，请改成实际的服务器连接地址和认证信息，需要版本 v7.3 及以上。\n启动Agent #  使用如下命令启动Agent容器：\ndocker run -p 8080:8080 -v=`pwd`/agent.yml:/agent.yml infinilabs/agent:latest Docker Compose #  还可以使用 docker compose 来管理容器实例，新建一个 docker-compose.yml 文件如下：\nversion: \u0026quot;3.5\u0026quot; services: infini-agent: image: infinilabs/agent:latest ports: - 8080:8080 container_name: \u0026quot;infini-agent\u0026quot; volumes: - ./agent.yml:/agent.yml volumes: dist: 在配置文件所在目录，执行如下命令即可启动，如下：\n➜ docker-compose up Recreating infini-agent ... done Attaching to infini-agent infini-agent | _ ___ __ __ _____ infini-agent | /_\\ / _ \\ /__\\/\\ \\ \\/__ \\ infini-agent | //_\\\\ / /_\\//_\\ / \\/ / / /\\/ infini-agent | / _ \\/ /_\\\\//__/ /\\ / / / infini-agent | \\_/ \\_/\\____/\\__/\\_\\ \\/ \\/ infini-agent | infini-agent | [AGENT] A light-weight, powerful and high-performance elasticsearch agent. infini-agent | [AGENT] 0.1.0_SNAPSHOT#15, 2022-08-26 15:05:43, 2025-12-31 10:10:10, 164bd8a0d74cfd0ba5607352e125d72b46a1079e infini-agent | [08-31 09:11:45] [INF] [app.go:164] initializing agent. infini-agent | [08-31 09:11:45] [INF] [app.go:165] using config: /agent.yml. infini-agent | [08-31 09:11:45] [INF] [instance.go:72] workspace: /data/agent/nodes/cc7ibke5epac7314bf9g infini-agent | [08-31 09:11:45] [INF] [metrics.go:63] ip:172.18.0.2, host:bd9f43490911, labels:, tags: infini-agent | [08-31 09:11:45] [INF] [api.go:261] api listen at: http://0.0.0.0:8080 infini-agent | [08-31 09:11:45] [INF] [actions.go:367] elasticsearch [default] is available infini-agent | [08-31 09:11:45] [INF] [module.go:116] all modules are started infini-agent | [08-31 09:11:45] [INF] [manage.go:180] register agent to console infini-agent | [08-31 09:11:45] [INF] [app.go:334] agent is up and running now. "});index.add({'id':17,'href':'/docs/latest/console/reference/system/cluster/','title':"集群管理",'section':"系统管理",'content':"集群管理 #  简介 #  集群管理可以快速方便地帮助我们纳管跨版本的多个 Elasticsearch 集群。\n集群列表 #  在集群列表中可以查询注册的 Elasticsearch 集群\n集群注册 #  第一步填写集群地址，按需开启 TLS 和 身份验证（开启身份验证后需要输入用户名和密码）。\n第二步，信息确认\n 按需修改集群名称，集群描述； 是否开启监控（默认开启），启用监控之后可以在 console 监控功能里面查看 Elasticsearch 集群的各种指标 是否开启 Discovery（推荐开启） , 启用之后 console 会自动发现集群所有节点，当配置的集群地址不可用时，console 会尝试使用自动发现的其他节点中可用的地址和 Elasticsearch 交互  更新集群配置 #  点击集群列表表格中的编辑按钮，进入更新界面\n按需修改配置，然后点击保存按钮提交\n删除集群 #  点击集群列表表格中的删除按钮，进行二次确认，确认删除后执行删除操作。\n"});index.add({'id':18,'href':'/docs/latest/console/reference/alerting/message/','title':"告警中心",'section':"告警管理",'content':"告警中心 #  简介 #  消息中心默认展示的是当前系统内正在发生的告警事件，方便管理人员快速预览系统的执行状态。\n事件消息列表 #  消息列表聚合了所有已触发的告警事件，如每个告警规则重复触发了多次告警消息，这里只会聚合显示一条，点击详情就可以去看更多的信息。\n消息详情 #  点击消息列表行列中的详情按钮可以查看当前告警事件消息的详细内容，包含事件消息的基本信息，事件触发周期内的时序曲线图，规则执行检测历史记录等，如下图所示：\n忽略告警消息 #  如认为告警事件不需要做处理或者不重要，可以进行忽略操作，忽略后告警消息将不默认展在消息列表中，不过可以通过状态筛选过滤进行查询。\n操作步骤：点击消息列表表格中的忽略按钮，进行二次确认，填写忽略原因，提交后执行忽略操作。\n"});index.add({'id':19,'href':'/docs/latest/console/reference/system/command/','title':"常用命令",'section':"系统管理",'content':"常用命令 #  简介 #  常用命令用于在开发工具中将高频使用的 Elasticsearch 请求保存, 这样后续如果需要使用， 只需要在开发工具中使用 LOAD 命令加载，即可快速使用。\n保存常用命令 #  打开 console 右上角的开发工具(Ctrl+shift+o)， 在开发工具中选择需要保存的 Elasticsearch 请求 （支持一次选中多个请求保存为常用命令），选中之后点击工具栏里面的 Save As Command 提交。\n加载常用命令 #  在开发工具里，输入 LOAD + 保存的命令名称关键字 会自动提示相关已保存的常用命令， 选中要加载的命令后，按回车键即可自动加载相应的常用命令。\n常用命令列表 #  在常用命令列表中可以查询已经保存的常用命令\n点击在列表中常用命令名称一栏可以查看常用命令具体信息, 也可以修改名称和 tag 信息\n删除常用命令 #  点击常用命令列表中的删除按钮，进行二次确认，确认之后执行删除操作。\n"});index.add({'id':20,'href':'/docs/latest/console/reference/alerting/rule/','title':"告警规则",'section':"告警管理",'content':"告警规则 #  简介 #  告警规则包括数据源，指标定义，触发条件，消息通知四个部分的配置\n告警规则列表 #  在告警规则列表中可以查询已经添加的告警规则\n新建告警规则 #  在告警规则列表中点击新建按钮进入新建告警规则页面\n配置数据源 #   选择集群（必选） 选择索引，支持输入索引 pattern （必填） 输入 elasticsearch query DSL 查询过滤条件（可选） 选择时间字段（必选） 选择统计周期（用于时间字段聚合，默认一分钟）  配置告警指标以及触发条件 #   输入规则名称 按需添加分组的字段以及分组大小，可以添加多个，用于 terms 聚合 选择指标聚合字段以及统计类型，可以配置多个，当配置多个时必须配置公式用于计算最终的指标 配置告警触发条件 选择执行检查周期 输入告警事件标题（模版，被模版变量中的 title 引用，点击这里了解 模版语法 ） 输入告警事件消息（模版，被模版变量中的 message 引用，点击这里了解 模版语法 ）  配置消息通知 #   配置通知渠道，可以重新配置，也可以通过添加按钮选择已经创建好的渠道作为模版快速填充，并支持添加多个 按需选择是否开启通知升级 选择沉默周期（通知消息发送频率） 配置通知发送时间段 点击保存按钮提交  更新告警规则 #  在告警规则列表中选择需要更新的告警规则点击编辑按钮进入更新告警规则页\n删除告警规则 #  点击告警规则列表表格中的删除按钮，进行二次确认，确认删除后执行删除操作。\n常见规则模板一键导入 #  下面列举了一些常见告警规则，并且配置钉钉、企业微信、Slack等通知渠道，仅需要替换模板中指定的自定义变量，即可通过 Console 的 DevTools 工具快速导入规则。\n  Cluster Health Change to Red  Index Health Change to Red  Disk utilization is Too High  CPU utilization is Too High  JVM utilization is Too High  Shard Storage \u0026gt;= 55G  Elasticsearch node left cluster  Search latency is great than 500ms  Too Many Deleted Documents  "});index.add({'id':21,'href':'/docs/latest/console/tutorials/start_with_specify_user/','title':"如何指定内置账户名和密码启动 INFINI Console",'section':"动手教程",'content':"如何指定内置账户名和密码启动 INFINI Console #  准备 #   下载并安装最新版 INFINI Console 开启 INFINI Console 安全功能  INFINI Console 内置账户 #  INFINI Console 在开启安全的情况下，内置了一个管理员账户。 在不指定账户名和密码的情况下，INFINI Console 默认情况下内置账户的用户名和密码都是 admin。\n指定账户名和密码启动 INFINI Console #  INFINI Console 支持使用环境变量的方式指定账户名和密码启动，下面以 Macos 操作系统为例：\nBOOTSTRAP_USERNAME=admin BOOTSTRAP_PASSWORD=123456 ./console-mac-amd64\n禁用内置账户 #  由于使用内置账户，可能存在安全隐患，例如密码设置太简单等。因此当我们使用内置账户 登录 INFINI Console 创建新的管理员账号之后，可以使用新管理员账号登录，然后在 系统管理\u0026gt;安全设置 里面禁用内置账户。禁用之后就无法使用内置账户登录 INFINI Console了。\n创建管理员账户 #  INFINI Console 内置了一个管理员角色 Administrator，创建新用户的时候赋予这个角色，新用户就拥有管理员权限了。\n点击 INFINI Console 左侧菜单 系统管理》安全设置，选择用户 Tab 页进入账户管理页。然后点击新建按钮，进入创建用户页面\n 输入用户名 root 角色选择 Administrator 点击保存按钮提交 将保存成功后的初始密码保存下来备用  使用新建的管理员禁用内置用户 #  使用上一步创建好的 root 用户和密码登录 INFINI Console, 然后在 系统管理\u0026gt;安全设置 里面打开禁用内置账户开关，看到如下界面时表示操作成功。\n"});index.add({'id':22,'href':'/docs/latest/gateway/getting-started/install/','title':"安装网关",'section':"入门指南",'content':"安装网关 #  极限网关支持主流的操作系统和平台，程序包很小，没有任何额外的外部依赖，安装起来应该是很快的 ：）\n安装演示 #    下载安装 #  根据您所在的操作系统和平台选择下面相应的下载地址：\n https://release.infinilabs.com/\n容器部署 #  极限网关也支持 Docker 容器方式部署。\n了解更多  验证安装 #  极限网关下载解压之后，我们可以执行这个命令来验证安装包是否有效，如下：\n✗ ./bin/gateway -v gateway 1.0.0_SNAPSHOT 2021-01-03 22:45:28 6a54bb2 如果能够正常看到上面的版本信息，说明网关程序本身一切正常。\n启动网关 #  以管理员身份直接运行网关程序即可启动极限网关了，如下：\n➜ sudo ./bin/gateway ___ _ _____ __ __ __ _ / _ \\ /_\\ /__ \\/__\\/ / /\\ \\ \\/_\\ /\\_/\\ / /_\\///_\\\\ / /\\/_\\ \\ \\/ \\/ //_\\\\\\_ _/ / /_\\\\/ _ \\/ / //__ \\ /\\ / _ \\/ \\ \\____/\\_/ \\_/\\/ \\__/ \\/ \\/\\_/ \\_/\\_/ [GATEWAY] A light-weight, powerful and high-performance elasticsearch gateway. [GATEWAY] 1.0.0_SNAPSHOT, 4daf6e9, Mon Jan 11 11:40:44 2021 +0800, medcl, add response_header_filter [01-11 16:43:31] [INF] [instance.go:24] workspace: data/gateway/nodes/0 [01-11 16:43:31] [INF] [api.go:255] api server listen at: http://0.0.0.0:2900 [01-11 16:43:31] [INF] [runner.go:59] pipeline: primary started with 1 instances [01-11 16:43:31] [INF] [runner.go:59] pipeline: nodes_index started with 1 instances [01-11 16:43:31] [INF] [entry.go:262] entry [es_gateway] listen at: https://0.0.0.0:8000 [01-11 16:43:32] [INF] [floating_ip.go:170] floating_ip listen at: 192.168.3.234, echo port: 61111 [01-11 16:43:32] [INF] [app.go:254] gateway now started. 看到上面的启动信息，说明网关已经成功运行了，并且监听了响应的端口。\n访问网关 #  使用浏览器或者其它客户端即可正常访问由网关代理的后端 Elasticsearch 服务了，如下：\n停止网关 #  如果需要停止网关，按 Ctrl+C 即可停止极限网关，如下：\n^C [GATEWAY] got signal: interrupt, start shutting down [01-11 16:44:41] [INF] [app.go:303] gateway now terminated. [GATEWAY] 1.0.0_SNAPSHOT, uptime: 1m10.550336s Thanks for using GATEWAY, have a good day! 系统服务 #  如果希望将极限网关以后台任务的方式运行，如下：\n➜ ./gateway -service install Success ➜ ./gateway -service start Success 卸载服务也很简单，如下：\n➜ ./gateway -service stop Success ➜ ./gateway -service uninstall Success 到这里极限网关就已经安装好了，下一步我们来看如何配置极限网关。\n配置网关  "});index.add({'id':23,'href':'/docs/latest/gateway/references/entry/','title':"服务入口",'section':"功能手册",'content':"服务入口 #  定义入口 #  每一个网关都至少要对外暴露一个服务的入口，用来接收业务的操作请求，这个在极限网关里面叫做 entry，通过下面的参数即可定义：\nentry: - name: es_gateway enabled: true router: default network: binding: 0.0.0.0:8000 reuse_port: true tls: enabled: false 通过参数 network.binding 可以指定服务监听的 IP 和地址，极限网关支持端口重用，也就是多个极限网关共享一个相同的 IP 和端口，这样可以充分利用服务器的资源， 也能做到不同网关进程的动态配置修改（通过开启多个进程，修改配置之后，依次重启各个进程）而不会中断客户端的正常请求。\n每个发送到 entry 的请求都会通过 router 来进行流量的路由处理，router 在单独的地方定义规则，以方便在不同的 entry 间复用，entry 只需要通过 router 参数指定要使用的 router 规则即可，这里定义的是 default。\nTLS 配置 #  极限网关支持无缝开启 TLS 传输加密，只需要将 tls.enabled 设置成 true，即可直接切换为 HTTPS 的通信模式，极限网关能自动生成自签证书。\n极限网关也支持自定义证书路径，配置方式如下：\nentry: - name: es_gateway enabled: true router: default network: binding: 0.0.0.0:8000 reuse_port: true tls: enabled: true cert_file: /etc/ssl.crt key_file: /etc/ssl.key skip_insecure_verify: false 多个服务 #  极限网关支持一个网关监听多个不同的服务入口，各个服务入口的监听地址、协议和路由都可以分别定义，用来满足不同的业务需求，配置示例如下：\nentry: - name: es_ingest enabled: true router: ingest_router network: binding: 0.0.0.0:8000 - name: es_search enabled: true router: search_router network: binding: 0.0.0.0:9000 上面的例子，定义了一个名为 es_ingest 的服务入口，监听的地址是 0.0.0.0:8000，所有请求都通过 ingest_router 来进行处理。 另外一个 es_search 服务，监听端口是 9000，使用 search_router 来进行请求处理，可以实现业务的读写分离。 另外，对于不同的后端 Elasticsearch 集群也可以定义不同的服务入口，通过网关来进行请求的代理转发。\nIPv6 支持 #  极限网关支持绑定到 IPv6 地址，示例如下：\nentry: - name: es_ingest enabled: true router: ingest_router network: # binding: \u0026quot;[ff80::4e2:7fb6:7db6:a839%en0]:8000\u0026quot; binding: \u0026quot;[::]:8000\u0026quot; 参数说明 #     名称 类型 说明     name string 服务入口名称   enabled bool 是否启用该入口   max_concurrency int 最大的并发连接数，默认 10000   router string 路由名称   network object 网络的相关配置   tls object TLS 安全传输相关配置   network.host string 服务监听的网络地址，如：192.168.3.10   network.port int 服务监听的端口地址，如：8000   network.binding string 服务监听的网络绑定地址，如：0.0.0.0:8000   network.publish string 服务监听的对外访问地址，如：192.168.3.10:8000   network.reuse_port bool 是否重用网络端口，用于多进程端口共享   network.skip_occupied_port bool 是否自动跳过已占用端口   tls.enabled bool 是否启用 TLS 安全传输   tls.cert_file string TLS 安全证书公钥路径   tls.key_file string TLS 安全证书秘钥路径   tls.skip_insecure_verify bool 是否忽略 TLS 的证书校验    "});index.add({'id':24,'href':'/docs/latest/gateway/tutorial/request-logging/','title':"查询请求流量日志分析",'section':"动手教程",'content':"查询请求流量日志分析 #  极限网关能够跟踪记录经过网关的所有请求，可用来分析发送给 Elasticsearch 的请求情况，用于分析请求性能和了解业务运行情况。\n设置网关路由 #  如果需要开启极限网关的查询日志分析，需要在路由上面配置 tracing_flow 参数，设置一个流程来记录请求日志。\nrouter: - name: default tracing_flow: request_logging default_flow: cache_first 上面的配置定义了一个名为 default 的路由，默认的请求流程为 cache_first，用于日志记录的流程为 request_logging。\n定义日志流程 #  日志处理流程配置 request_logging 的定义如下：\nflow: - name: request_logging filter: - request_path_filter: must_not: # any match will be filtered prefix: - /favicon.ico - request_header_filter: exclude: - app: kibana # in order to filter kibana's access log, config `elasticsearch.customHeaders: { \u0026quot;app\u0026quot;: \u0026quot;kibana\u0026quot; }` to your kibana's config `/config/kibana.yml` - logging: queue_name: request_logging 上面的流程里面使用了若干个过滤器：\n request_path_filter 过滤了无用的 /favicon.ico 请求 request_header_filter，过滤了来自 Kibana 的请求 logging，将请求日志记录到本地磁盘队列 request_logging，供后续管道来消费并创建索引  定义日志管道 #  极限网关使用管道任务来异步消费这些日志，并创建索引，具体的定义配置如下：\npipeline: - name: request_logging_index auto_start: true keep_running: true processor: - json_indexing: index_name: \u0026quot;gateway_requests\u0026quot; elasticsearch: \u0026quot;dev\u0026quot; input_queue: \u0026quot;request_logging\u0026quot; idle_timeout_in_seconds: 1 worker_size: 1 bulk_size_in_mb: 10 #in MB 上面的配置里面，定义了一个名为 request_logging_index 的处理管道，设置了消费的磁盘队列名称 request_logging 和索引的目标集群 dev 和索引名 gateway_requests，使用了一个工作线程，批次提交大小为 10MB。\n定义索引集群 #  接下来配置索引集群，如下：\nelasticsearch: - name: dev enabled: true endpoint: https://192.168.3.98:9200 # if your elasticsearch is using https, your gateway should be listen on as https as well basic_auth: #used to discovery full cluster nodes, or check elasticsearch's health and versions username: elastic password: pass discovery: # auto discovery elasticsearch cluster nodes enabled: true refresh: enabled: true 上面的配置定义了一个名为 dev 的 Elasticsearch 集群，并且开启 Elastic 模块来处理集群的自动配置。\n配置索引模板 #  然后就可以配置 Elasticsearch 集群的索引模板了，在 dev 集群上执行下面的命令创建日志索引的模板。\n 展开查看 Elasticsearch 的模板定义 ...  PUT _template/.infini-gateway-default { \u0026quot;order\u0026quot;: 100000, \u0026quot;index_patterns\u0026quot;: [ \u0026quot;gateway_requests\u0026quot; ], \u0026quot;settings\u0026quot;: { \u0026quot;index\u0026quot;: { \u0026quot;max_result_window\u0026quot;: \u0026quot;10000000\u0026quot;, \u0026quot;number_of_shards\u0026quot;: \u0026quot;1\u0026quot; } }, \u0026quot;mappings\u0026quot;: { \u0026quot;dynamic_templates\u0026quot;: [ { \u0026quot;strings\u0026quot;: { \u0026quot;mapping\u0026quot;: { \u0026quot;ignore_above\u0026quot;: 256, \u0026quot;type\u0026quot;: \u0026quot;keyword\u0026quot; }, \u0026quot;match_mapping_type\u0026quot;: \u0026quot;string\u0026quot; } } ], \u0026quot;properties\u0026quot;: { \u0026quot;request\u0026quot;: { \u0026quot;properties\u0026quot;: { \u0026quot;body\u0026quot;: { \u0026quot;type\u0026quot;: \u0026quot;text\u0026quot; } } }, \u0026quot;response\u0026quot;: { \u0026quot;properties\u0026quot;: { \u0026quot;body\u0026quot;: { \u0026quot;type\u0026quot;: \u0026quot;text\u0026quot; } } } } }, \u0026quot;aliases\u0026quot;: {} }     配置索引生命周期 #   展开查看索引生命周期的定义 ...  PUT _ilm/policy/30days-retention { \u0026quot;policy\u0026quot;: { \u0026quot;phases\u0026quot;: { \u0026quot;hot\u0026quot;: { \u0026quot;min_age\u0026quot;: \u0026quot;0ms\u0026quot;, \u0026quot;actions\u0026quot;: { \u0026quot;rollover\u0026quot;: { \u0026quot;max_age\u0026quot;: \u0026quot;30d\u0026quot;, \u0026quot;max_size\u0026quot;: \u0026quot;50gb\u0026quot; }, \u0026quot;set_priority\u0026quot;: { \u0026quot;priority\u0026quot;: 100 } } }, \u0026quot;warm\u0026quot;: { \u0026quot;actions\u0026quot;: { \u0026quot;forcemerge\u0026quot;: { \u0026quot;max_num_segments\u0026quot;: 1 }, \u0026quot;set_priority\u0026quot;: { \u0026quot;priority\u0026quot;: 50 } } }, \u0026quot;cold\u0026quot;: { \u0026quot;min_age\u0026quot;: \u0026quot;3d\u0026quot;, \u0026quot;actions\u0026quot;: { \u0026quot;allocate\u0026quot;: { \u0026quot;number_of_replicas\u0026quot;: 1, \u0026quot;include\u0026quot;: {}, \u0026quot;exclude\u0026quot;: {}, \u0026quot;require\u0026quot;: { \u0026quot;box_type\u0026quot;: \u0026quot;warm\u0026quot; } }, \u0026quot;set_priority\u0026quot;: { \u0026quot;priority\u0026quot;: 0 } } }, \u0026quot;delete\u0026quot;: { \u0026quot;min_age\u0026quot;: \u0026quot;30d\u0026quot;, \u0026quot;actions\u0026quot;: { \u0026quot;delete\u0026quot;: { \u0026quot;delete_searchable_snapshot\u0026quot;: true } } } } } } PUT _template/gateway_requests-rollover { \u0026quot;order\u0026quot; : 100000, \u0026quot;index_patterns\u0026quot; : [ \u0026quot;gateway_requests-*\u0026quot; ], \u0026quot;settings\u0026quot; : { \u0026quot;index\u0026quot; : { \u0026quot;format\u0026quot; : \u0026quot;7\u0026quot;, \u0026quot;lifecycle\u0026quot; : { \u0026quot;name\u0026quot; : \u0026quot;30days-retention\u0026quot;, \u0026quot;rollover_alias\u0026quot; : \u0026quot;gateway_requests\u0026quot; }, \u0026quot;codec\u0026quot; : \u0026quot;best_compression\u0026quot;, \u0026quot;routing\u0026quot; : { \u0026quot;allocation\u0026quot; : { \u0026quot;require\u0026quot; : { \u0026quot;box_type\u0026quot; : \u0026quot;hot\u0026quot; }, \u0026quot;total_shards_per_node\u0026quot; : \u0026quot;1\u0026quot; } }, \u0026quot;number_of_shards\u0026quot; : \u0026quot;1\u0026quot; } }, \u0026quot;mappings\u0026quot; : { \u0026quot;dynamic_templates\u0026quot; : [ { \u0026quot;strings\u0026quot; : { \u0026quot;mapping\u0026quot; : { \u0026quot;ignore_above\u0026quot; : 256, \u0026quot;type\u0026quot; : \u0026quot;keyword\u0026quot; }, \u0026quot;match_mapping_type\u0026quot; : \u0026quot;string\u0026quot; } } ] }, \u0026quot;aliases\u0026quot; : { } } DELETE gateway_requests-00001 PUT gateway_requests-00001 { \u0026quot;settings\u0026quot;: { \u0026quot;index.lifecycle.rollover_alias\u0026quot;:\u0026quot;gateway_requests\u0026quot; , \u0026quot;refresh_interval\u0026quot;: \u0026quot;5s\u0026quot; }, \u0026quot;aliases\u0026quot;:{ \u0026quot;gateway_requests\u0026quot;:{ \u0026quot;is_write_index\u0026quot;:true } } }     导入仪表板 #  下载面向 Kibana 7.9 的最新的仪表板 INFINI-Gateway-7.9.2-2021-01-15.ndjson.zip，在 dev 集群的 Kibana 里面导入，如下：\n启动网关 #  接下来，就可以启动网关，。\n➜ ./bin/gateway ___ _ _____ __ __ __ _ / _ \\ /_\\ /__ \\/__\\/ / /\\ \\ \\/_\\ /\\_/\\ / /_\\///_\\\\ / /\\/_\\ \\ \\/ \\/ //_\\\\\\_ _/ / /_\\\\/ _ \\/ / //__ \\ /\\ / _ \\/ \\ \\____/\\_/ \\_/\\/ \\__/ \\/ \\/\\_/ \\_/\\_/ [GATEWAY] A light-weight, powerful and high-performance elasticsearch gateway. [GATEWAY] 1.0.0_SNAPSHOT, a17be4c, Wed Feb 3 00:12:02 2021 +0800, medcl, add extra retry for bulk_indexing [02-03 13:51:35] [INF] [instance.go:24] workspace: data/gateway/nodes/0 [02-03 13:51:35] [INF] [api.go:255] api server listen at: http://0.0.0.0:2900 [02-03 13:51:35] [INF] [runner.go:59] pipeline: request_logging_index started with 1 instances [02-03 13:51:35] [INF] [entry.go:267] entry [es_gateway] listen at: http://0.0.0.0:8000 [02-03 13:51:35] [INF] [app.go:297] gateway now started. 修改应用配置 #  将之前指向 Elasticsearch 地址的应用（如 Beats、Logstash、Kibana 等）换成网关的地址。 假设网关 IP 是 192.168.3.98，则修改 Kibana 配置如下：\n# The Kibana server's name. This is used for display purposes. #server.name: \u0026quot;your-hostname\u0026quot; # The URLs of the Elasticsearch instances to use for all your queries. elasticsearch.hosts: [\u0026quot;https://192.168.3.98:8000\u0026quot;] elasticsearch.customHeaders: { \u0026quot;app\u0026quot;: \u0026quot;kibana\u0026quot; } # When this setting's value is true Kibana uses the hostname specified in the server.host # setting. When the value of this setting is false, Kibana uses the hostname of the host # that connects to this Kibana instance. #elasticsearch.preserveHost: true # Kibana uses an index in Elasticsearch to store saved searches, visualizations and # dashboards. Kibana creates a new index if the index doesn't already exist. #kibana.index: \u0026quot;.kibana\u0026quot; # The default application to load. #kibana.defaultAppId: \u0026quot;home\u0026quot; 保存配置并重启 Kibana。\n查看效果 #  现在任何通过网关访问 Elasticsearch 的请求都能被监控到了。\n"});index.add({'id':25,'href':'/docs/latest/gateway/references/modules/floating_ip/','title':"浮动 IP",'section':"功能组件",'content':"浮动 IP #  极限网关内置浮动 IP 功能，可以实现双机热备、故障转移的能力，极限网关天然提供四层网络流量的高可用，无需再额外考虑增加额外的软件和设备来保障因为停机、网络故障等造成的代理服务中断。\n注意:\n 该特性目前仅支持 Mac OS、Linux 操作系统。且需要网关以 root 身份运行。 此特性依赖目标系统的 ping 和 ifconfig 命令，请确保相关包默认已安装。 一组启用浮动 IP 的网关所在网卡地址应该在一个子网，且内网广播互通（网关实际 IP 和浮动 IP 要求只最后一位地址不一样，如：192.168.3.x）。   功能演示 #    Youtube  Bilibili  什么是浮动 IP #  极限网关基于浮动 IP 来实现高可用，浮动 IP 也叫虚拟 IP 或者动态 IP，我们知道每台服务器之间都必须要有 IP 才能进行通信，一台服务器的 IP 一般是固定的并且一般要提前分配好， 如果这台服务器因为故障挂了的话，这个 IP 以及上面部署的业务也就不能访问了。 而一个浮动 IP 通常是一个公开的、可以路由到的 IP 地址，并且不会自动分配给实体设备。项目管理者临时分配这个动态IP到一个或者多个实体设备。 这个实体设备有自动分配的静态 IP 用于内部网间设备的通讯。这个内部网使用私有地址，这些私有地址不能被路由到。通过浮动 IP 内网实体的服务才能被外网识别和访问。\n为什么需要浮动 IP #  在一个配置好浮动 IP 的典型切换场景是，当出现当前绑定浮动 IP 的机器出现故障的时候，浮动 IP 地址会飘到网络中的另一台设备。新设备无延迟的接替当掉的设备，并对外提供服务。 从而实现网络服务的高可用，对应业务的消费方来说，只需要指定浮动 IP 就可以了。 浮动 IP 非常有用，在某些特定的场景，比如客户端或者 SDK 只允许配置一个服务 IP 地址，所以这个 IP 一定要是高可用的，而极限网关正好解决了这个问题。 使用两个独立的极限网关服务器，最好部署在独立的物理服务器上，两台极限网关构成一组双机热备的状态，任意网关出现故障都能保障前端业务的正常访问。\n如何开启浮动 IP #  极限网关开启浮动 IP 的操作非常简单，通过修改配置文件 gateway.yml，增加如下配置：\nfloating_ip: enabled: true 极限网关能够自动检测网络网卡设备信息，自动绑定虚拟 IP 到内网通信的端口，非常智能，对于使用起来非常简单，默认监听的 IP 为当前机器所在网段的 *.*.*.234。 假设你当前机器所在的物理 IP 是 192.168.3.35，那么默认的浮动 IP 是 192.168.3.234，这个默认处理只是为了方便配置和快速启动，如果你需要使用自定义的浮动 IP 的话，也可以通过补充完整的参数来设置。\n相关参数设置 #  有关浮动 IP 更多完整的配置参数样例如下：\nfloating_ip: enabled: true ip: 192.168.3.234 netmask: 255.255.255.0 interface: en1 各参数说明如下：\n   名称 类型 说明     enabled bool 是否开启浮动 IP，默认是 false   interface string 网卡设备名称，如果不指定，会选择第一个监听非本机地址的设备名称，如果服务器有多张网卡，建议手动设置   ip string 监听的浮动 IP 地址，默认是当前物理网卡所在网段的 *.*.*.234地址，建议手动设置浮动 IP 地址，浮动 IP 地址不能和已有 IP 冲突   netmask string 浮动 IP 的子网掩码，默认是网卡所在子网掩码，或者 255.255.255.0    "});index.add({'id':26,'href':'/docs/latest/console/reference/data/indices/','title':"索引管理",'section':"数据管理",'content':"索引管理 #  索引列表 #  索引列表包括对索引的增删改查操作。\n新建索引 #  输入新索引名称及索引设置即可完成添加。\n索引详情 #  可以查看索引健康状态、分片数、文档数、存储大小等详情，以及Mappings、Edit settings的查看和修改。\n"});index.add({'id':27,'href':'/docs/latest/console/getting-started/ilm/','title':"索引设置",'section':"入门指南",'content':"索引设置 #  INFINI Console 的所有监控指标都保存在 Elasticsearch 索引里面，随着时间的推移数据会越来越多，我们可以配置索引的生命周期来适配我们的监控存储需求。\n配置默认索引模板 #  然后就可以配置 Elasticsearch 集群的索引模板了，在 系统监控 集群上执行下面的命令创建索引的模板。\n 展开查看 Elasticsearch 的模板定义 ...  PUT _template/.infini { \u0026quot;order\u0026quot;: 0, \u0026quot;index_patterns\u0026quot;: [ \u0026quot;.infini_*\u0026quot; ], \u0026quot;settings\u0026quot;: { \u0026quot;index\u0026quot;: { \u0026quot;max_result_window\u0026quot;: \u0026quot;10000000\u0026quot;, \u0026quot;mapping\u0026quot;: { \u0026quot;total_fields\u0026quot;: { \u0026quot;limit\u0026quot;: \u0026quot;20000\u0026quot; } }, \u0026quot;analysis\u0026quot;: { \u0026quot;analyzer\u0026quot;: { \u0026quot;suggest_text_search\u0026quot;: { \u0026quot;filter\u0026quot;: [ \u0026quot;word_delimiter\u0026quot; ], \u0026quot;tokenizer\u0026quot;: \u0026quot;classic\u0026quot; } } }, \u0026quot;number_of_shards\u0026quot;: \u0026quot;1\u0026quot; } }, \u0026quot;mappings\u0026quot;: { \u0026quot;dynamic_templates\u0026quot;: [ { \u0026quot;strings\u0026quot;: { \u0026quot;mapping\u0026quot;: { \u0026quot;ignore_above\u0026quot;: 256, \u0026quot;type\u0026quot;: \u0026quot;keyword\u0026quot; }, \u0026quot;match_mapping_type\u0026quot;: \u0026quot;string\u0026quot; } } ] }, \u0026quot;aliases\u0026quot;: {} }     给索引 .infini_metrics 配置生命周期 #   展开查看设置 ...  PUT _ilm/policy/infini_metrics-30days-retention { \u0026quot;policy\u0026quot;: { \u0026quot;phases\u0026quot;: { \u0026quot;hot\u0026quot;: { \u0026quot;min_age\u0026quot;: \u0026quot;0ms\u0026quot;, \u0026quot;actions\u0026quot;: { \u0026quot;rollover\u0026quot;: { \u0026quot;max_age\u0026quot;: \u0026quot;30d\u0026quot;, \u0026quot;max_size\u0026quot;: \u0026quot;50gb\u0026quot; }, \u0026quot;set_priority\u0026quot;: { \u0026quot;priority\u0026quot;: 100 } } }, \u0026quot;delete\u0026quot;: { \u0026quot;min_age\u0026quot;: \u0026quot;30d\u0026quot;, \u0026quot;actions\u0026quot;: { \u0026quot;delete\u0026quot;: { \u0026quot;delete_searchable_snapshot\u0026quot;: true } } } } } } PUT _template/.infini_metrics-rollover { \u0026quot;order\u0026quot; : 100000, \u0026quot;index_patterns\u0026quot; : [ \u0026quot;.infini_metrics*\u0026quot; ], \u0026quot;settings\u0026quot; : { \u0026quot;index\u0026quot; : { \u0026quot;format\u0026quot; : \u0026quot;7\u0026quot;, \u0026quot;lifecycle\u0026quot; : { \u0026quot;name\u0026quot; : \u0026quot;infini_metrics-30days-retention\u0026quot;, \u0026quot;rollover_alias\u0026quot; : \u0026quot;.infini_metrics\u0026quot; }, \u0026quot;codec\u0026quot; : \u0026quot;best_compression\u0026quot;, \u0026quot;number_of_shards\u0026quot; : \u0026quot;1\u0026quot;, \u0026quot;translog.durability\u0026quot;:\u0026quot;async\u0026quot; } }, \u0026quot;mappings\u0026quot; : { \u0026quot;dynamic_templates\u0026quot; : [ { \u0026quot;strings\u0026quot; : { \u0026quot;mapping\u0026quot; : { \u0026quot;ignore_above\u0026quot; : 256, \u0026quot;type\u0026quot; : \u0026quot;keyword\u0026quot; }, \u0026quot;match_mapping_type\u0026quot; : \u0026quot;string\u0026quot; } } ] }, \u0026quot;aliases\u0026quot; : { } } # delete old index DELETE .infini_metrics DELETE .infini_metrics-00001 PUT .infini_metrics-00001 { \u0026quot;settings\u0026quot;: { \u0026quot;index.lifecycle.rollover_alias\u0026quot;:\u0026quot;.infini_metrics\u0026quot; , \u0026quot;refresh_interval\u0026quot;: \u0026quot;5s\u0026quot; }, \u0026quot;aliases\u0026quot;:{ \u0026quot;.infini_metrics\u0026quot;:{ \u0026quot;is_write_index\u0026quot;:true } } }     如果之前已经存在索引 .infini_metrics，需要先删除。\n给索引 .infini_alert-history 配置生命周期 #  告警功能存储执行记录的索引数据量很大，所以需要配置一下 ILM 如下：\n 展开查看设置 ...  PUT _template/.infini_alert-history-rollover { \u0026quot;order\u0026quot; : 100000, \u0026quot;index_patterns\u0026quot; : [ \u0026quot;.infini_alert-history*\u0026quot; ], \u0026quot;settings\u0026quot; : { \u0026quot;index\u0026quot; : { \u0026quot;format\u0026quot; : \u0026quot;7\u0026quot;, \u0026quot;lifecycle\u0026quot; : { \u0026quot;name\u0026quot; : \u0026quot;infini_metrics-30days-retention\u0026quot;, \u0026quot;rollover_alias\u0026quot; : \u0026quot;.infini_alert-history\u0026quot; }, \u0026quot;codec\u0026quot; : \u0026quot;best_compression\u0026quot;, \u0026quot;number_of_shards\u0026quot; : \u0026quot;1\u0026quot;, \u0026quot;translog.durability\u0026quot;:\u0026quot;async\u0026quot; } }, \u0026quot;mappings\u0026quot; : { \u0026quot;dynamic_templates\u0026quot; : [ { \u0026quot;strings\u0026quot; : { \u0026quot;mapping\u0026quot; : { \u0026quot;ignore_above\u0026quot; : 256, \u0026quot;type\u0026quot; : \u0026quot;keyword\u0026quot; }, \u0026quot;match_mapping_type\u0026quot; : \u0026quot;string\u0026quot; } } ] }, \u0026quot;aliases\u0026quot; : { } } DELETE .infini_alert-history DELETE .infini_alert-history-00001 PUT .infini_alert-history-00001 { \u0026quot;settings\u0026quot;: { \u0026quot;index.lifecycle.rollover_alias\u0026quot;:\u0026quot;.infini_alert-history\u0026quot; , \u0026quot;refresh_interval\u0026quot;: \u0026quot;5s\u0026quot; }, \u0026quot;aliases\u0026quot;:{ \u0026quot;.infini_alert-history\u0026quot;:{ \u0026quot;is_write_index\u0026quot;:true } }, \u0026quot;mappings\u0026quot;: { \u0026quot;properties\u0026quot; : { \u0026quot;condition\u0026quot; : { \u0026quot;properties\u0026quot; : { \u0026quot;items\u0026quot; : { \u0026quot;properties\u0026quot; : { \u0026quot;expression\u0026quot; : { \u0026quot;type\u0026quot; : \u0026quot;keyword\u0026quot;, \u0026quot;ignore_above\u0026quot; : 256 }, \u0026quot;minimum_period_match\u0026quot; : { \u0026quot;type\u0026quot; : \u0026quot;long\u0026quot; }, \u0026quot;operator\u0026quot; : { \u0026quot;type\u0026quot; : \u0026quot;keyword\u0026quot;, \u0026quot;ignore_above\u0026quot; : 256 }, \u0026quot;severity\u0026quot; : { \u0026quot;type\u0026quot; : \u0026quot;keyword\u0026quot;, \u0026quot;ignore_above\u0026quot; : 256 }, \u0026quot;values\u0026quot; : { \u0026quot;type\u0026quot; : \u0026quot;keyword\u0026quot;, \u0026quot;ignore_above\u0026quot; : 256 } } }, \u0026quot;operator\u0026quot; : { \u0026quot;type\u0026quot; : \u0026quot;keyword\u0026quot;, \u0026quot;ignore_above\u0026quot; : 256 } } }, \u0026quot;condition_result\u0026quot; : { \u0026quot;type\u0026quot; : \u0026quot;object\u0026quot;, \u0026quot;enabled\u0026quot; : false }, \u0026quot;context\u0026quot; : { \u0026quot;type\u0026quot; : \u0026quot;keyword\u0026quot;, \u0026quot;copy_to\u0026quot; : [ \u0026quot;search_text\u0026quot; ] }, \u0026quot;created\u0026quot; : { \u0026quot;type\u0026quot; : \u0026quot;date\u0026quot; }, \u0026quot;expression\u0026quot; : { \u0026quot;type\u0026quot; : \u0026quot;keyword\u0026quot;, \u0026quot;copy_to\u0026quot; : [ \u0026quot;search_text\u0026quot; ] }, \u0026quot;id\u0026quot; : { \u0026quot;type\u0026quot; : \u0026quot;keyword\u0026quot; }, \u0026quot;is_escalated\u0026quot; : { \u0026quot;type\u0026quot; : \u0026quot;boolean\u0026quot; }, \u0026quot;is_notified\u0026quot; : { \u0026quot;type\u0026quot; : \u0026quot;boolean\u0026quot; }, \u0026quot;message\u0026quot; : { \u0026quot;type\u0026quot; : \u0026quot;keyword\u0026quot;, \u0026quot;ignore_above\u0026quot; : 256 }, \u0026quot;objects\u0026quot; : { \u0026quot;type\u0026quot; : \u0026quot;keyword\u0026quot;, \u0026quot;copy_to\u0026quot; : [ \u0026quot;search_text\u0026quot; ] }, \u0026quot;resource_id\u0026quot; : { \u0026quot;type\u0026quot; : \u0026quot;keyword\u0026quot; }, \u0026quot;resource_name\u0026quot; : { \u0026quot;type\u0026quot; : \u0026quot;keyword\u0026quot; }, \u0026quot;rule_id\u0026quot; : { \u0026quot;type\u0026quot; : \u0026quot;keyword\u0026quot; }, \u0026quot;rule_name\u0026quot; : { \u0026quot;type\u0026quot; : \u0026quot;keyword\u0026quot; }, \u0026quot;search_text\u0026quot; : { \u0026quot;type\u0026quot; : \u0026quot;text\u0026quot;, \u0026quot;analyzer\u0026quot; : \u0026quot;suggest_text_search\u0026quot;, \u0026quot;index_prefixes\u0026quot; : { \u0026quot;min_chars\u0026quot; : 2, \u0026quot;max_chars\u0026quot; : 5 }, \u0026quot;index_phrases\u0026quot; : true }, \u0026quot;severity\u0026quot; : { \u0026quot;type\u0026quot; : \u0026quot;keyword\u0026quot; }, \u0026quot;state\u0026quot; : { \u0026quot;type\u0026quot; : \u0026quot;keyword\u0026quot;, \u0026quot;ignore_above\u0026quot; : 256 }, \u0026quot;title\u0026quot; : { \u0026quot;type\u0026quot; : \u0026quot;keyword\u0026quot; }, \u0026quot;updated\u0026quot; : { \u0026quot;type\u0026quot; : \u0026quot;date\u0026quot; } } } }     给索引 .infini_activities 配置生命周期 #   展开查看设置 ...  PUT _template/.infini_activities-rollover { \u0026quot;order\u0026quot; : 100000, \u0026quot;index_patterns\u0026quot; : [ \u0026quot;.infini_activities*\u0026quot; ], \u0026quot;settings\u0026quot; : { \u0026quot;index\u0026quot; : { \u0026quot;format\u0026quot; : \u0026quot;7\u0026quot;, \u0026quot;lifecycle\u0026quot; : { \u0026quot;name\u0026quot; : \u0026quot;infini_metrics-30days-retention\u0026quot;, \u0026quot;rollover_alias\u0026quot; : \u0026quot;.infini_activities\u0026quot; }, \u0026quot;codec\u0026quot; : \u0026quot;best_compression\u0026quot;, \u0026quot;number_of_shards\u0026quot; : \u0026quot;1\u0026quot;, \u0026quot;translog.durability\u0026quot;:\u0026quot;async\u0026quot; } }, \u0026quot;mappings\u0026quot; : { \u0026quot;dynamic_templates\u0026quot; : [ { \u0026quot;strings\u0026quot; : { \u0026quot;mapping\u0026quot; : { \u0026quot;ignore_above\u0026quot; : 256, \u0026quot;type\u0026quot; : \u0026quot;keyword\u0026quot; }, \u0026quot;match_mapping_type\u0026quot; : \u0026quot;string\u0026quot; } } ] }, \u0026quot;aliases\u0026quot; : { } } DELETE .infini_activities DELETE .infini_activities-00001 PUT .infini_activities-00001 { \u0026quot;settings\u0026quot;: { \u0026quot;index.lifecycle.rollover_alias\u0026quot;:\u0026quot;.infini_activities\u0026quot; , \u0026quot;refresh_interval\u0026quot;: \u0026quot;5s\u0026quot; }, \u0026quot;aliases\u0026quot;:{ \u0026quot;.infini_activities\u0026quot;:{ \u0026quot;is_write_index\u0026quot;:true } } }     "});index.add({'id':28,'href':'/docs/latest/console/reference/data/alias/','title':"别名管理",'section':"数据管理",'content':"别名管理 #  别名列表 #  别名列表包括对别名的增删改查操作。\n新建别名 #   别名：输入别名名称 索引：选择别名对应的目标索引，支持使用 (*) 来绑定多个索引。 是否为写索引：指定选择的索引是否可写，如果别名只绑定一个索引，则默认该索引可写；如果是通过(*) 绑定多个索引，最需要指定其中一个索引为可写。  别名与索引关系列表 #  点开别名列表行首的+号按钮，会展开显示该别名对应绑定的索引列表，同时可以对索引进行关系绑定更新设置和删除。\n"});index.add({'id':29,'href':'/docs/latest/console/reference/alerting/channel/','title':"告警渠道",'section':"告警管理",'content':"告警渠道 #  简介 #  告警渠道用于当告警规则触发之后，发送通知消息的通道配置，目前支持 webhook。\n渠道列表 #  在渠道列表中可以查询已经添加的渠道\n新建告警渠道 #  在渠道列表页面中点击新建按钮进入新建告警渠道页面\n 输入渠道名称（必填） 选择渠道类型（当前仅支持 webhook ） 输入 webhook 地址 选择 HTTP 请求的方法，默认 POST 按需添加 HTTP 请求头 配置 webhook 请求体 点击保存按钮提交  更新渠道配置 #  在渠道列表中选择需要更新的渠道点击编辑按钮进入更新渠道配置页\n操作参考新建告警渠道\n删除告警渠道 #  点击告警渠道列表表格中的删除按钮，进行二次确认，确认删除后执行删除操作。\n"});index.add({'id':30,'href':'/docs/latest/console/tutorials/create_readonly_account/','title':"如何轻松创建一个 Elasticsearch “游客” 用户",'section':"动手教程",'content':"如何轻松创建一个 Elasticsearch “游客” 用户 #  简介 #  有些情况下，我们想给客户分享一下某些功能或者数据，但是又不希望数据被修改。 这个时候我们就需要创建一个“游客” 用户了。本文简单地介绍了如何使用 INFINI Console 创建\u0026quot;游客\u0026quot;用户。\n准备 #   下载并安装最新版 INFINI Console 开启 INFINI Console 安全功能  创建角色 #  点击 INFINI Console 左侧菜单 系统管理》安全设置，选择角色 Tab 页进入角色管理页。\n新建平台角色 readonly #  点击新建按钮，选择平台角色，新建一个平台角色 readonly，操作步骤如下：\n 输入角色名称 readonly 展开所有的功能权限 除了系统设置下面的安全功能，其他所有的功能都选择 Read 权限。 系统设置下面的安全功能 设置为 None 权限。 点击保存按钮提交   选择某个功能的 All 权限代表拥有这个功能的读和写的操作权限， Read 代表只拥有读的权限， None 代表没有该功能权限（用户登录之后菜单中没有该功能）\n 新建数据角色 es-v7171 #  点击新建按钮，选择数据角色，新建一个数据角色 es-v7171，操作步骤如下：\n 输入角色名称 es-v7171 集群权限选择集群 es-v7171 点击保存按钮提交  新建账户 guest #  点击 INFINI Console 左侧菜单 系统管理》安全设置，选择用户 Tab 页进入账户管理页。 点击新建按钮，新建账户 guest ，并赋予这个账户角色 readonly, es-v7171\n点击保存提交，创建成功之后就可以使用 guest 账户登录 INFINI Console ，并且只拥有只读权限。\n"});index.add({'id':31,'href':'/docs/latest/console/reference/migration/migration/','title':"数据迁移",'section':"容灾备份",'content':"数据迁移 #  创建迁移任务 #  点击 INFINI Console 中左侧菜单 容灾备份》数据迁移，然后点击新建按钮创建迁移任务，如下图所示：\n配置迁移集群 #  在源集群列表中选择集群 es-v5616, 在目标集群列表中选择集群 es-v7140\n配置迁移索引 #  点击选择迁移索引按钮, 如下图：\n这里我们选择了两个索引 test-10 和 test-15 ,然后点击确认\n 选择索引的时候请确认目标集群相应索引是否创建好 mapping, setting 等元数据信息\n 表格右方可以设置目标索引名称和文档 type，按需修改即可，这里我们将索引 test-10 重命名为 test-10-x, 将索引 test-15 重命名为 test-15-x，文档类型都重命名为 _doc。 选择完索引之后，点击下一步，进行迁移任务的数据范围设置和分区设置，如下图：\n配置数据范围 #  如果需要过滤数据迁移，可以进行数据范围的设置，这里我们进行全量的数据迁移，就不设置了\n配置数据分区 #  如果一个索引数据量特别大，可以进行数据分区的设置。数据分区根据设置的字段，以及分区步长将数据拆成多段，系统最终会将一个分段的数据作为一个子任务去运行，迁移数据， 这样的话即使，一个分段迁移过程出现异常，只需要重跑这个子任务。\n数据分区设置目前支持按照日期类型字段（date）, 和数字类型 (number) 拆分分区，如上图所示，我们选择日期类型字段 now_widh_format 进行拆分分区，分区步长设置为 5分钟(5m), 然后点击预览按钮，可以看到根据设置拆分可以得到 8 个分区（文档数为0的分区最终不会生成子任务）。 根据预览信息确认分区设置无误之后，点击保存关闭分区设置并保存，然后点击下一步进行运行设置。\n运行设置 #  一般情况下使用默认设置，然后执行节点选择网关实例 Dynamo，然后点击创建任务。\n 如果没有在网关管理》实例管理里面注册网关实例，需要提前注册\n 启动迁移任务 #  创建迁移任务成功后会看到任务列表，如下图：\n可以看到，最近一条任务就是我们刚创建的，然后在表格右侧操作栏中点击 start 开始任务（任务开始之前，需要确认目标集群中索引是否已经设置好mapping， 和 settings, 索引模版，ilm ）。\n点击开始按钮 启动迁移任务。\n查看迁移任务进度 #  任务启动成功之后，点击刷新按钮，刷新列表，看到操作一栏中有详情入口时，点击详情进入任务详情页查看任务执行状态。开启自动刷新之后，我们可以看到任务详情有如下变化：\n图中蓝色方块表示，子任务（分区任务）已经在运行，灰色表示任务还没有开始\n上图中可以看到方块变成了浅绿色，表示子任务（分区任务）已经数据导出完成，索引 test-10的迁移进度是 65.5%, 索引 test-15 迁移进度是 18.05%\n上图中可以看到所有方块变成了绿色，索引迁移进度都是 100%, 表示数据已经迁移完成。\n"});index.add({'id':32,'href':'/docs/latest/console/tutorials/role_with_different_rights/','title':"如何给不同 INFINI Console 账户分配不同 Elasticsearch 集群访问权限",'section':"动手教程",'content':"如何给不同 INFINI Console 账户分配不同 Elasticsearch 集群访问权限 #  简介 #  本文将介绍使用 INFINI Console 给两个不同账户分配两个不同的 Elasticsearch 集群管理权限\n准备 #   下载并安装最新版 INFINI Console 开启 INFINI Console 安全功能 注册至少两个 Elasticsearch 集群到 INFINI Console  创建角色 #  点击 INFINI Console 左侧菜单 系统管理》安全设置，选择角色 Tab 页进入角色管理页。\n新建平台角色 platform_role #  点击新建按钮，选择平台角色，新建一个平台角色 platform_role，操作步骤如下：\n 输入角色名称 platform_role 展开所有的功能权限 除了系统设置下面的安全功能，其他所有的功能都选择 All 权限。 系统设置下面的安全功能 设置为 None 权限。 点击保存按钮提交   选择某个功能的 All 权限代表拥有这个功能的读和写的操作权限， Read 代表只拥有读的权限， None 代表没有该功能权限（用户登录之后菜单中没有该功能）\n 新建数据角色 es-v7171 #  点击新建按钮，选择数据角色，新建一个数据角色 es-v7171\n新建数据角色 es-v630 #  点击新建按钮，选择数据角色，新建一个数据角色 es-v630，配置同角色 es-v7171 类似\n创建账户 #  点击 INFINI Console 左侧菜单 系统管理》安全设置，选择用户 Tab 页进入账户管理页。\n新建账户 zhangsan #  点击新建按钮，新建账户 zhangsan ，并赋予这个账户角色 platform_role, es-v717\n点击保存按钮提交创建成功之后，保存一下账户密码\n新建账户 wangwu #  点击新建按钮，新建账户 wangwu ，并赋予这个账户角色 platform_role, es-v630 ,配置同账户 zhangsan 类似\n使用管理员账号登录 #  使用管理员账号登录之后，查看平台概览，注册的 13 个集群都可以看到\n使用账号 zhangsan 登录 #  使用账号 zhangsan 登录之后，查看平台概览，只能看到集群 es-v7171\n使用账号 wangwu 登录 #  使用账号 zhangsan 登录之后，查看平台概览，只能看到集群 es-v630\n小结 #  通过创建不同的角色并且赋予不同的 Elasticsearch 集群权限，然后将角色赋予用户，我们可以快速的实现 对不同用户赋予不同的 Elasticsearch 集群权限。\n"});index.add({'id':33,'href':'/docs/latest/console/tutorials/role_with_index_limit/','title':"如何给 INFINI Console 账户分配 Elasticsearch 索引级别权限",'section':"动手教程",'content':"如何给 INFINI Console 账户分配 Elasticsearch 索引级别权限 #  简介 #  本文将介绍使用 INFINI Console 限定某个账户只有 Elasticsearch 集群里面某些索引的管理权限\n准备 #   下载并安装最新版 INFINI Console 开启 INFINI Console 安全功能 注册至少两个 Elasticsearch 集群到 INFINI Console  创建角色 #  点击 INFINI Console 左侧菜单 系统管理》安全设置，选择角色 Tab 页进入角色管理页。\n新建平台角色 platform_role #  点击新建按钮，选择平台角色，新建一个平台角色 platform_role\n新建数据角色 test_index_only #  点击新建按钮，选择数据角色，新建一个数据角色 test_index_only, 然后做如下配置：\n 将集群只选择 es-v7140 （限制该角色只有 Elasticsearch 集群 es-v7140 的访问权限 ） 设置索引权限 索引只输入索引 pattern test* （限制该角色只有索引名称匹配 test* 的索引访问权限）  配置完成之后点击保存按钮提交。\n创建账户 #  点击 INFINI Console 左侧菜单 系统管理》安全设置，选择用户 Tab 页进入账户管理页。\n新建账户 liming #  点击新建按钮，新建账户 liming ，并赋予这个账户角色 platform_role, test_index_only\n点击保存按钮提交创建成功之后，保存一下账户密码\n使用管理员账号登录 #  使用管理员账号登录之后，点击菜单数据管理里面的索引管理，选择集群 es-v7140 ， 然后可以看到：\n使用账号 liming 登录 #  使用账号 liming 登录之后，点击菜单数据管理里面的索引管理，选择集群 es-v7140 ， 然后可以看到：\n小结 #  通过指定角色的 Elasticsearch 集群权限以及索引权限，可以轻松地将用户的权限分配精准控制到索引级别。\n"});index.add({'id':34,'href':'/docs/latest/gateway/user-cases/stories/a_cross_region_cluster_access_locality/','title':"作业帮跨云集群的就近本地访问",'section':"用户案例",'content':"跨云集群的就近本地访问 #  业务需求 #  作业帮为了确保某个业务 Elasticsearch 集群的高可用，在百度云和华为云上面采取了双云部署，即将单个 Elasticsearch 集群跨云进行部署，并且要求业务请求优先访问本地云。\nElasticsearch 单集群双云实现 #  Elasticsearch 集群采用 Master 与 Data 节点分离的架构。 目前主力云放 2 个 Master，另外一个云放一个 Master。 主要考虑就是基础设施故障中，专线故障问题是大多数，某个云厂商整体挂的情况基本没有。 所以设置了主力云，当专线故障时，主力云的 Elasticsearch 是可以读写的，业务把流量切到主力云就行了。\n具体配置方式如下。\n首先，在 Master 节点上设置：\ncluster.routing.allocation.awareness.attributes: zone_id cluster.routing.allocation.awareness.force.zone_id.values: zone_baidu,zone_huawei 然后分别在百度云上数据节点上设置：\nnode.attr.zone_id: zone_baidu 和华为云上数据节点上设置：\nnode.attr.zone_id: zone_huawei 创建索引采用 1 副本，可以保证百度云与华为云上都有一份相同的数据。\n业务访问方式如下图：\n 百度云业务 -\u0026gt; 百度 lb -\u0026gt; INFINI Gateway (百度) -\u0026gt; Elasticsearch （百度云 data 节点） 华为云业务 -\u0026gt; 华为 lb -\u0026gt; INFINI Gateway (华为) -\u0026gt; Elasticsearch （华为云 data 节点）  极限网关配置 #  Elasticsearch 支持一个 Preference 参数来设置请求的优先访问，通过在两个云内部的极限网关分别设置各自请求默认的 Preference 参数，让各个云内部的请求优先发往本云内的数据节点，即可实现请求的就近访问。\n具体的百度云的 INFINI Gateway 配置如下（华为云大体相同，就不重复贴了）：\npath.data: data path.logs: log entry: - name: es-test enabled: true router: default network: binding: 0.0.0.0:9200 reuse_port: true router: - name: default default_flow: es-test flow: - name: es-test filter: - set_request_query_args: args: - preference -\u0026gt; _prefer_nodes:node-id-of-data-baidu01,node-id-of-data-baidu02 #通过配置preference的_prefer_nodes为所有的百度data节点的node_id，来实现百度云的业务优先访问百度云的节点，最大程度避免跨云访问，对业务更友好。 when: contains: _ctx.request.path: /_search - elasticsearch: elasticsearch: default refresh: enabled: true interval: 10s roles: include: - data #配置为data，请求只发送到data节点 tags: include: - zone_id: zone_baidu #只转发给百度云里面的节点 elasticsearch: - name: default enabled: true endpoint: http://10.10.10.10:9200 allow_access_when_master_not_found: true discovery: enabled: true refresh: enabled: true interval: 10s basic_auth: username: elastic password: elastic 总结与收益 #  引入极限网关前故障回顾 #  百度云业务访问 Elasticsearch 集群，拉取每天的增量数据同步到 Hive 集群，其中有几个任务失败后，又重新同步。结果是部分数据从华为云的 Elasticsearch 节点拉取到百度云的 Hive 集群中，数据量巨大导致跨云专线流量监控告警。由于线上业务、MySQL、Redis、Elasticsearch 等使用同一根专线， 此次故障影响面较大。临时解决方案是业务修改语句加入 Preference 参数来实现业务只拉取本地云数据，减少对专线的占用。但是一方面业务改造及维护成本较高；另一方面作为 DBA 会担心业务改造有疏漏、新增业务遗忘 Preference 参数、以及后期调整成本较高，这始终是一个风险点。\n引入极限网关的收益 #  在原有架构上加入极限网关，可以在业务不修改代码的情况下做到优先访问本地云，提升访问速度的同时，最大限度减少对专线的压力。\n 作者：赵青，前网易 DBA，工作主要涉及 Oracle、MySQL、Redis、Elasticsearch、Tidb、OB 等组件的运维以及运维自动化、平台化、智能化等工作。现就职于作业帮。\n "});index.add({'id':35,'href':'/docs/latest/console/reference/data/view/','title':"数据视图",'section':"数据管理",'content':"数据视图 #  视图列表 #  创建和管理数据视图可以帮助您更好地从 Elasticsearch 获取数据。\n创建视图 #  步骤 1 定义数据视图 #   输入数据视图名称 匹配规则：匹配相应索引，也可以使用 (*) 来匹配多个索引。  步骤 2 配置 #    为数据视图索引选择时间字段作为时间过滤\n  创建完成\n  编辑数据视图 #  页面列出匹配索引的所有字段，可以对字段的Format、Popularity等做相关设置。\n"});index.add({'id':36,'href':'/docs/latest/gateway/references/router/','title':"服务路由",'section':"功能手册",'content':"服务路由 #  极限网关通过路由来判断流量的去向，一个典型的路由配置示例如下：\nrouter: - name: my_router default_flow: default_flow tracing_flow: request_logging rules: - method: - PUT - POST pattern: - \u0026quot;/_bulk\u0026quot; - \u0026quot;/{index_name}/_bulk\u0026quot; flow: - bulk_process_flow 路由有几个非常重要的概念：\n flow：请求的处理流程，一个路由里面有三个地方定义 flow default_flow: 默认的处理流，也就是业务处理的主流程，请求转发、过滤、缓存等操作都在这里面进行 tracing_flow：用于追踪请求状态的流，不受 default_flow 的影响，用于记录请求日志、统计等 rules：根据匹配规则将请求分发到特定的处理流中去，支持请求的 Method、Path 的正则匹配  参数说明 #     名称 类型 说明     name string 路由名称   default_flow string 默认的请求的处理流程名称   tracing_flow string 用于追踪请求的处理流程名称   rules array 路由规则列表，按照数组的先后顺序依次应用   rules.method string 请求的 Method 类型，支持 GET、HEAD、POST、PUT、PATCH、DELETE、CONNECT、OPTIONS、TRACE， * 表示任意类型   rules.pattern string 请求的 URL Path 匹配规则，支持通配符，不允许有重叠匹配   rules.flow string 规则匹配之后执行的处理流程，支持多个 flow 组合，依次顺序执行   permitted_client_ip_list string array 指定一组允许访客 IP 的白名单   denied_client_ip_list string array 指定一组拒绝访客 IP 的黑名单    Pattern 语法 #     语法 说明 示例     {变量名} 带名称的变量 /{name}   {变量名:regexp} 通过正则来限制变量的匹配规则 /{name:[a-zA-Z]}   {变量名:*} 匹配之后的任意路径，只允许应用在 Pattern 末尾 /{any:*}    更多示例：\nPattern: /user/{user} /user/gordon match /user/you match /user/gordon/profile no match /user/ no match Pattern with suffix: /user/{user}_admin /user/gordon_admin match /user/you_admin match /user/you no match /user/gordon/profile no match /user/gordon_admin/profile no match /user/ no match Pattern: /src/{filepath:*} /src/ match /src/somefile.go match /src/subdir/somefile.go match 其他注意事项：\n Pattern 必须是 / 开头 任意匹配只能作为最后的一个规则  IP 访问控制 #  如果希望对访问网关服务的来源 IP 进行访问控制，可以通过 ip_access_control 配置节点来进行管理。\nrouter: - name: my_router default_flow: async_bulk ip_access_control: enabled: true 白名单 #  如果只希望某些特定指定 IP 的访客才能访问网关服务，可以在路由里面配置来实现访问准入，该请求会在链接建立的过程中直接拒绝。 如下例子，133.37.55.22 会被允许网关的服务访问，其余的 IP 都会拒绝。\nrouter: - name: my_router default_flow: async_bulk ip_access_control: enabled: true client_ip: permitted: - 133.37.55.22 黑名单 #  如果希望拒绝某些特定指定 IP 的访客来访问网关服务，可以在路由里面配置来实现访问拒绝，该请求会在链接建立的过程中直接拒绝。 如下例子，133.37.55.22 就会被阻止网关的服务访问。\nrouter: - name: my_router default_flow: async_bulk ip_access_control: enabled: true client_ip: denied: - 133.37.55.22 "});index.add({'id':37,'href':'/docs/latest/gateway/user-cases/stories/indexing_speedup_for_big_index_rebuild/','title':"某保险业务索引速度百倍提升",'section':"用户案例",'content':"某保险集团业务的索引速度百倍提升之旅 #  业务挑战 #  某大型保险集团的保单查询业务，通过将数据库的常用字段放到 Elasticsearch 里面，用来提升查询性能，集群部署在 14 台物理机上面，每个物理机上面部署了 4 个 Elasticsearch 实例， 整个集群约有 90 多亿条数据，索引主分片存储接近 5 TB，每天的增量更新数据大概在 6 亿条左右，由于业务上的特殊性，全国的所有的业务数据都存放在一个索引里面， 造成了单个索引达到了 210 个分片，批量重建的任务采用 Spark 任务来并行执行，平均的写入速度在 2000~3000 条/s 左右，一次增量重建时间可能需要 2~3 天， 业务数据的更新延迟较大，长时间的重建也会影响正常时间段的业务访问。该技术团队也尝试过直接对 Elasticsearch 层面和 Spark 写入端多轮的测试和调优，发现对整体的写入速度没有太大的提升。\n应用场景 #  通过分析，集群性能应该没有问题，不过由于单个批次写入请求到达 Elasticsearch 之后需要重新再次按照主分片所在节点进行封装转发，而某保的业务索引分片个数太多，每个数据节点最终拿到的请求文档数太小， 客户端一次批次写入要拆分成几百次的小批次请求，并且由于短板原理，最慢的节点处理速度会拖慢整个批次写入的速度，从而造成集群总体吞吐的低下。\n通过评估极限网关，发现极限网关具备提前拆分请求和合并请求的能力，通过提前拆分合并请求到以节点为单位的本地队列，然后通过队列消费程序写入到目标 Elasticsearch 集群，将随机的批次请求转换为顺序的精准投放，如下图：\n极限网关在收到 Spark 请求之后先落地到本地磁盘确保数据不丢失，同时极限网关能够本地计算每个文档与目标数据节点的对应关系，新的数据写入架构如下图所示：\n通过采用极限网关来接收 Spark 的写入请求，整个集群的写入吞吐显著提升，Spark 写数据只花了不到 15 分钟即任务运行结束，网关从收到请求到写完 Elasticsearch 也只花了 20 分钟，服务器的 CPU 资源也充分利用起来了， 各个节点的 CPU 利用率均达到 100%。\n用户收益 #   索引速度提升 20000%\n 通过采用极限网关来作为中间加速层，该集团保单业务的索引重建速度由原来的 2-3 天都重建不完缩减到 20 分钟左右，每日增量 6 亿条数据的全部重建终于也可以快速完成， 索引写入 QPS 峰值也达到了 30 万+，大大缩短了索引重建周期，降低了数据延迟，增强了线上数据的一致性，确保了查询业务的正常使用。\n"});index.add({'id':38,'href':'/docs/latest/gateway/tutorial/index_diff/','title':"索引文档级别差异对比",'section':"动手教程",'content':"索引差异对比 #  通过极限网关可以进行索引的文档差异对比，可以对同集群或者跨集群的两个不同的索引进行 diff 比较，对于使用应用双写、CCR 或者其他数据复制方案的场景，可以进行定期 diff 比较来确保数据是否真的一致。\n功能演示 #    如何配置 #  设置目标集群 #  修改配置文件 gateway.yml，设置两个集群资源 source 和 target，增加如下配置：\nelasticsearch: - name: source enabled: true endpoint: http://localhost:9200 basic_auth: username: test password: testtest - name: target enabled: true endpoint: http://localhost:9201 basic_auth: #used to discovery full cluster nodes, or check elasticsearch's health and versions username: test password: testtest 配置对比任务 #  增加一个服务管道配置，用来处理两个集群的索引文档拉取和对比，如下：\npipeline: - name: index_diff_service auto_start: true keep_running: true processor: - dag: parallel: - dump_hash: #dump es1's doc indices: \u0026quot;medcl-test\u0026quot; scroll_time: \u0026quot;10m\u0026quot; elasticsearch: \u0026quot;source\u0026quot; output_queue: \u0026quot;source_docs\u0026quot; batch_size: 10000 slice_size: 5 - dump_hash: #dump es2's doc indices: \u0026quot;medcl-test\u0026quot; scroll_time: \u0026quot;10m\u0026quot; batch_size: 10000 slice_size: 5 elasticsearch: \u0026quot;target\u0026quot; output_queue: \u0026quot;target_docs\u0026quot; end: - index_diff: diff_queue: \u0026quot;diff_result\u0026quot; buffer_size: 1 text_report: true #如果要存 es，这个开关关闭，开启 pipeline 的 diff_result_ingest 任务 source_queue: 'source_docs' target_queue: 'target_docs' 上面的配置中，并行使用了 dump_hash 来拉取集群 source 的 medcl-a 索引和取集群 target 的 medcl-b 索引，并以文本结果的方式输出到终端。\n输出结果到 Elasticsearch #  如果 diff 结果比较多，可以选择保存到 Elasticsearch 集群，将上面的 index_diff 处理单元的参数 text_report 设置为 false，并增加如下配置：\npipeline: - name: diff_result_ingest auto_start: true keep_running: true processor: - json_indexing: index_name: \u0026quot;diff_result\u0026quot; elasticsearch: \u0026quot;source\u0026quot; input_queue: \u0026quot;diff_result\u0026quot; idle_timeout_in_seconds: 1 worker_size: 1 bulk_size_in_mb: 10 #in MB 最后导入 仪表板 到 Kibana 即可看到如下效果：\n"});index.add({'id':39,'href':'/docs/latest/gateway/references/modules/force_merge/','title':"索引段合并",'section':"功能组件",'content':"主动合并索引分段 #  极限网关内置一个索引分段合并服务，可以主动对索引段文件进行合并，从而提升查询速度，段合并服务支持多个索引的依次顺序处理，并对合并任务状态进行了跟踪处理，避免大量段合并任务并行操作拖慢集群。\n如何开启 #  修改配置文件 gateway.yml，增加如下配置：\nforce_merge: enabled: false elasticsearch: dev min_num_segments: 20 max_num_segments: 1 indices: - index_name 各参数说明如下：\n   名称 类型 说明     enabled bool 是否启用该模块，默认是 false   elasticsearch string 操作的 Elasticsearch 集群 ID   min_num_segments int 超过多少分片的索引才会执行主动分片合并，以索引为单位的统计数目   max_num_segments int 将分片下的段文件合并之后，最多生成的段文件个数   indices array 需要进行分片合并的索引列表   discovery object 自动发现索引的相关设置   discovery.min_idle_time string 满足段合并条件的最小时间跨度，默认 1d   discovery.interval string 重新检测需要进行段合并的时间间隔   discovery.rules array 自动进行索引检测的索引匹配规则   discovery.rules.index_pattern string 要进行索引段文件合并的索引通配符   discovery.rules.timestamp_fields array 代表索引时间戳的字段列表    "});index.add({'id':40,'href':'/docs/latest/gateway/getting-started/configuration/','title':"配置网关",'section':"入门指南",'content':"配置 #  极限网关支持多种方式来修改配置。\n命令行参数 #  极限网关提供了命令行参数如下：\n✗ ./bin/gateway --help Usage of ./bin/gateway: -config string the location of config file, default: gateway.yml (default \u0026quot;gateway.yml\u0026quot;) -debug run in debug mode, gateway will quit with panic error -log string the log level,options:trace,debug,info,warn,error (default \u0026quot;info\u0026quot;) -v version 常用的说明如下：\n config，指定配置文件名，默认的配置文件名为当前执行命令所在目录的 gateway.yml，如果你的配置文件放置在其他地方，可以通过指定参数来进行选择。 daemon，将网关切换到后台执行，一般还需要结合 pidfile 来保存进程号，方便后续的进程操作。  配置文件 #  极限网关的大部分配置都可以通过 gateway.yml 来进行配置，配置修改完成之后，需要重启网关程序才能生效。\n定义入口 #  每一个网关都至少要对外暴露一个服务的入口，用来接收业务的操作请求，这个在极限网关里面叫做 entry，通过下面的参数即可定义：\nentry: - name: es_gateway enabled: true router: default network: binding: 0.0.0.0:8000 这里定义了一个名为 es_gateway 的服务入口，监听的地址是 0.0.0.0:8000，使用了一个名为 default 的路由来处理请求。\n定义路由 #  极限网关通过路由来判断流量的去向，一个典型的路由配置示例如下：\nrouter: - name: default default_flow: cache_first 这里定义了一个名为 default 的路由，也就是业务处理的主流程，请求转发、过滤、缓存等操作都在这里面进行。\n定义流程 #  一个请求流程定义了一系列请求处理的工作单元，是一个典型的管道式工作方式，一个典型的配置示例如下：\nflow: - name: cache_first filter: - get_cache: - elasticsearch: elasticsearch: prod - set_cache: 上面的配置定义了一个名为 cache_first 的处理流，使用了三个不同的 filter，分别是 get_cache、elasticsearch 和 set_cache，这些 filter 会依据配置的先后顺序依次执行，注意每个 filter 名称后面要带上一个 :。 各个 filter 的处理结果分别如下：\n get_cache，这个 filter 主要用来从缓存里面拿数据，如果之前发生过相同的请求，并且缓存还存在且有效的情况下，这个 filter 可以直接拿到缓存然后立即返回，不用继续往下处理； elasticsearch，这个 filter 主要用来将请求转发给后端的 Elasticsearch 集群，并且将 Elasticsearch 返回的响应内容继续往下传递； set_cache，这个 filter 会将执行结果缓存到本地内存，有一些参数限制，比如状态码，请求大小等，并设置一定的过期时间，以方便下次重复请求可以直接使用缓存，一般要和 get_cache 组合使用。  定义资源 #  这里的资源主要是指 Elasticsearch 后端服务器资源，极限网关支持多个 Elasticsearch 集群，可以实现将请求转发到多个不同集群，也可以支持请求的蓝绿发布、灰度切换等，定义一个 Elasticsearch 后端资源的方式示例如下：\nelasticsearch: - name: prod enabled: true endpoint: http://192.168.3.201:9200 discovery: enabled: true refresh: enabled: true basic_auth: username: elastic password: pass 通过参数 endpoint 来设置 Elasticsearch 的访问地址，如果 Elasticsearch 开启了身份认证，可以通过 basic_auth 来指定用户名和密码信息，该用户需要有能够获取集群状态信息的权限。 通过参数 discover 可以开启自动的后端节点的自动发现，用于自动检测后端节点的情况，能够自动识别新增和离线的节点。\n通过这些基本的配置，我们就可以正常的代理 Elasticsearch 的请求了，关于每个组件更详细完整的参数，请参考 功能手册。\n"});index.add({'id':41,'href':'/docs/latest/console/getting-started/docker/','title':"容器部署",'section':"入门指南",'content':"容器部署 #  INFINI Console 支持容器方式部署。\n下载镜像 #  INFINI Console 的镜像发布在 Docker 的官方仓库，地址如下：\n https://hub.docker.com/r/infinilabs/console\n使用下面的命令即可获取最新的容器镜像：\ndocker pull infinilabs/console:latest 验证镜像 #  将镜像下载到本地之后，可以看到 INFINI Console 平台的容器镜像非常小，只有不到 30MB，所以下载的速度应该是非常快的。\n✗ docker images REPOSITORY TAG IMAGE ID CREATED SIZE infinilabs/console latest 8c27cd334e4c 47 minutes ago 26.4MB 创建配置 #  现在需要创建一个配置文件 console.yml，来进行基本的配置，如下：\n# for this System Cluster, please use Elasticsearch v7.3+ elasticsearch: - name: default enabled: true monitored: false endpoint: http://192.168.3.188:9299 basic_auth: username: elastic password: ZBdkVQUUdF1Sir4X4BGB discovery: enabled: true web: enabled: true embedding_api: true auth: enabled: true ui: enabled: true path: .public vfs: true local: true network: binding: 0.0.0.0:9000 skip_occupied_port: true gzip: enabled: true elastic: elasticsearch: default enabled: true remote_configs: true health_check: enabled: true interval: 30s availability_check: enabled: true interval: 60s metadata_refresh: enabled: true interval: 30s cluster_settings_check: enabled: true interval: 20s store: enabled: false orm: enabled: true init_template: true template_name: \u0026quot;.infini\u0026quot; index_prefix: \u0026quot;.infini_\u0026quot; metrics: enabled: true major_ip_pattern: \u0026quot;192.*\u0026quot; queue: metrics elasticsearch: enabled: true cluster_stats: true node_stats: true index_stats: true pipeline: - name: indexing_merge auto_start: true keep_running: true processor: - indexing_merge: input_queue: \u0026quot;metrics\u0026quot; elasticsearch: \u0026quot;default\u0026quot; index_name: \u0026quot;.infini_metrics\u0026quot; output_queue: name: \u0026quot;metrics_requests\u0026quot; label: tag: \u0026quot;metrics\u0026quot; worker_size: 1 bulk_size_in_mb: 10 - name: consume-metrics_requests auto_start: true keep_running: true processor: - bulk_indexing: bulk: compress: true batch_size_in_mb: 10 batch_size_in_docs: 5000 consumer: fetch_max_messages: 100 queues: type: indexing_merge when: cluster_available: [ \u0026quot;default\u0026quot; ] - name: metadata_ingest auto_start: true keep_running: true processor: - metadata: bulk_size_in_mb: 10 bulk_max_docs_count: 5000 fetch_max_messages: 1000 elasticsearch: \u0026quot;default\u0026quot; queues: type: metadata category: elasticsearch consumer: group: metadata when: cluster_available: [ \u0026quot;default\u0026quot; ] - name: activity_ingest auto_start: true keep_running: true processor: - activity: bulk_size_in_mb: 10 bulk_max_docs_count: 5000 fetch_max_messages: 1000 elasticsearch: \u0026quot;default\u0026quot; queues: category: elasticsearch activity: true consumer: group: activity when: cluster_available: [ \u0026quot;default\u0026quot; ] Note: 上面配置里面的 Elasticsearch 的相关配置，请改成实际的服务器连接地址和认证信息，需要版本 v7.3 及以上。\n启动平台 #  使用如下命令启动极限网关容器：\ndocker run -p 9000:9000 -v=`pwd`/console.yml:/console.yml infinilabs/console:latest Docker Compose #  还可以使用 docker compose 来管理容器实例，新建一个 docker-compose.yml 文件如下：\nversion: \u0026quot;3.5\u0026quot; services: infini-console: image: infinilabs/console:latest ports: - 9000:9000 container_name: \u0026quot;infini-console\u0026quot; volumes: - ../console.yml:/console.yml volumes: dist: 在配置文件所在目录，执行如下命令即可启动，如下：\n➜ docker-compose up "});index.add({'id':42,'href':'/docs/latest/gateway/getting-started/docker/','title':"容器部署",'section':"入门指南",'content':"容器部署 #  极限网关支持容器方式部署。\n安装演示 #    下载镜像 #  极限网关的镜像发布在 Docker 的官方仓库，地址如下：\n https://hub.docker.com/r/infinilabs/gateway\n使用下面的命令即可获取最新的容器镜像：\ndocker pull infinilabs/gateway:latest 验证镜像 #  将镜像下载到本地之后，可以看到极限网关的容器镜像非常小，只有不到 25MB，所以下载的速度应该是非常快的。\n✗ docker images REPOSITORY TAG IMAGE ID CREATED SIZE infinilabs/gateway latest fdae74b64e1a 47 minutes ago 23.5MB 创建配置 #  现在需要创建一个配置文件 gateway.yml，来进行基本的配置，如下：\npath.data: data path.logs: log entry: - name: my_es_entry enabled: true router: my_router max_concurrency: 200000 network: binding: 0.0.0.0:8000 flow: - name: simple_flow filter: - elasticsearch: elasticsearch: dev router: - name: my_router default_flow: simple_flow elasticsearch: - name: dev enabled: true endpoint: http://localhost:9200 basic_auth: username: test password: testtest Note: 上面配置里面的 Elasticsearch 的相关配置，请改成实际的服务器连接地址和认证信息：\n启动网关 #  使用如下命令启动极限网关容器：\ndocker run -p 2900:2900 -p 8000:8000 -v=`pwd`/gateway.yml:/gateway.yml infinilabs/gateway:latest 验证网关 #  如果都运行正常的话，应该可以看到如下的信息：\n➜ /tmp docker run -p 2900:2900 -p 8000:8000 -v=`pwd`/gateway.yml:/gateway.yml infinilabs/gateway:latest ___ _ _____ __ __ __ _ / _ \\ /_\\ /__ \\/__\\/ / /\\ \\ \\/_\\ /\\_/\\ / /_\\///_\\\\ / /\\/_\\ \\ \\/ \\/ //_\\\\\\_ _/ / /_\\\\/ _ \\/ / //__ \\ /\\ / _ \\/ \\ \\____/\\_/ \\_/\\/ \\__/ \\/ \\/\\_/ \\_/\\_/ [GATEWAY] A light-weight, powerful and high-performance elasticsearch gateway. [GATEWAY] 1.0.0_SNAPSHOT, b61758c, Mon Dec 28 14:32:02 2020 +0800, medcl, no panic by default [12-30 05:26:41] [INF] [instance.go:24] workspace: data/gateway/nodes/0 [12-30 05:26:41] [INF] [runner.go:59] pipeline: primary started with 1 instances [12-30 05:26:41] [INF] [entry.go:257] entry [es_gateway] listen at: http://0.0.0.0:8000 [12-30 05:26:41] [INF] [app.go:247] gateway now started. [12-30 05:26:45] [INF] [reverseproxy.go:196] elasticsearch [prod] endpoints: [] =\u0026gt; [192.168.3.201:9200] 如果希望容器运行在后台，加上 -d 参数，如下：\ndocker run -d -p 2900:2900 -p 8000:8000 -v=`pwd`/gateway.yml:/gateway.yml infinilabs/gateway:latest 使用命令行或者浏览器访问地址： http://localhost:8000/ 应该就能正常访问 Elasticsearch 了，如下：\n➜ /tmp curl -v http://localhost:8000/ * Trying ::1... * TCP_NODELAY set * Connected to localhost (::1) port 8000 (#0) \u0026gt; GET / HTTP/1.1 \u0026gt; Host: localhost:8000 \u0026gt; User-Agent: curl/7.64.1 \u0026gt; Accept: */* \u0026gt; \u0026lt; HTTP/1.1 200 OK \u0026lt; Server: INFINI \u0026lt; Date: Wed, 30 Dec 2020 05:12:39 GMT \u0026lt; Content-Type: application/json; charset=UTF-8 \u0026lt; Content-Length: 480 \u0026lt; UPSTREAM: 192.168.3.201:9200 \u0026lt; { \u0026quot;name\u0026quot; : \u0026quot;node1\u0026quot;, \u0026quot;cluster_name\u0026quot; : \u0026quot;pi\u0026quot;, \u0026quot;cluster_uuid\u0026quot; : \u0026quot;Z_HcN_6ESKWicV-eLsyU4g\u0026quot;, \u0026quot;version\u0026quot; : { \u0026quot;number\u0026quot; : \u0026quot;6.4.2\u0026quot;, \u0026quot;build_flavor\u0026quot; : \u0026quot;default\u0026quot;, \u0026quot;build_type\u0026quot; : \u0026quot;tar\u0026quot;, \u0026quot;build_hash\u0026quot; : \u0026quot;04711c2\u0026quot;, \u0026quot;build_date\u0026quot; : \u0026quot;2018-09-26T13:34:09.098244Z\u0026quot;, \u0026quot;build_snapshot\u0026quot; : false, \u0026quot;lucene_version\u0026quot; : \u0026quot;7.4.0\u0026quot;, \u0026quot;minimum_wire_compatibility_version\u0026quot; : \u0026quot;5.6.0\u0026quot;, \u0026quot;minimum_index_compatibility_version\u0026quot; : \u0026quot;5.0.0\u0026quot; }, \u0026quot;tagline\u0026quot; : \u0026quot;You Know, for Search\u0026quot; } * Connection #0 to host localhost left intact * Closing connection 0 Docker Compose #  还可以使用 docker compose 来管理容器实例，新建一个 docker-compose.yml 文件如下：\nversion: \u0026quot;3.5\u0026quot; services: infini-gateway: image: infinilabs/gateway:latest ports: - 2900:2900 - 8000:8000 container_name: \u0026quot;infini-gateway\u0026quot; volumes: - ../gateway.yml:/gateway.yml volumes: dist: 在配置文件所在目录，执行如下命令即可启动，如下：\n➜ docker-compose up Starting infini-gateway ... done Attaching to infini-gateway infini-gateway | ___ _ _____ __ __ __ _ infini-gateway | / _ \\ /_\\ /__ \\/__\\/ / /\\ \\ \\/_\\ /\\_/\\ infini-gateway | / /_\\///_\\\\ / /\\/_\\ \\ \\/ \\/ //_\\\\\\_ _/ infini-gateway | / /_\\\\/ _ \\/ / //__ \\ /\\ / _ \\/ \\ infini-gateway | \\____/\\_/ \\_/\\/ \\__/ \\/ \\/\\_/ \\_/\\_/ infini-gateway | infini-gateway | [GATEWAY] A light-weight, powerful and high-performance elasticsearch gateway. infini-gateway | [GATEWAY] 1.0.0_SNAPSHOT, b61758c, Mon Dec 28 14:32:02 2020 +0800, medcl, no panic by default infini-gateway | [12-30 13:24:16] [INF] [instance.go:24] workspace: data/gateway/nodes/0 infini-gateway | [12-30 13:24:16] [INF] [api.go:244] api server listen at: http://0.0.0.0:2900 infini-gateway | [12-30 13:24:16] [INF] [runner.go:59] pipeline: primary started with 1 instances infini-gateway | [12-30 13:24:16] [INF] [entry.go:257] entry [es_gateway] listen at: http://0.0.0.0:8000 infini-gateway | [12-30 13:24:16] [INF] [app.go:247] gateway now started. "});index.add({'id':43,'href':'/docs/latest/console/reference/system/security/role/','title':"角色管理",'section':"安全设置",'content':"角色管理 #  简介 #  角色管理包括对角色的增删改查操作。 INFINI Console 内置了一个管理员角色，角色名为 Administrator, 该角色拥有所有的操作权限, 包括所有的平台权限和数据权限。 数据角色用于控制 elasticsearch 集群的访问权限, 包括 elasticsearch API 的访问权限， elasticsearch API 的列表可以在安装目录下的 config/permission.json 文件中配置。\n创建平台角色 #   输入唯一的角色名. 选择平台权限，不能为空. 按需输入角色描述 点击保存按钮保存  All 权限代表同时拥有读和写的权限, Read 代表只读权限, None 代表没有权限。\n创建数据角色 #   输入唯一的角色名. 选择一个或者多个集群， * 代表选择所有集群. 配置集群级别 API 权限, * 代表所有集群级别 API 权限. 配置索引级别 API 权限, * 代表所有索引级别 API 权限. 按需输入角色描述 点击保存按钮保存  查询角色 #  输入关键字点击搜索按钮查询角色。\n更新平台角色 #  按需修改角色，然后点击保存按钮保存。\n更新数据角色 #  按需修改角色，然后点击保存按钮保存。\n"});index.add({'id':44,'href':'/docs/latest/console/screenshot/','title':"系统截图",'section':"INFINI Console",'content':"系统截图 #  集群概览 #  集群动态 #  告警管理 #  集群监控 #  数据管理 #  命令工具 #  集群管理 #  安全设置 #  "});index.add({'id':45,'href':'/docs/latest/console/reference/system/security/','title':"安全设置",'section':"系统管理",'content':"安全设置 #  简介 #  INFINI Console Security 具有以下安全方面的能力和优势:\n 给不同的用户授权访问不同的平台功能 给不同的用户授权不同的 Elasticsearch 集群访问权限，权限粒度可以控制到索引级别和 Elasticsearch API 级别  INFINI Console Security 包含两种角色\n 平台角色，用于平台功能层面的权限控制 数据角色, 用于控制 Elasticsearch 集群数据的权限控制  INFINI Console Security 默认是开启的，如果需要关闭，可以修改 console.yml 配置文件中的 web\u0026gt;auth\u0026gt;enabled 配置,将其改为 false,如下所示：\nweb: enabled: true embedding_api: true auth: enabled: false ui: enabled: true path: .public vfs: true local: true network: binding: 0.0.0.0:9000 skip_occupied_port: true gzip: enabled: true  开启安全功能之后，需要用户密码登录 INFINI Console 。INFINI Console 内置了一个管理员账户，账户名和密码都为 admin 。\n "});index.add({'id':46,'href':'/docs/latest/console/reference/data/discover/','title':"数据探索",'section':"数据管理",'content':"数据探索 #  简介 #  在数据探索里，可以根据时间、字段等条件对索引或者视图下的数据进行搜索查询，数据展示方式有常规模式和Insight模式。\n搜索工具栏 #  索引(视图) #  搜索语句 #  时间范围 #  字段过滤 #  保存搜索 #  保存的搜索列表 #  Insight模式 #  Insight配置 #  常规模式 #  常规模式下用多功能图表灵活地添加字段来展示数据\n可对文档数据进行编辑、删除等操作\nInsight模式 #  Insight模式下会根据数据特征推送可视化图表来展示数据\n可通过推送列表添加图表\n可对图表进行编辑、删除\n"});index.add({'id':47,'href':'/docs/latest/gateway/user-cases/','title':"用户案例",'section':"INFINI Gateway",'content':"用户案例 #  谁在用? #  如果您正在使用 极限网关 并且您觉得还不错愿意告诉大家您也在用的话，请在这个 Github Discussion里留言告诉我们，感谢您的支持和鼓励。\n国内用户 #                              "});index.add({'id':48,'href':'/docs/latest/gateway/getting-started/optimization/','title':"系统调优",'section':"入门指南",'content':"系统调优 #  要保证极限网关运行在最佳状态，其所在服务器的操作系统也需要进行相应的调优，以 Linux 为例。\n系统参数 #  sudo tee /etc/security/limits.d/21-infini.conf \u0026lt;\u0026lt;-'EOF' * soft nofile 1048576 * hard nofile 1048576 * soft memlock unlimited * hard memlock unlimited root soft nofile 1048576 root hard nofile 1048576 root soft memlock unlimited root hard memlock unlimited EOF 内核调优 #  cat \u0026lt;\u0026lt; SETTINGS | sudo tee /etc/sysctl.d/70-infini.conf fs.file-max=10485760 fs.nr_open=10485760 vm.max_map_count=262144 net.core.somaxconn=65535 net.core.netdev_max_backlog=65535 net.core.rmem_default = 262144 net.core.wmem_default = 262144 net.core.rmem_max=4194304 net.core.wmem_max=4194304 net.ipv4.ip_forward = 1 net.ipv4.ip_nonlocal_bind=1 net.ipv4.ip_local_port_range = 1024 65535 net.ipv4.conf.default.accept_redirects = 0 net.ipv4.conf.default.rp_filter = 1 net.ipv4.conf.all.accept_redirects = 0 net.ipv4.conf.all.send_redirects = 0 net.ipv4.tcp_tw_reuse=1 net.ipv4.tcp_tw_recycle = 1 net.ipv4.tcp_max_tw_buckets = 300000 net.ipv4.tcp_timestamps=1 net.ipv4.tcp_syncookies=1 net.ipv4.tcp_max_syn_backlog=65535 net.ipv4.tcp_synack_retries=0 net.ipv4.tcp_keepalive_intvl = 30 net.ipv4.tcp_keepalive_time = 900 net.ipv4.tcp_keepalive_probes = 3 net.ipv4.tcp_fin_timeout = 10 net.ipv4.tcp_max_orphans = 131072 net.ipv4.tcp_rmem = 4096 4096 16777216 net.ipv4.tcp_wmem = 4096 4096 16777216 net.ipv4.tcp_mem = 786432 3145728 4194304 SETTINGS 执行下面的命令验证配置参数是否合法。\nsysctl -p 最后重启操作系统让配置生效。\n"});index.add({'id':49,'href':'/docs/latest/gateway/references/flow/','title':"处理流程",'section':"功能手册",'content':"处理流程 #  流程定义 #  每一个网关接收到的请求都会通过一系列的流程处理，最后才返回给客户端，流程的定义在极限网关里面叫做 flow，以下面的这个例子为例：\nflow: - name: hello_world filter: - echo: message: \u0026quot;hello gateway\\n\u0026quot; repeat: 1 - name: not_found filter: - echo: message: '404 not found\\n' repeat: 1 上面的例子定义了两个 flow hello_world 和 not_found， 每个 flow 都使用了一个名为 echo 的过滤器，用来输出一段字符串，每个 flow 下面可以定义一系列 filter，他们按照定义的顺序依次执行。\n语法说明 #  极限网关采用约定的格式来定义流程，并且支持灵活的条件参数来进行逻辑判断，具体的格式定义如下：\nflow: - name: \u0026lt;flow_name\u0026gt; filter: - \u0026lt;filter_name\u0026gt;: when: \u0026lt;condition\u0026gt; \u0026lt;parameters\u0026gt; - \u0026lt;filter_name\u0026gt;: when: \u0026lt;condition\u0026gt; \u0026lt;parameters\u0026gt; ... 上面的 filter_name 代表具体的某个过滤器名称，用来执行特定的任务，when 下面的 condition 用来定义特定的满足执行该任务的条件参数，不满足条件的情况下会跳过该过滤器任务的执行，parameters 里面设置的该过滤器相关的参数，如果多个参数依次换行即可。\n条件判断 #  极限网关的流程定义支持复杂的逻辑判断，可以让特定的过滤器只有在满足某种条件下才会执行，举例如下：\nfilter: - if: \u0026lt;condition\u0026gt; then: - \u0026lt;filter_name\u0026gt;: \u0026lt;parameters\u0026gt; - \u0026lt;filter_name\u0026gt;: \u0026lt;parameters\u0026gt; ... else: - \u0026lt;filter_name\u0026gt;: \u0026lt;parameters\u0026gt; - \u0026lt;filter_name\u0026gt;: \u0026lt;parameters\u0026gt; ... 参数说明 #     名称 类型 说明     then array 表示满足 condition 条件定义后才会执行的一系列过滤器定义   else array 不满足条件才会执行的一系列过滤器定义，可不设置    使用 if 可以对多个 filter 来进行条件判断进行逻辑选择，使用 when 来对单个过滤器进行判断是否执行。\n条件类型 #  在流程里面定义的各种 condition 条件可以使用当前 请求上下文 来判断是否满足特定条件，从而实现逻辑处理，支持布尔表达式（AND、NOT、OR）来进行组合，完整的条件类型如下：\n equals contains prefix suffix regexp range network has_fields in queue_has_lag consumer_has_lag cluster_available or and not  equals #  使用 equals 条件来判断字段的内容是否为指定的值，用于字符和数字类型的精确匹配。\n如下面的例子判断是否请求的方法是否为 GET 类型，_ctx 是访问请求上下文的特定关键字：\nequals: _ctx.request.method: GET contains #  使用 contains 条件来判断字段的内容是否包含特定的字符值，仅支持字符字段类型。\n如下面的例子为判断返回的请求体里面是否包含错误关键字：\ncontains: _ctx.response.body: \u0026quot;error\u0026quot; prefix #  使用 prefix 条件来判断字段的内容是否由特定的字符值开头，仅支持字符字段类型。\n如下面的例子为判断返回的请求路径为特定索引名称开头：\nprefix: _ctx.request.path: \u0026quot;/filebeat\u0026quot; suffix #  使用 suffix 条件来判断字段的内容是否由特定的字符值结尾，仅支持字符字段类型。\n如下面的例子为判断返回的请求是否为搜索请求：\nsuffix: _ctx.request.path: \u0026quot;/_search\u0026quot; regexp #  使用 regexp 条件可以用来判断某个字段的内容是否满足正则表达式的匹配规则，仅支持字符字段类型。\n如下面的例子判断请求的 uri 是否为查询请求：\nregexp: _ctx.request.uri: \u0026quot;.*/_search\u0026quot; range #  使用 range 条件用来判断字段的值是否满足特定的范围，支持 lt、lte、gt 和 gte 几种类型，仅支持数字字段类型。\n如下面判断状态码范围的例子：\nrange: _ctx.response.code: gte: 400 以及如下组合来判断响应字节大小范围的例子：\nrange: _ctx.request.body_length.gte: 100 _ctx.request.body_length.lt: 5000 network #  如果某个字段的值为 IP 字段类型，可以使用 network 条件可以判断该字段是否满足某个特定的网络范围，支持标准的 IPv4 和 IPv6，支持 CIDR 的表达方式，或者是以下范围别名：\n   名称 说明     loopback 匹配本地回环网络地址，范围：127.0.0.0/8 或者 ::1/128。   unicast 匹配 RFC 1122、RFC 4632 和 RFC 4291 中定义的全球单播地址，但 IPv4 广播地址 (255.255.255.255) 除外。包括私有地址范围。   multicast 匹配广播地址。   interface_local_multicast 匹配 IPv6 接口本地组播地址。   link_local_unicast 匹配链路本地单播地址。   link_local_multicast 匹配链路本地广播地址。   private 匹配 RFC 1918 (IPv4) 和 RFC 4193 (IPv6) 中定义的私有地址范围。   public 匹配除了本机、未指定、IPv4 广播、链路本地单播、链路本地多播、接口本地多播或私有地址以外的公网地址。   unspecified 匹配未指定的地址（IPv4 地址 0.0.0.0 或 IPv6 地址 :: ）。    如下面的例子匹配本机网络地址：\nnetwork: _ctx.request.client_ip: private 或者指定一个子网：\nnetwork: _ctx.request.client_ip: '192.168.3.0/24' 支持数组，任意满足即可：\nnetwork: _ctx.request.client_ip: ['192.168.3.0/24', '10.1.0.0/8', loopback] has_fields #  如果要判断某个字段是否存在，可以使用 has_fields，支持一个或者多个字符字段，如下：\nhas_fields: ['_ctx.request.user'] in #  如果要判断某个字段是否存在指定数组的任意值，可以使用 in，支持单个字段的判断，仅支持字符和数值类型。\n如下判断返回状态码：\nin: _ctx.response.status: [ 403,404,200,201 ] queue_has_lag #  使用 queue_has_lag 可以来判断某个或多个本地磁盘队列是否存在堆积的情况，如下：\nqueue_has_lag: [ \u0026quot;prod\u0026quot;, \u0026quot;prod-500\u0026quot; ] 如果希望设置队列大于指定深度可以在队列的名称后面加上 \u0026gt;队列深度，如：\nqueue_has_lag: [ \u0026quot;prod\u0026gt;10\u0026quot;, \u0026quot;prod-500\u0026gt;10\u0026quot; ] 上面的例子表示，只有当队列深度超过 10 的情况下才满足条件。\nconsumer_has_lag #  使用 consumer_has_lag 可以来判断某个队列的消费者是否存在延迟堆积的情况，如下：\nconsumer_has_lag: queue: \u0026quot;primary-partial-success_bulk_requests\u0026quot; group: \u0026quot;my-group\u0026quot; name: \u0026quot;my-consumer-1\u0026quot; cluster_available #  使用 cluster_available 可以判断某个或多个 Elasticsearch 集群的服务可用性，如下：\ncluster_available: [\u0026quot;prod\u0026quot;] or #  使用 or 来组合多个任意可选条件，格式如下：\nor: - \u0026lt;condition1\u0026gt; - \u0026lt;condition2\u0026gt; - \u0026lt;condition3\u0026gt; ... 举例如下：\nor: - equals: _ctx.response.code: 304 - equals: _ctx.response.code: 404 and #  使用 and 来组合多个必要条件，格式如下：\nand: - \u0026lt;condition1\u0026gt; - \u0026lt;condition2\u0026gt; - \u0026lt;condition3\u0026gt; ... 举例如下：\nand: - equals: _ctx.response.code: 200 - equals: _ctx.status: OK 还可以对 and 和 or 条件进行灵活组合，如下：\nor: - \u0026lt;condition1\u0026gt; - and: - \u0026lt;condition2\u0026gt; - \u0026lt;condition3\u0026gt; not #  如果要对某个条件取反，使用 not 即可，格式如下：\nnot: \u0026lt;condition\u0026gt; 举例如下：\nnot: equals: _ctx.status: OK "});index.add({'id':50,'href':'/docs/latest/console/reference/system/security/settings/','title':"安全设置",'section':"安全设置",'content':"安全设置 #  禁用内置用户 #  当开启安全的之后，在没有指定用户和密码的情况下启动 console ，系统会有一个 默认的内置用户 admin。当添加新的拥有管理员权限的用户之后，可以将内置用户禁用。\n 不能使用内置用户禁用自己  "});index.add({'id':51,'href':'/docs/latest/console/user-cases/','title':"用户案例",'section':"INFINI Console",'content':"用户案例 #  谁在用? #  如果您正在使用 INFINI Console 并且您觉得还不错愿意告诉大家您也在用的话，请在这个 Github Discussion里留言告诉我们，感谢您的支持和鼓励。\n国内用户 #            "});index.add({'id':52,'href':'/docs/latest/gateway/references/elasticsearch/','title':"Elasticsearch",'section':"功能手册",'content':"Elasticsearch #  定义资源 #  极限网关支持多集群的访问，支持不同的版本，每个集群作为一个 Elasticsearch 后端资源，可以后续被极限网关的多个地方使用，以下面的这个例子为例：\nelasticsearch: - name: local enabled: true endpoint: https://127.0.0.1:9200 - name: dev enabled: true endpoint: https://192.168.3.98:9200 basic_auth: username: elastic password: pass - name: prod enabled: true endpoint: http://192.168.3.201:9200 discovery: enabled: true refresh: enabled: true interval: 10s basic_auth: username: elastic password: pass 上面的例子定义了一个名为 local 的本地开发测试集群，和一个名为 dev 的开发集群。开发集群开启了身份验证，这里也定义了相应的用户名和密码。 最后还定义了一个名为 prod 的生产集群，并且通过参数 discovery 开启了集群的节点拓扑自动发现和更新。\n参数说明 #     名称 类型 说明     name string Elasticsearch 集群名称   project string 项目名称   location.provider string 集群提供商   location.region string 集群所在可用区   location.dc string 集群所在数据中心   location.rack string 集群所在机架   labels map 集群自定义标签   tags array 集群自定义标签   enabled bool 是否启用   endpoint string Elasticsearch 访问地址，如: http://localhost:9200   endpoints array Elasticsearch 访问地址列表，支持多个入口地址，用于冗余   schema string 协议类型，http 或者 https   host string Elasticsearch 主机，格式：localhost:9200，host 和 endpoint 任意选择一种配置方式即可   hosts array Elasticsearch 主机列表，支持多个入口地址，用于冗余   request_timeout int 请求超时时间，单位秒，默认 30   request_compress bool 是否开启 Gzip 压缩   basic_auth object 身份认证信息   basic_auth.username string 用户名   basic_auth.password string 密码   discovery object 集群发现设置   discovery.enabled bool 是否启用集群拓扑发现   discovery.refresh object 集群拓扑更新设置   discovery.refresh.enabled bool 是否启用集群拓扑自动更新   discovery.refresh.interval string 集群拓扑自动更新时间间隔   traffic_control object 集群按节点级别的总体流量控制   traffic_control.max_bytes_per_node int 最大允许的每秒请求字节数   traffic_control.max_qps_per_node int 最大允许的每秒请求次数，不区分读写   traffic_control.max_connection_per_node int 最大允许的主机连接数   traffic_control.max_wait_time_in_ms int 如遇限速, 最大允许的等待时间,默认 10000   allow_access_when_master_not_found bool 当集群出现 master_not_discovered_exception 异常后，任然允许转发请求到该集群，默认为 false    "});index.add({'id':53,'href':'/docs/latest/gateway/references/context/','title':"请求上下文",'section':"功能手册",'content':"请求上下文 #  什么是上下文 #  上下文是极限网关用来访问当前运行环境下相关信息的入口，如请求的来源和配置信息等等，使用关键字 _ctx 即可访问相应的字段，如：_ctx.request.uri 表示请求的 URL 地址。\n内置请求上下文 #  HTTP 请求内置的 _ctx 上下文对象主要包括如下：\n   名称 类型 说明     id uint64 请求的唯一 ID   tls bool 表示请求是否 TLS   remote_ip string 客户端来源 IP   remote_addr string 客户端来源地址，包含端口   local_ip string 网关本地 IP   local_addr string 网关本地地址，包含端口   elapsed int64 请求已执行时间（毫秒）   request.* object 描述请求信息   response.* object 描述响应信息    request #  request 对象包含以下属性：\n   名称 类型 说明     to_string string 文本格式的 HTTP 完整请求信息   host string 访问的目标主机名/域名   method string 请求类型   uri string 请求完整地址   path string 请求路径   query_args map Url 请求参数   username string 发起请求的用户名   password string 发起请求的密码信息   header map Header 参数   body string 请求体   body_json object JSON 请求体对象   body_length int 请求体长度    如果客户端提交的请求体数据类型是 JSON 格式，可以通过 body_json 来直接访问，举例如下：\ncurl -u tesla:password -XGET \u0026quot;http://localhost:8000/medcl/_search?pretty\u0026quot; -H 'Content-Type: application/json' -d' { \u0026quot;query\u0026quot;:{ \u0026quot;bool\u0026quot;:{ \u0026quot;must\u0026quot;:[{\u0026quot;match\u0026quot;:{\u0026quot;name\u0026quot;:\u0026quot;A\u0026quot;}},{\u0026quot;match\u0026quot;:{\u0026quot;age\u0026quot;:18}}] }\t}, \u0026quot;size\u0026quot;:900, \u0026quot;aggs\u0026quot;: { \u0026quot;total_num\u0026quot;: { \u0026quot;terms\u0026quot;: { \u0026quot;field\u0026quot;: \u0026quot;name1\u0026quot;, \u0026quot;size\u0026quot;: 1000000 } } } }' 在 JSON 里面通过 . 来标识路径，如果是数组则使用 [下标] 来访问指定的元素，比如可以使用一个 dump 过滤器来进行调试，如下：\n - name: cache_first filter: - dump: context: - _ctx.request.body_json.size - _ctx.request.body_json.aggs.total_num.terms.field - _ctx.request.body_json.query.bool.must.[1].match.age 输出结果如下：\n_ctx.request.body_json.size : 900 _ctx.request.body_json.aggs.total_num.terms.field : name1 _ctx.request.body_json.query.bool.must.[1].match.age : 18 response #  response 对象包含以下属性：\n   名称 类型 说明     to_string string 文本格式的 HTTP 完整响应信息   status int 请求状态码   header map Header 参数   content_type string 响应请求体类型   body string 响应体   body_length int 响应体长度    "});index.add({'id':54,'href':'/docs/latest/console/tutorials/cluster_slow_request/','title':"如何监控 Elasticsearch 里面的慢查询请求",'section':"动手教程",'content':"如何监控 Elasticsearch 里面的慢查询请求 #  简介 #  很多时候，Elasticsearch 集群会出现数据写入或者查询流量高峰期的情况，这个时候 Elasticsearch 集群压力会很大，通过对 Elasticsearch 索引查询的延迟的监控告警。 可以让我们定位 Elasticsearch 集群的压力主要集中在哪些索引。本文将介绍如何使用 INFINI Console 告警功能监控 Elasticsearch 里面的慢查询请求索引。\n准备 #   下载并安装最新版 INFINI Console 使用INFINI Console 注册 Elasticsearch 集群  创建告警规则 #  在浏览器中打开 INFINI Console, 点击左侧菜单 告警管理》规则管理 进入告警管理页，然后点击 新建按钮进入创建告警规则页。按以下步骤创建告警规则：\n 选择集群（这里需要选择 INFINI Console 存储数据的 Elasticsearch 集群，也就是在配置文件 console.yml 配置的 Elasticsearch 集群，如果没有注册到 INFINI Console , 请先注册） 输入告警对象 .infini_metrics*（选择 Elasticsearch 集群下的索引，或者输入索引 pattern, 这里因为 INFINI Console 采集的监控数据存放在索引 .infini_metrics 里面） 输入筛选条件（ Elasticsearch 查询 DSL ） 这里我们需要过滤监控指标类别为 index_stats，并且索引名称不能为 _all, DSL 如下：  { \u0026quot;bool\u0026quot;: { \u0026quot;must\u0026quot;: [ { \u0026quot;term\u0026quot;: { \u0026quot;metadata.name\u0026quot;: { \u0026quot;value\u0026quot;: \u0026quot;index_stats\u0026quot; } } }, { \u0026quot;term\u0026quot;: { \u0026quot;metadata.category\u0026quot;: { \u0026quot;value\u0026quot;: \u0026quot;elasticsearch\u0026quot; } } } ], \u0026quot;must_not\u0026quot;: [ { \u0026quot;term\u0026quot;: { \u0026quot;metadata.labels.index_name\u0026quot;: { \u0026quot;value\u0026quot;: \u0026quot;_all\u0026quot; } } } ] } }  选择时间字段 timestamp 和统计周期用于做 date histogram 聚合   输入规则名称 分组设置（可选，可配置多个），当统计指标需要分组的时候设置，由于所有注册到 INFINI Console 的 Elasticsearch 集群监控指标都存储在索引 .infini_metrics 里面，所以需要先根据集群 ID 分组，然后再根据索引名称分组， 这里我们选择 metadata.labels.cluster_id 和 metadata.labels.index_name 配置告警指标，选择聚合字段 payload.elasticsearch.index_stats.total.search.query_time_in_millis，统计方法求导 derivative。然后再添加一个告警指标，选择聚合字段 payload.elasticsearch.index_stats.total.search.query_total，统计方法 derivative。 配置指标公式（当配置了一个以上的告警指标的时候，需要设置一个公式来计算目标指标），这里公式 fx 配置为 a/b来计算延时， 配置告警条件，这里配置三个告警条件，配置 持续一个周期 延时 大于 100 的时候，触发 P3(Low) 告警; 配置 持续一个周期 延时 大于 500 的时候，触发 P1(High) 告警; 配置 持续一个周期 延时 大于 1000 的时候，触发 P0(Critical) 告警; 设置执行周期，这里配置一分钟执行一次检查 设置事件标题，事件标题是一个模版，可以使用模版变量，模版语法及模版变量用法参考 这里 设置事件内容，事件内容是一个模版，可以使用模版变量，模版语法及模版变量用法参考 这里  Priority:{{.priority}} Timestamp:{{.timestamp | datetime_in_zone \u0026quot;Asia/Shanghai\u0026quot;}} RuleID:{{.rule_id}} EventID:{{.event_id}} {{range .results}} ClusterID:{{index .group_values 0}}; Index name:{{index .group_values 1}}; Current value:{{.result_value | to_fixed 2}}ms; {{end}}  打开配置告警渠道开关，选择右上角 add 快速选择一个告警渠道模版填充，关于怎么创建告警渠道模版请参考 这里 设置沉默周期 1 小时，即触发告警规则后，一个小时内只发送通知消息一次 设置接收时段，默认 00:00-23:59 ，即全天都可接收通知消息  设置完成之后点击保存按钮提交。\n收到告警通知消息 #  等待一会儿，收到钉钉告警消息通知如下：\n可以看到告警通知消息里面显示了查询延时过高的 Elasticsearch 集群 ID，索引名称, 延时大小。\n查看告警消息中心 #  除了会收到外部通知消息外，INFINI Console 告警消息中心也会生成一条告警消息。点击菜单 告警管理》告警中心进入\n小结 #  通过使用 INFINI Console 告警功能， 可以很方便地监控 Elasticsearch 集群慢索引。配置告警规则之后， 一旦有任何 Elasticsearch 索引查询延时过高，都会触发告警并发送告警消息。\n"});index.add({'id':55,'href':'/docs/latest/console/tutorials/cluster_health_change/','title':"如何监控 Elasticsearch 集群健康状态",'section':"动手教程",'content':"如何监控 Elasticsearch 集群健康状态 #  简介 #  很多时候 Elasticsearch 集群会因为某些原因，集群健康状态会变为红色，这个时候 Elasticsearch 集群至少存在一个主分片未分配或者丢失。所以监控 Elasticsearch 集群 健康状态是很有必要的。本文将介绍如何使用 INFINI Console 告警功能监控 Elasticsearch 集群 健康状态。\n准备 #   下载并安装最新版 INFINI Console 使用INFINI Console 注册 Elasticsearch 集群  创建告警规则 #  在浏览器中打开 INFINI Console, 点击左侧菜单 告警管理》规则管理 进入告警管理页，然后点击 新建按钮进入创建告警规则页。按以下步骤创建告警规则：\n 选择集群（这里需要选择 INFINI Console 存储数据的 Elasticsearch 集群，也就是在配置文件 console.yml 配置的 Elasticsearch 集群，如果没有注册到 INFINI Console , 请先注册） 选择告警对象 .infini_metrics（选择 Elasticsearch 集群下的索引，或者输入索引 pattern, 这里因为 INFINI Console 采集的监控数据存放在索引 .infini_metrics 里面） 输入筛选条件（ Elasticsearch 查询 DSL ） 这里我们需要过滤监控指标类别为 cluster_health，并且健康状态为红色的数据，DSL 如下：  { \u0026quot;bool\u0026quot;: { \u0026quot;must\u0026quot;: [ { \u0026quot;match\u0026quot;: { \u0026quot;payload.elasticsearch.cluster_health.status\u0026quot;: \u0026quot;red\u0026quot; } }, { \u0026quot;term\u0026quot;: { \u0026quot;metadata.name\u0026quot;: { \u0026quot;value\u0026quot;: \u0026quot;cluster_health\u0026quot; } } } ] } }  选择时间字段和统计周期用于做 date histogram 聚合   输入规则名称 分组设置（可选，可配置多个），当统计指标需要分组的时候设置，由于所有注册到 INFINI Console 的 Elasticsearch 集群监控指标都存储在索引 .infini_metrics 里面，所以需要根据集群 ID 分组， 这里我们选择 metadata.labels.cluster_id 配置告警指标，选择聚合字段 payload.elasticsearch.cluster_health.status，统计方法 count 配置告警条件，配置 持续一个周期 聚合结果 大于等于 1，即触发 Critical 告警 设置执行周期，这里配置一分钟执行一次检查 设置事件标题，事件标题是一个模版，可以使用模版变量，模版语法及模版变量用法参考 这里 设置事件内容，事件内容是一个模版，可以使用模版变量，模版语法及模版变量用法参考 这里   打开配置告警渠道开关，选择右上角 add 快速选择一个告警渠道模版填充，关于怎么创建告警渠道模版请参考 这里 设置沉默周期 1 小时，即触发告警规则后，一个小时内只发送通知消息一次 设置接收时段，默认 00:00-23:59 ，即全天都可接收通知消息  设置完成之后点击保存按钮提交。\n模拟触发告警规则 #  打开 INFINI Console 开发工具（Ctrl+Shift+O），输入如下图所示命令：\n收到告警通知消息 #  等待一分钟左右，收到钉钉告警消息通知如下：\n可以看到告警通知消息里面显示了健康状态变红的 Elasticsearch 集群 ID，点击消息下方的链接查看告警详细信息如下：\n查看告警消息中心 #  除了会收到外部通知消息外，INFINI Console 告警消息中心也会生成一条告警消息。点击菜单 告警管理》告警中心进入\n小结 #  通过使用 INFINI Console 告警功能， 可以很方便地监控 Elasticsearch 集群健康状态。配置告警规则之后， 一旦有任何 Elasticsearch 集群状态变红，都会触发告警并发送告警消息。\n"});index.add({'id':56,'href':'/docs/latest/console/tutorials/cluster_node_disk_usage/','title':"如何监控 Elasticsearch 集群节点磁盘使用率",'section':"动手教程",'content':"如何监控 Elasticsearch 集群节点磁盘使用率 #  简介 #  当系统磁盘使用率过高时，Elasticsearch 集群会出现数据写入不进去的情况，这样很可能导致数据丢失，所以监控 Elasticsearch 集群 节点磁盘使用率是很有必要的。本文将介绍如何使用 INFINI Console 告警功能监控 Elasticsearch 集群 节点磁盘的使用率。\n准备 #   下载并安装最新版 INFINI Console 使用INFINI Console 注册 Elasticsearch 集群  创建告警规则 #  在浏览器中打开 INFINI Console, 点击左侧菜单 告警管理》规则管理 进入告警管理页，然后点击 新建按钮进入创建告警规则页。按以下步骤创建告警规则：\n 选择集群（这里需要选择 INFINI Console 存储数据的 Elasticsearch 集群，也就是在配置文件 console.yml 配置的 Elasticsearch 集群，如果没有注册到 INFINI Console , 请先注册） 输入告警对象 .infini_metrics*（选择 Elasticsearch 集群下的索引，或者输入索引 pattern, 这里因为 INFINI Console 采集的监控数据存放在索引 .infini_metrics 里面） 输入筛选条件（ Elasticsearch 查询 DSL ） 这里我们需要过滤监控指标类别为 node_stats，DSL 如下：  { \u0026quot;bool\u0026quot;: { \u0026quot;must\u0026quot;: [ { \u0026quot;term\u0026quot;: { \u0026quot;metadata.name\u0026quot;: { \u0026quot;value\u0026quot;: \u0026quot;node_stats\u0026quot; } } } ] } }  选择时间字段 timestamp 和统计周期用于做 date histogram 聚合   输入规则名称 分组设置（可选，可配置多个），当统计指标需要分组的时候设置，由于所有注册到 INFINI Console 的 Elasticsearch 集群监控指标都存储在索引 .infini_metrics 里面，所以需要先根据集群 ID 分组，然后再根据节点 ID 分组， 这里我们选择 metadata.labels.cluster_id 和 metadata.labels.node_id 配置告警指标，选择聚合字段 payload.elasticsearch.node_stats.fs.total.free_in_bytes，统计方法 avg。然后再添加一个告警指标，选择聚合字段 payload.elasticsearch.node_stats.fs.total.total_in_bytes，统计方法 avg。 配置指标公式（当配置了一个以上的告警指标的时候，需要设置一个公式来计算目标指标），这里公式 fx 配置为 ((b-a)/b)*100，意思是先用总的磁盘空间减去剩余磁盘空间得到磁盘的已使用空间， 然后用磁盘的已使用空间除以总的磁盘空间再乘以 100，得到磁盘的使用率 配置告警条件，这里配置三个告警条件，配置 持续一个周期 磁盘使用率 大于 80 的时候，触发 P2(Medium) 告警; 配置 持续一个周期 磁盘使用率 大于 90 的时候，触发 P1(High) 告警; 配置 持续一个周期 磁盘使用率 大于 95 的时候，触发 P0(Critical) 告警; 设置执行周期，这里配置一分钟执行一次检查 设置事件标题，事件标题是一个模版，可以使用模版变量，模版语法及模版变量用法参考 这里 设置事件内容，事件内容是一个模版，可以使用模版变量，模版语法及模版变量用法参考 这里  Priority:{{.priority}} Timestamp:{{.timestamp | datetime}} RuleID:{{.rule_id}} EventID:{{.event_id}} {{range .results}} ClusterID：{{index .group_values 0}} ; NodeID：{{index .group_values 1}} ; Disk Usage:{{.result_value | to_fixed 2}}%； Free Storage:{{.relation_values.a | format_bytes 2}}； {{end}}  打开配置告警渠道开关，选择右上角 add 快速选择一个告警渠道模版填充，关于怎么创建告警渠道模版请参考 这里 设置沉默周期 1 小时，即触发告警规则后，一个小时内只发送通知消息一次 设置接收时段，默认 00:00-23:59 ，即全天都可接收通知消息  设置完成之后点击保存按钮提交。\n收到告警通知消息 #  等待一会儿，收到钉钉告警消息通知如下：\n可以看到告警通知消息里面显示了磁盘使用率过高的 Elasticsearch 集群 ID，节点 ID, 磁盘剩余空间。\n查看告警消息中心 #  除了会收到外部通知消息外，INFINI Console 告警消息中心也会生成一条告警消息。点击菜单 告警管理》告警中心进入\n小结 #  通过使用 INFINI Console 告警功能， 可以很方便地监控 Elasticsearch 集群节点磁盘使用率。配置告警规则之后， 一旦有任何 Elasticsearch 节点磁盘使用率超过设定的阈值就会触发告警并发送告警消息。\n"});index.add({'id':57,'href':'/docs/latest/console/troubleshooting/','title':"常见问题",'section':"INFINI Console",'content':"常见问题及故障处理 #  这里主要收集 INFINI Console 使用过程中遇到的常见问题及处理办法，欢迎反馈提交到 这里。\n常见问题 #  Elasticsearch 前面加上 Nginx，平台提示 400 错误 #  类似错误日志如下：\n[11-25 18:26:58] [TRC] [v0.go:390] search response: {\u0026quot;query\u0026quot;:{\u0026quot;match\u0026quot;:{\u0026quot;status\u0026quot;: \u0026quot;RUNNING\u0026quot;}}},\u0026lt;!DOCTYPE html\u0026gt; \u0026lt;title\u0026gt;Error 400 (Bad Request)!!1\u0026lt;/title\u0026gt; \u0026lt;p\u0026gt;\u0026lt;b\u0026gt;400.\u0026lt;/b\u0026gt; \u0026lt;ins\u0026gt;That’s an error.\u0026lt;/ins\u0026gt; \u0026lt;p\u0026gt;Your client has issued a malformed or illegal request. \u0026lt;ins\u0026gt;That’s all we know.\u0026lt;/ins\u0026gt; [11-25 18:26:58] [ERR] [init.go:87] json: invalid character '\u0026lt;' looking for beginning of value: \u0026lt;!DOCTYPE html\u0026gt; \u0026lt;html lang=en\u0026gt; 问题描述 #  Nginx 对于 GET 请求类型，不支持传递请求体\n解决方案 #  将 INFINI Console 升级最新版本。\n注册集群后监控数据不显示 #  如下如所示：\n问题描述 #  INFINI Console 需要用到 Elasticsearch 7.0 以上版本的一些特性\n解决方案 #  将 INFINI Console 存储数据的 ES 集群版本升级到 v7.0+\n启动报错 #  [03-23 08:38:20] [ERR] [metadata.go:529] {\u0026quot;error\u0026quot;:{\u0026quot;root_cause\u0026quot;:[{\u0026quot;type\u0026quot;:\u0026quot;illegal_argument_exception\u0026quot;,\u0026quot;reason\u0026quot;:\u0026quot;Can't merge a non object mapping [payload.node_state.settings.http.type] with an object mapping [payload.node_state.settings.http.type]\u0026quot;}],\u0026quot;type\u0026quot;:\u0026quot;illegal_argument_exception\u0026quot;,\u0026quot;reason\u0026quot;:\u0026quot;Can't merge a non object mapping [payload.node_state.settings.http.type] with an object mapping [payload.node_state.settings.http.type]\u0026quot;},\u0026quot;status\u0026quot;:400} 或者出现错误\n[04-16 09:45:06] [ERR] [schema.go:144] error on update mapping: {\u0026quot;root_cause\u0026quot;:[{\u0026quot;type\u0026quot;:\u0026quot;mapper_parsing_exception\u0026quot;,\u0026quot;reason\u0026quot;:\u0026quot;Failed to parse mapping [_doc]: analyzer [suggest_text_search] has not been configured in mappings\u0026quot;}],\u0026quot;type\u0026quot;:\u0026quot;mapper_parsing_exception\u0026quot;,\u0026quot;reason\u0026quot;:\u0026quot;Failed to parse mapping [_doc]: analyzer [suggest_text_search] has not been configured in mappings\u0026quot;,\u0026quot;caused_by\u0026quot;:{\u0026quot;type\u0026quot;:\u0026quot;illegal_argument_exception\u0026quot;,\u0026quot;reason\u0026quot;:\u0026quot;analyzer [suggest_text_search] has not been configured in mappings\u0026quot;}} 问题描述 #  版本 v0.3 修改了模板和 Mapping，如果升级之前未手动更新模板，旧索引已经存在且 Mapping 不是期望的 object 类型，会提示字段冲突或者分析器找不到。\n关于升级，请参考 升级说明\n解决方案 #   停止 INFINI Console 删除索引模板 .infini  DELETE _template/.infini  删除索引 .infini_node 和 .infini_index  DELETE .infini_node DELETE .infini_index  启动 INFINI Console  "});index.add({'id':58,'href':'/docs/latest/gateway/troubleshooting/','title':"常见问题",'section':"INFINI Gateway",'content':"常见问题及故障处理 #  这里主要收集极限网关使用过程中遇到的常见问题及处理办法，欢迎反馈提交到 这里 。\n常见问题 #  服务启动不了 #  问题描述: 安装系统服务但是启动失败 问题解答: 服务失败的原因有很多，为了帮助我们快速定位问题，请尝试执行 journalctl -xeu gateway、dmesg、tail -n 1000 /var/log/syslog 命令来获取服务启动的相关失败日志信息，同时提供配置文件、程序版本信息， 并在 这里 反馈给我们。\n配置里面 Elasticsearch 的身份信息 #  问题描述：我看到在配置 Elasticsearch 的时候，需要指定用户信息，有什么用，可以不配么？ 问题解答：极限网关是透明网关，使用网关之前是怎么传的参数，在替换为网关之后，还是照样传，比如身份信息还是需要传递。 网关配置里面的身份信息主要用于获取集群的内部运行状态和元数据，一些异步的操作或需要由网关来进行集群的操作也需要使用到该身份信息，比如记录指标和日志。\n写入速度没有提升 #  问题描述：为什么我用了极限网关的 bulk_reshuffle，写入速度没有提升呢？\n问题解答：如果你的集群节点总数太少，比如低于 10 个数据节点或者索引吞吐低于 15w/s，你可能没有必要使用这个功能或者关注点不应该在写入性能上面， 因为集群规模太小，Elasticsearch 因为转发性能和请求分发造成的影响不是特别明显，走不走网关理论上性能不会差距很大。 当然使用 bulk_reshuffle 还有其他好处，比如数据先落地网关队列可以解耦后端 Elasticsearch 故障的影响。\nElasticsearch 401 错误 #  问题描述：访问网关提升身份验证失败 问题解答：极限网关是透明网关，在网关配置里面的身份信息仅用于网关和 Elasticsearch 的通信，客户端通过网关来访问 Elasticsearch 任然需要传递适当的身份信息。\n常见故障 #  端口重用不支持的问题 #  错误提示：The OS doesn\u0026rsquo;t support SO_REUSEPORT: cannot enable SO_REUSEPORT: protocol not available\n问题描述：极限网关默认开启端口重用，用于多进程共享端口，在旧版本的 Linux 内核中需要打补丁才能使用。\n解决方案：可以通过修改监听网络的配置，将 reuse_port 改成 false，关闭端口重用：\n**. network: binding: 0.0.0.0:xx reuse_port: false Elasticsearch 用户权限不够 #  错误提示：[03-10 14:57:43] [ERR] [app.go:325] shutdown: json: cannot unmarshal object into Go value of type []adapter.CatIndexResponse\n问题描述：极限网关 Elasticsearch 配置开启 discovery 的情况下，如果用户权限给的不够，会提示这个错误，因为需要访问相关的 Elasticsearch API 来获取集群的信息。\n解决方案：给相关的 Elasticsearch 用户赋予所有索引的 monitor 和 view_index_metadata 权限即可。\n"});index.add({'id':59,'href':'/docs/latest/gateway/getting-started/benchmark/','title':"性能测试",'section':"入门指南",'content':"性能测试 #  推荐使用 Elasticsearch 专属压测工具 Loadgen 来对网关进行性能压测。\nLoadgen 的特点：\n 性能强劲 轻量级无依赖 支持模板化参数随机 支持高并发 支持压测端均衡流量控制   下载地址： http://release.infinilabs.com/loadgen/\n Loadgen #  Loadgen 使用非常简单，下载解压之后会得到两个文件，一个可执行程序和一个配置文件 loadgen.yml，配置文件样例如下：\nvariables: - name: ip type: file path: test/ip.txt - name: user type: file path: test/user.txt - name: id type: sequence - name: uuid type: uuid - name: now_local type: now_local - name: now_utc type: now_utc - name: now_unix type: now_unix requests: - request: method: GET basic_auth: username: elastic password: pass url: http://localhost:8000/medcl/_search body: '{ \u0026quot;query\u0026quot;: {\u0026quot;match\u0026quot;: { \u0026quot;name\u0026quot;: \u0026quot;$[[user]]\u0026quot; }}}' 变量的使用 #  上面的配置中，variables 用来定义变量参数，根据 name 来设置变量标识，在构造请求的使用 $[[变量名]] 即可访问该变量的值，变量目前支持的类型有：\n   类型 说明     file 文件型外部变量参数   sequence 自增数字类型的变量   range 数字范围类型的变量，支持参数 from 和 to 来限制范围   uuid UUID 字符类型的变量   now_local 当前时间、本地时区   now_utc 当前时间、UTC 时区   now_unix 当前时间、Unix 时间戳   now_with_format 当前时间，支持自定义 format 参数来格式化时间字符串，如：2006-01-02T15:04:05-0700    file 类型变量参数加载自外部文本文件，每行一个变量参数，访问该变量时每次随机取其中一个，变量里面的定义格式举例如下：\n➜ loadgen git:(master) ✗ cat test/user.txt medcl elastic 附生成固定长度的随机字符串，如 1024 个字符每行：\nLC_CTYPE=C tr -dc A-Za-z0-9_\\!\\@\\#\\$\\%\\^\\\u0026amp;\\*\\(\\)-+= \u0026lt; /dev/random | head -c 1024 \u0026gt;\u0026gt; 1k.txt 请求的定义 #  配置节点 requests 用来设置 Loadgen 将依次执行的请求，支持固定参数的请求，也可支持模板变量参数化构造请求，以下是一个普通的查询请求：\nrequests: - request: method: GET basic_auth: username: elastic password: pass url: http://localhost:8000/medcl/_search?q=name:$[[user]] 上面的查询对 medcl 索引进行了查询，并对 name 字段执行一个查询，每次请求的值来自随机变量 user。\n命令行参数 #  Loadgen 会循环执行配置文件里面定义的请求，默认 Loadgen 只会运行 5s 就自动退出了，如果希望延长运行时间或者加大并发可以通过启动的时候设置参数来控制，通过查看帮助命令如下：\n➜ loadgen git:(master) ✗ ./bin/loadgen --help Usage of ./bin/loadgen: -c int Number of concurrent threads (default 1) -compress Compress requests with gzip -config string the location of config file, default: loadgen.yml (default \u0026quot;loadgen.yml\u0026quot;) -d int Duration of tests in seconds (default 5) -debug run in debug mode, loadgen will quit with panic error -l int Limit total requests (default -1) -log string the log level,options:trace,debug,info,warn,error (default \u0026quot;info\u0026quot;) -r int Max requests per second (fixed QPS) (default -1) -v\tversion 执行压测 #  执行 Loadgen 程序即可执行压测，如下:\n➜ loadgen git:(master) ✗ ./bin/loadgen -d 30 -c 100 -compress __ ___ _ ___ ___ __ __ / / /___\\/_\\ / \\/ _ \\ /__\\/\\ \\ \\ / / // ///_\\\\ / /\\ / /_\\//_\\ / \\/ / / /__/ \\_// _ \\/ /_// /_\\\\//__/ /\\ / \\____|___/\\_/ \\_/___,'\\____/\\__/\\_\\ \\/ [LOADGEN] A http load generator and testing suit. [LOADGEN] 1.0.0_SNAPSHOT, 83f2cb9, Sun Jul 4 13:52:42 2021 +0800, medcl, support single item in dict files [07-19 16:15:00] [INF] [instance.go:24] workspace: data/loadgen/nodes/0 [07-19 16:15:00] [INF] [loader.go:312] warmup started [07-19 16:15:00] [INF] [app.go:306] loadgen now started. [07-19 16:15:00] [INF] [loader.go:316] [GET] http://localhost:8000/medcl/_search [07-19 16:15:00] [INF] [loader.go:317] status: 200,\u0026lt;nil\u0026gt;,{\u0026quot;took\u0026quot;:1,\u0026quot;timed_out\u0026quot;:false,\u0026quot;_shards\u0026quot;:{\u0026quot;total\u0026quot;:1,\u0026quot;successful\u0026quot;:1,\u0026quot;skipped\u0026quot;:0,\u0026quot;failed\u0026quot;:0},\u0026quot;hits\u0026quot;:{\u0026quot;total\u0026quot;:{\u0026quot;value\u0026quot;:0,\u0026quot;relation\u0026quot;:\u0026quot;eq\u0026quot;},\u0026quot;max_score\u0026quot;:null,\u0026quot;hits\u0026quot;:[]}} [07-19 16:15:00] [INF] [loader.go:316] [GET] http://localhost:8000/medcl/_search?q=name:medcl [07-19 16:15:00] [INF] [loader.go:317] status: 200,\u0026lt;nil\u0026gt;,{\u0026quot;took\u0026quot;:1,\u0026quot;timed_out\u0026quot;:false,\u0026quot;_shards\u0026quot;:{\u0026quot;total\u0026quot;:1,\u0026quot;successful\u0026quot;:1,\u0026quot;skipped\u0026quot;:0,\u0026quot;failed\u0026quot;:0},\u0026quot;hits\u0026quot;:{\u0026quot;total\u0026quot;:{\u0026quot;value\u0026quot;:0,\u0026quot;relation\u0026quot;:\u0026quot;eq\u0026quot;},\u0026quot;max_score\u0026quot;:null,\u0026quot;hits\u0026quot;:[]}} [07-19 16:15:01] [INF] [loader.go:316] [POST] http://localhost:8000/_bulk [07-19 16:15:01] [INF] [loader.go:317] status: 200,\u0026lt;nil\u0026gt;,{\u0026quot;took\u0026quot;:120,\u0026quot;errors\u0026quot;:false,\u0026quot;items\u0026quot;:[{\u0026quot;index\u0026quot;:{\u0026quot;_index\u0026quot;:\u0026quot;medcl-y4\u0026quot;,\u0026quot;_type\u0026quot;:\u0026quot;doc\u0026quot;,\u0026quot;_id\u0026quot;:\u0026quot;c3qj9123r0okahraiej0\u0026quot;,\u0026quot;_version\u0026quot;:1,\u0026quot;result\u0026quot;:\u0026quot;created\u0026quot;,\u0026quot;_shards\u0026quot;:{\u0026quot;total\u0026quot;:2,\u0026quot;successful\u0026quot;:1,\u0026quot;failed\u0026quot;:0},\u0026quot;_seq_no\u0026quot;:5735852,\u0026quot;_primary_term\u0026quot;:3,\u0026quot;status\u0026quot;:201}}]} [07-19 16:15:01] [INF] [loader.go:325] warmup finished 5253 requests in 32.756483336s, 524.61KB sent, 2.49MB received [Loadgen Client Metrics] Requests/sec:\t175.10 Request Traffic/sec:\t17.49KB Total Transfer/sec:\t102.34KB Avg Req Time:\t5.711022ms Fastest Request:\t440.448µs Slowest Request:\t3.624302658s Number of Errors:\t0 Number of Invalid:\t0 Status 200:\t5253 [Estimated Server Metrics] Requests/sec:\t160.37 Transfer/sec:\t93.73KB Avg Req Time:\t623.576686ms Loadgen 在正式压测之前会将所有的请求执行一次来进行预热，如果出现错误会提示是否继续，预热的请求结果也会输出到终端，执行完成之后会输出执行的摘要信息。\n 因为 Loadgen 最后的结果是所有请求全部执行完成之后的累计统计，可能存在不准的问题，建议通过打开 Kibana 的监控仪表板来实时查看 Elasticsearch 的各项运行指标。\n 模拟批量写入 #  使用 Loadgen 来模拟 bulk 批量写入也非常简单，在请求体里面配置一条索引操作，然后使用 body_repeat_times 参数来随机参数化复制若干条请求即可完成一批请求的准备，如下：\n - request: method: POST basic_auth: username: test password: testtest url: http://localhost:8000/_bulk body_repeat_times: 1000 body: \u0026quot;{ \\\u0026quot;index\\\u0026quot; : { \\\u0026quot;_index\\\u0026quot; : \\\u0026quot;medcl-y4\\\u0026quot;,\\\u0026quot;_type\\\u0026quot;:\\\u0026quot;doc\\\u0026quot;, \\\u0026quot;_id\\\u0026quot; : \\\u0026quot;$[[uuid]]\\\u0026quot; } }\\n{ \\\u0026quot;id\\\u0026quot; : \\\u0026quot;$[[id]]\\\u0026quot;,\\\u0026quot;field1\\\u0026quot; : \\\u0026quot;$[[user]]\\\u0026quot;,\\\u0026quot;ip\\\u0026quot; : \\\u0026quot;$[[ip]]\\\u0026quot;,\\\u0026quot;now_local\\\u0026quot; : \\\u0026quot;$[[now_local]]\\\u0026quot;,\\\u0026quot;now_unix\\\u0026quot; : \\\u0026quot;$[[now_unix]]\\\u0026quot; }\\n\u0026quot; 限制客户端压力 #  使用 Loadgen 并设置命令行参数 -r 可以限制客户端发送的每秒请求数，从而评估固定压力下 Elasticsearch 的响应时间和负载情况，如下：\n➜ loadgen git:(master) ✗ ./bin/loadgen -d 30 -c 100 -r 100  注意，在大量并发下，此客户端吞吐限制可能不完全准确。\n 限制请求的总条数 #  通过设置参数 -l 可以控制客户端发送的请求总数，从而制造固定的文档，修改配置如下：\nrequests: - request: method: POST basic_auth: username: test password: testtest url: http://localhost:8000/medcl-test/doc2/_bulk body_repeat_times: 1 body: \u0026quot;{ \\\u0026quot;index\\\u0026quot; : { \\\u0026quot;_index\\\u0026quot; : \\\u0026quot;medcl-test\\\u0026quot;, \\\u0026quot;_id\\\u0026quot; : \\\u0026quot;$[[uuid]]\\\u0026quot; } }\\n{ \\\u0026quot;id\\\u0026quot; : \\\u0026quot;$[[id]]\\\u0026quot;,\\\u0026quot;field1\\\u0026quot; : \\\u0026quot;$[[user]]\\\u0026quot;,\\\u0026quot;ip\\\u0026quot; : \\\u0026quot;$[[ip]]\\\u0026quot; }\\n\u0026quot; 每次请求只有一个文档，然后执行 loadgen\n./bin/loadgen -config loadgen-gw.yml -d 600 -c 100 -l 50000 执行完成之后，Elasticsearch 的索引 medcl-test 将增加 50000 条记录。\n使用自增 ID 来确保文档的顺序性 #  如果希望生成的文档编号自增有规律，方便进行对比，可以使用 sequence 类型的自增 ID 来作为主键，内容也不要用随机数，如下：\nrequests: - request: method: POST basic_auth: username: test password: testtest url: http://localhost:8000/medcl-test/doc2/_bulk body_repeat_times: 1 body: \u0026quot;{ \\\u0026quot;index\\\u0026quot; : { \\\u0026quot;_index\\\u0026quot; : \\\u0026quot;medcl-test\\\u0026quot;, \\\u0026quot;_id\\\u0026quot; : \\\u0026quot;$[[id]]\\\u0026quot; } }\\n{ \\\u0026quot;id\\\u0026quot; : \\\u0026quot;$[[id]]\\\u0026quot; }\\n\u0026quot; 上下文复用变量 #  在一个请求中，我们可能希望有相同的参数出现，比如 routing 参数用来控制分片的路由，同时我们又希望该参数也保存在文档的 JSON 里面， 可以使用 runtime_variables 来设置请求级别的变量，或者 runtime_body_line_variables 定义请求体级别的变量，如果请求体复制 N 份，每份的参数是不同的，举例如下：\nvariables: - name: id type: sequence - name: uuid type: uuid - name: now_local type: now_local - name: now_utc type: now_utc - name: now_unix type: now_unix - name: suffix type: range from: 10 to: 15 requests: - request: method: POST runtime_variables: batch_no: id runtime_body_line_variables: routing_no: uuid basic_auth: username: ingest password: password #url: http://localhost:8000/_search?q=$[[id]] url: http://192.168.3.188:9206/_bulk body_repeat_times: 10 body: \u0026quot;{ \\\u0026quot;create\\\u0026quot; : { \\\u0026quot;_index\\\u0026quot; : \\\u0026quot;test-$[[suffix]]\\\u0026quot;,\\\u0026quot;_type\\\u0026quot;:\\\u0026quot;doc\\\u0026quot;, \\\u0026quot;_id\\\u0026quot; : \\\u0026quot;$[[uuid]]\\\u0026quot; , \\\u0026quot;routing\\\u0026quot; : \\\u0026quot;$[[routing_no]]\\\u0026quot; } }\\n{ \\\u0026quot;id\\\u0026quot; : \\\u0026quot;$[[uuid]]\\\u0026quot;,\\\u0026quot;routing_no\\\u0026quot; : \\\u0026quot;$[[routing_no]]\\\u0026quot;,\\\u0026quot;batch_number\\\u0026quot; : \\\u0026quot;$[[batch_no]]\\\u0026quot;, \\\u0026quot;random_no\\\u0026quot; : \\\u0026quot;$[[suffix]]\\\u0026quot;,\\\u0026quot;ip\\\u0026quot; : \\\u0026quot;$[[ip]]\\\u0026quot;,\\\u0026quot;now_local\\\u0026quot; : \\\u0026quot;$[[now_local]]\\\u0026quot;,\\\u0026quot;now_unix\\\u0026quot; : \\\u0026quot;$[[now_unix]]\\\u0026quot; }\\n\u0026quot; 我们定义了 batch_no　变量来代表一批文档里面的相同批次号，同时又定义了　routing_no　变量来代表每个文档级别的 routing 值。\n"});index.add({'id':60,'href':'/docs/latest/console/tutorials/cluster_node_cpu_usage/','title':"如何监控 Elasticsearch 集群节点的 CPU 使用率",'section':"动手教程",'content':"如何监控 Elasticsearch 集群节点的 CPU 使用率 #  简介 #  本文将介绍如何使用 INFINI Console 监控 Elasticsearch 集群节点磁盘的使用率，并进行告警。\n准备 #   下载并安装最新版 INFINI Console 使用INFINI Console 注册 Elasticsearch 集群  创建告警规则 #  在浏览器中打开 INFINI Console, 点击左侧菜单 告警管理》规则管理 进入告警管理页，然后点击 新建按钮进入创建告警规则页。按以下步骤创建告警规则：\n 选择集群（这里需要选择 INFINI Console 存储数据的 Elasticsearch 集群，也就是在配置文件 console.yml 配置的 Elasticsearch 集群，如果没有注册到 INFINI Console , 请先注册） 输入告警对象 .infini_metrics*（选择 Elasticsearch 集群下的索引，或者输入索引 pattern, 这里因为 INFINI Console 采集的监控数据存放在索引 .infini_metrics 里面） 输入筛选条件（ Elasticsearch 查询 DSL ） 这里我们需要过滤监控指标类别为 node_stats 及元数据分类为 elasticsearch，DSL 如下：  { \u0026quot;bool\u0026quot;: { \u0026quot;must\u0026quot;: [ { \u0026quot;term\u0026quot;: { \u0026quot;metadata.name\u0026quot;: { \u0026quot;value\u0026quot;: \u0026quot;node_stats\u0026quot; } } }, { \u0026quot;term\u0026quot;: { \u0026quot;metadata.category\u0026quot;: { \u0026quot;value\u0026quot;: \u0026quot;elasticsearch\u0026quot; } } } ] } }  选择时间字段 timestamp 和统计周期用于做 date histogram 聚合   输入规则名称 分组设置（可选，可配置多个），当统计指标需要分组的时候设置，由于所有注册到 INFINI Console 的 Elasticsearch 集群监控指标都存储在索引 .infini_metrics 里面，所以需要先根据集群 ID 分组，然后再根据节点 ID 分组， 这里我们选择 metadata.labels.cluster_id 和 metadata.labels.node_id。 配置告警指标，选择聚合字段 payload.elasticsearch.node_stats.process.cpu.percent，统计方法 avg。 配置指标公式（当配置了一个以上的告警指标的时候，需要设置一个公式来计算目标指标），这里公式 fx 配置为 a。然后设置变量a的数值类型为比率Ratio。 配置告警条件，这里配置三个告警条件，配置 持续一个周期 CPU使用率 大于 80 的时候，触发 P2(Medium) 告警; 配置 持续一个周期 CPU使用率 大于 90 的时候，触发 P1(High) 告警; 配置 持续一个周期 CPU使用率 大于 95 的时候，触发 P0(Critical) 告警; 设置执行周期，这里配置一分钟执行一次检查 设置事件标题，事件标题是一个模版，可以使用模版变量，模版语法及模版变量用法参考 这里 设置事件内容，事件内容是一个模版，可以使用模版变量，模版语法及模版变量用法参考 这里  Priority:{{.priority}} Timestamp:{{.timestamp | datetime_in_zone \u0026quot;Asia/Shanghai\u0026quot;}} RuleID:{{.rule_id}} EventID:{{.event_id}} {{range .results}} ClusterID:{{index .group_values 0}}; NodeID:{{index .group_values 1}}; CPU:{{.result_value | to_fixed 2}}%; {{end}}  打开配置告警渠道开关，选择右上角 add 快速选择一个告警渠道模版填充，关于怎么创建告警渠道模版请参考 这里 设置沉默周期 1 小时，即触发告警规则后，一个小时内只发送通知消息一次 设置接收时段，默认 00:00-23:59 ，即全天都可接收通知消息  设置完成之后点击保存按钮提交。\n收到告警通知消息 #  等待一会儿，收到钉钉告警消息通知如下：\n可以看到告警通知消息里面显示了当前规则触发的 Elasticsearch 集群 ID，节点 ID, 当前CPU使用率。\n查看告警消息中心 #  除了会收到外部通知消息外，INFINI Console 告警消息中心也会生成一条告警消息。点击菜单 告警管理》告警中心进入\n小结 #  通过使用 INFINI Console 告警功能， 可以很方便地监控 Elasticsearch 集群节点的CPU使用率。配置告警规则之后， 一旦有任何 Elasticsearch 节点 CPU 使用率超过设定的阈值就会触发告警并发送告警消息。\n"});index.add({'id':61,'href':'/docs/latest/console/tutorials/cluster_node_jvm_usage/','title':"如何监控 Elasticsearch 集群节点的 JVM 使用率",'section':"动手教程",'content':"如何监控 Elasticsearch 集群节点的 JVM 使用率 #  简介 #  本文将介绍如何使用 INFINI Console 监控 Elasticsearch 集群节点 JVM 的使用率，并进行告警。\n准备 #   下载并安装最新版 INFINI Console 使用INFINI Console 注册 Elasticsearch 集群  创建告警规则 #  在浏览器中打开 INFINI Console, 点击左侧菜单 告警管理》规则管理 进入告警管理页，然后点击 新建按钮进入创建告警规则页。按以下步骤创建告警规则：\n 选择集群（这里需要选择 INFINI Console 存储数据的 Elasticsearch 集群，也就是在配置文件 console.yml 配置的 Elasticsearch 集群，如果没有注册到 INFINI Console , 请先注册） 输入告警对象 .infini_metrics*（选择 Elasticsearch 集群下的索引，或者输入索引 pattern, 这里因为 INFINI Console 采集的监控数据存放在索引 .infini_metrics 里面） 输入筛选条件（ Elasticsearch 查询 DSL ） 这里我们需要过滤监控指标类别为 node_stats 及元数据分类为 elasticsearch，DSL 如下：  { \u0026quot;bool\u0026quot;: { \u0026quot;must\u0026quot;: [ { \u0026quot;term\u0026quot;: { \u0026quot;metadata.name\u0026quot;: { \u0026quot;value\u0026quot;: \u0026quot;node_stats\u0026quot; } } }, { \u0026quot;term\u0026quot;: { \u0026quot;metadata.category\u0026quot;: { \u0026quot;value\u0026quot;: \u0026quot;elasticsearch\u0026quot; } } } ] } }  选择时间字段 timestamp 和统计周期用于做 date histogram 聚合   输入规则名称 分组设置（可选，可配置多个），当统计指标需要分组的时候设置，由于所有注册到 INFINI Console 的 Elasticsearch 集群监控指标都存储在索引 .infini_metrics 里面，所以需要先根据集群 ID 分组，然后再根据节点 ID 分组， 这里我们选择 metadata.labels.cluster_id 和 metadata.labels.node_id。 配置告警指标，选择聚合字段 payload.elasticsearch.node_stats.jvm.mem.heap_used_percent，统计方法 p90。 配置指标公式（当配置了一个以上的告警指标的时候，需要设置一个公式来计算目标指标），这里公式 fx 配置为 a。然后设置变量a的数值类型为比率Ratio。 配置告警条件，这里配置三个告警条件，配置 持续一个周期 JVM 使用率 大于 50 的时候，触发 P2(Medium) 告警; 配置 持续一个周期 JVM 使用率 大于 90 的时候，触发 P1(High) 告警; 配置 持续一个周期 JVM 使用率 大于 95 的时候，触发 P0(Critical) 告警; 设置执行周期，这里配置一分钟执行一次检查 设置事件标题，事件标题是一个模版，可以使用模版变量，模版语法及模版变量用法参考 这里 设置事件内容，事件内容是一个模版，可以使用模版变量，模版语法及模版变量用法参考 这里  Priority:{{.priority}} Timestamp:{{.timestamp | datetime_in_zone \u0026quot;Asia/Shanghai\u0026quot;}} RuleID:{{.rule_id}} EventID:{{.event_id}} {{range .results}} ClusterID:{{index .group_values 0}}; NodeID:{{index .group_values 1}}; JVM used percent：{{.result_value | to_fixed 2}}%; {{end}}  打开配置告警渠道开关，选择右上角 add 快速选择一个告警渠道模版填充，关于怎么创建告警渠道模版请参考 这里 设置沉默周期 1 小时，即触发告警规则后，一个小时内只发送通知消息一次 设置接收时段，默认 00:00-23:59 ，即全天都可接收通知消息  设置完成之后点击保存按钮提交。\n收到告警通知消息 #  等待一会儿，收到钉钉告警消息通知如下：\n可以看到告警通知消息里面显示了当前规则触发的 Elasticsearch 集群 ID，节点 ID, 当前 JVM 使用率。\n查看告警消息中心 #  除了会收到外部通知消息外，INFINI Console 告警消息中心也会生成一条告警消息。点击菜单 告警管理》告警中心进入\n小结 #  通过使用 INFINI Console 告警功能， 可以很方便地监控 Elasticsearch 集群节点的 JVM 使用率。配置告警规则之后， 一旦有任何 Elasticsearch 节点 JVM 使用率超过设定的阈值就会触发告警并发送告警消息。\n"});index.add({'id':62,'href':'/docs/latest/console/tutorials/data_migration/','title':"如何使用 INFINI 迁移功能",'section':"动手教程",'content':"如何使用 INFINI 迁移功能 #  简介 #  本文将介绍如何使用 INFINI Console 和 INFINI Gateway 来迁移 Elasticsearch 索引数据。\n准备 #   下载并安装最新版 INFINI Console (版本要求 0.7 及以上) 下载并安装最新版的 INFINI Gateway (版本要求 1.9 及以上) 两个 Elasticsearch 集群  Gateway 迁移配置 #  配置文件名为 migration.yml\npath.data: data path.logs: log progress_bar.enabled: false stats.no_buffer: true elasticsearch: - name: task_from enabled: true schema: http hosts: - 192.168.3.6:9200 traffic_control: #global traffic control max_bps_per_node: 209715200 #max total bytes send to es per node, 200MB/s max_qps_per_node: 20000 #max total requests send to es per node, 20k/s discovery: # auto discovery elasticsearch cluster nodes enabled: true refresh: enabled: true interval: 60s pipeline: - name: target_indexing auto_start: true keep_running: true processor: - disorder_bulk_indexing: max_worker_size: 10 detect_interval: 100 bulk: compress: true batch_size_in_mb: 20 batch_size_in_docs: 5000 invalid_queue: bulk_indexing_400 queues: type: scroll_docs consumer: fetch_max_messages: 1000 - name: task_stats auto_start: true keep_running: true processor: - dynamic_task_stats: detect_interval: 10000 pipeline.dynamic: true pipeline.dynamic_task_size: 10 disk_queue: sync_timeout_in_ms: 10000 sync_every_records: 10000 elastic: elasticsearch: task_from enabled: true remote_configs: true health_check: enabled: true interval: 30s availability_check: enabled: true interval: 60s metadata_refresh: enabled: true interval: 30s cluster_settings_check: enabled: true interval: 20s store: enabled: false orm: enabled: true init_template: true template_name: \u0026quot;.infini\u0026quot; index_prefix: \u0026quot;.infini_\u0026quot; disk_queue.compress.segment.enabled: true 启动 Gateway #  ./gateway-xxx-xxx -config migration.yml\n注册 Gateway #  这里我们使用极限网关作为迁移任务的执行者，需要提前将网关实例注册到Console 里面管理，后面创建迁移任务的时候会用到。 点击 INFINI Console 中左侧菜单 网关管理》实例管理 ，然后点击 新建 按钮注册新的实例，如下图所示：\n输入网关的地址，这里要注意网关的默认 API 地址使用的是 2900 端口，这里我们输入 192.168.3.6:9200，然后点击下一步\n点击下一步，完成网关注册\n注册源集群和目标集群 #  点击 INFINI Console 中左侧菜单 系统管理》集群管理，然后点击注册集群，先后注册源集群 es-v5616 和目标集群 es-v7140，如下图所示：\n如果 Elasticsearch 集群有身份验证，需要设置身份验证信息，然后点击下一步\n确认集群信息无误，然后点击下一步\n到这里源目标集群就注册完成了，目标集群 es-v710 的注册步骤也是一样的，这里就不赘述了。\n创建迁移任务 #  点击 INFINI Console 中左侧菜单 容灾备份》数据迁移，然后点击新建按钮创建迁移任务，如下图所示：\n配置迁移集群 #  在源集群列表中选择集群 es-v5616, 在目标集群列表中选择集群 es-v7140\n配置迁移索引 #  点击选择迁移索引按钮, 如下图：\n这里我们选择了两个索引 test-10 和 test-15 ,然后点击确认\n 选择索引的时候请确认目标集群相应索引是否创建好 mapping, setting 等元数据信息\n 表格右方可以设置目标索引名称和文档 type，按需修改即可，这里我们将索引 test-10 重命名为 test-10-x, 将索引 test-15 重命名为 test-15-x，文档类型都重命名为 _doc。 选择完索引之后，点击下一步，进行迁移任务的数据范围设置和分区设置，如下图：\n配置数据范围 #  如果需要过滤数据迁移，可以进行数据范围的设置，这里我们进行全量的数据迁移，就不设置了\n配置数据分区 #  如果一个索引数据量特别大，可以进行数据分区的设置。数据分区根据设置的字段，以及分区步长将数据拆成多段，系统最终会将一个分段的数据作为一个子任务去运行，迁移数据， 这样的话即使，一个分段迁移过程出现异常，只需要重跑这个子任务。\n数据分区设置目前支持按照日期类型字段（date）, 和数字类型 (number) 拆分分区，如上图所示，我们选择日期类型字段 now_widh_format 进行拆分分区，分区步长设置为 5分钟(5m), 然后点击预览按钮，可以看到根据设置拆分可以得到 8 个分区（文档数为0的分区最终不会生成子任务）。 根据预览信息确认分区设置无误之后，点击保存关闭分区设置并保存，然后点击下一步进行运行设置。\n运行设置 #  一般情况下使用默认设置，然后执行节点选择先前注册的网关实例 Dynamo，然后点击创建任务。\n启动迁移任务 #  创建迁移任务成功后会看到任务列表，如下图：\n可以看到，最近一条任务就是我们刚创建的，然后在表格右侧操作栏中点击 start 开始任务（任务开始之前，需要确认目标集群中索引是否已经设置好mapping， 和 settings, 索引模版，ilm ）。\n点击开始按钮 启动迁移任务。\n查看迁移任务进度 #  任务启动成功之后，点击刷新按钮，刷新列表，看到操作一栏中有详情入口时，点击详情进入任务详情页查看任务执行状态。开启自动刷新之后，我们可以看到任务详情有如下变化：\n图中蓝色方块表示，子任务（分区任务）已经在运行，灰色表示任务还没有开始\n上图中可以看到方块变成了浅绿色，表示子任务（分区任务）已经数据导出完成，索引 test-10的迁移进度是 65.5%, 索引 test-15 迁移进度是 18.05%\n上图中可以看到所有方块变成了绿色，索引迁移进度都是 100%, 表示数据已经迁移完成。\n小结 #  使用 INFINI 数据迁移功能可以很方便地将 Elasticsearch 数据进行跨版本迁移，并且可以很直观地查看 当前数据的迁移进度。\n"});index.add({'id':63,'href':'/docs/latest/gateway/references/filters/','title':"在线过滤器",'section':"功能手册",'content':"请求过滤器 #  什么是过滤器 #  过滤器是网关接收到请求之后，在流程里面定义的一系列处理单元，每个过滤器处理一件任务，可以灵活组合，过滤器是请求的在线处理。\n过滤器列表 #  请求过滤 #    context_filter  request_method_filter  request_header_filter  request_path_filter  request_user_filter  request_host_filter  request_client_ip_filter  request_api_key_filter  response_status_filter  response_header_filter  请求转发 #    ratio  clone  switch  flow  redirect  请求干预 #    javascript  sample  request_body_json_del  request_body_json_set  context_regex_replace  request_body_regex_replace  response_body_regex_replace  response_header_format  set_context  set_basic_auth  set_hostname  set_request_header  set_request_query_args  set_response_header  set_response  限速限流 #    context_limiter  request_path_limiter  request_host_limiter  request_user_limiter  request_api_key_limiter  request_client_ip_limiter  retry_limiter  sleep  日志监控 #    logging  Elasticsearch #    date_range_precision_tuning  bulk_reshuffle  elasticsearch_health_check  bulk_response_process  bulk_request_mutate  身份认证 #    basic_auth  ldap_auth  Output #    queue  elasticsearch  cache  translog  redis_pubsub  drop  http  调试开发 #    echo  dump  record  "});index.add({'id':64,'href':'/docs/latest/console/release-notes/','title':"版本历史",'section':"INFINI Console",'content':"版本发布日志 #  这里是 INFINI Console 历史版本发布的相关说明。\n0.7.0 #  Breaking changes #  Features #   新增数据迁移。 新增初始化向导。 新增系统服务健康监控。 新增授权窗口。  Bug fix #   修复了 Discover 第一次加载未发起搜索请求的问题。  0.6.0 #  Breaking changes #  Features #   新增主机概览。 新增主机监控。 节点概览新增日志查看功能（需安装 Agent）。 Insight 配置框新增 Search 配置。  Bug fix #   修复了 Discover 字段过滤白屏问题。 修复了 Discover 表格添加字段后排序失效问题。 修复了低版本浏览器 js 不兼容导致集群注册不成功的问题。 修复了 Elasticsearch 8.x 删除文档报错不兼容的问题。 修复了创建新索引不成功时，异常处理的问题。 修复了元数据采集配置空指针引用的问题。 修复了开发工具中使用加载命令失败报错的问题。  Improvements #   本地列表搜索查找支持通配符过滤。 支持配置页面标题后缀。 优化告警规则必填字段标记显示。 优化 Discover 时间范围 Auto Fit，设为15分钟。 优化 Discover 保存搜索，会保存当前的字段过滤和 Insight 图表配置。 优化集群列表：增加链接跳转；支持集群列表 status 字段排序。  0.5.0 #  Breaking changes #  Features #   集群监控节点层面添加 IO 指标（仅支持 Linux 版本 Elasticsearch 集群）。 新增探针管理功能。 新增基于 Centos 的 Docker 镜像。 INFINI Insight 新增图表类型（单值、饼图、面积图）  Bug fix #   修复了 Gateway 实例列表刷新后多次请求的问题。 修复了 docker 镜像时区加载失败的问题。 修复了存储数据 Elasticsearch 集群不可用时，采集监控指标队列不消费的问题。 修复开发工具不能转发请求给后端集群为 Https 类型的问题。 修复 INFINI Insight 编辑组件后所有组件又重新获取数据的问题。 修复从其它页面的索引链接跳转到 Discover 时 Query 依然有旧状态的问题。  Improvements #   优化刷新集群状态日志输出。 优化了未授权时跳转至登录界面频繁的弹窗提示。 优化 Discover 搜索栏时间选择控件 UI，空间更紧凑，切换更方便。  0.4.0 #  Breaking changes #  Features #   数据探索新增 Insight 功能，根据索引下的数据特征推送图表，可视化展示指标数据。 数据探索新增保存搜索和回放搜索功能。 新增别名管理。  Bug fix #   修复了 v0.3.1 没有开启安全的情况下开发工具发送请求响应返回错误的 Bug。 修复了 AWS Elasticsearch 云环境 node http.public_address 没有，导致采集监控数据报错的 Bug。 Fixed the bug that when the Elasticsearch cluster for storing data is unavailable, the collected metric data are not consumed(Updating the settings of elastic\u0026gt;store defaults to false in console.yml).  Improvements #   优化 Console 存储数据 Elasticsearch 版本检查提示。  0.3.1 #  Bug fix #   The kv module should be initialized before elastic module The account profile api should get builtin username dynamically Fixed an issue where the index in the overview was not displayed correctly Fixed node health status in the overview was not displayed correctly Fixed the bug that the new channel could not get the type when the rule was submit  0.3.0 #  Breaking changes #  Features #   Support basic authentication Added platform overview Added cluster activities Added index management Added data view management Added data discover (Support both index and view) Support gzip compression and it is enabled by default Support rbac authorization Added alerting management (Support Webhook channel) Added time-zone quick selector  Bug fix #   Fixed bug:discover multi fields selected Fixed bug:the count of nodes and shards value incorrect in cluster overview Fixed bug:overview search request params field from do not counting from 0 Fixed bug:login page tab not centered Fixed bug:Re-login redirect jump parameter problem caused by session expiration Fixed bug:OverviewStatistic component mask state value incorrect Fixed bug:repeat http request pending state Fixed bug:console copy as curl without an endpoint  Improvements #   Rewritten monitoring UI Optimize cluster metrics line chart Optimize health status component Add filter component to quick filter clisters,nodes,indices Add local sort for table column of clisters,nodes,indices Add isTLS form field for Gateway register Index list and node list Support real-time and non-real-time data switching viewing The interval for collecting elasticsearch cluster state is configurable Optimized requests to elasticsearch Add Console version info Add client http request timeout auto abort Dev tool support search Proper Handle metrics collecting while cluster in partial failure  0.2.0 #  Breaking changes #  Features #   Collect Elasticsearch cluster_health metrics Added thread pool related metrics Optimize the grouping of metrics Index .infini_metrics support ilm configuration Added hot key(Ctrl+Shift+O) to dev tools English version support  Bug fix #   Fixed the \u0026ldquo;required authentication credentials\u0026rdquo; issue in the test connection cluster time Fixed the problem that the validation failed when the cluster address is a domain name and contains special characters Fixed the issue that monitoring data is not displayed on 32-bit operating systems Fixed the problem that the development tool was initialized blank when the storage ES address changed Fixed the problem that the pagination of cluster list page cannot work  Improvements #   Cluster view Added metrics of counting cluster master, data, and coordinating nodes Cluster view Added metric of cluster health Node view Add JVM grouping, display related information of JVM memory Node view added JVM GC frequency and GC delay metrics Use POST instead of GET when request body is not nil Node view added cache hit rate and other related metrics Node View added metric of the number of open files Show the last time of the metrics was collected When the cluster is unavailable  0.1.0 #   Elasticsearch clusters management Basic monitoring supported for Elasticsearch cluster Dev tools support elasticsearch  "});index.add({'id':65,'href':'/docs/latest/gateway/release-notes/','title':"版本历史",'section':"INFINI Gateway",'content':"版本发布日志 #  这里是极限网关历史版本发布的相关说明。\n1.9.0 #  Breaking changes #   Refactoring config for ip access control Disable metadata refresh and node availability check by default Update default config path from configs to config  Features #   Support listen on IPv6 address Add general health api Add request_ip to context Add badger filter plugin Allow to split produce and consume messages from s3 Add bulk_request_throttle filter Support access request context and more output options in echo filter Add body_json to response context Add cert config to API module, support mTLS  Bug fix #   Fix user was removed in logging filter Fix incorrect message size issue, reload when files changed in disk_queue Fix issue that index_diff could not finished automatically Fix hostname was not well updated in filter set_request_header or set_hostname Fix to check consumer\u0026rsquo;s lag instead of queue\u0026rsquo;s lag in flow_runner processor  Improvements #   Remove newline in indexing_merge and json_indexing processor Improve instance check, add config to disable Add option skip_insecure_verify to s3 module Improve instance check, enable config to disable Update the way to get ctx process info, optimize memory usage Improve indexing performance for bulk_indexing processor Refactoring disk_queue, speedup message consumption Enable segment compress for disk_queue by default Skip download s3 files when s3 was not enabled Add option to log warning messages for throttle filters Optimize hash performance for getting primary shardID and partitionID Add cache for get index routing table Optimize performance for bulk response processing Refactoring bulk_processor, pass meta info to payload func Don\u0026rsquo;t call payload func for delete action Improve queue consumer\u0026rsquo;s lag check  1.8.1 #  Bug fix #   Remove newline in document for processor es_scroll and dump_hash  1.8.0 #  Breaking changes #   Remove config compress_on_message_payload from disk_queue Rename parameter consumer to name in consumer_has_lag condition Remove redundancy prefix name of the disk_queue files  Features #   Add segment level based disk_queue file compression  Bug fix #   Fix nil host in bulk_indexing processor Fix nil body in bulk_response_process filter Fix sliced consume in bulk_indexing processor  Improvements #   Handle bulk stats to bulk_response_process and used in logging filter  1.7.0 #  Breaking changes #  Features #   Add prometheus format to stats API Add redirect filter Add context_flow to flow filter Add permitted_client_ip_list to router Add Centos based docker image  Bug fix #   Fix date_range_precision filter failed to parse on specify field Fix disk usage status in windows platform  Improvements #   Merge events during config change, prevent unnecessary reload Handle templates when loading config Add cache to ldap_auth filter  1.6.0 #  Breaking changes #   Update disk_queue folder structure, use UUID as folder name instead of the queue name Parameter mode was removed from bulk_reshuffle filter, only async was supported Rename filter bulk_response_validate to bulk_response_process  Features #   Add metadata to queue Support subscribe queue by specify labels Support concurrent worker control for bulk_indexing processor Auto detect new queues for bulk_indexing processor Allow to consume queue messages over disk queue Auto sync disk_queue files to remote s3 in background Add api to operate gateway entry Support plugin auto discovery Add API to operate gateway entities Filter bulk_request_mutate support remove _type in bulk requests for es v8.0+ Add elasticsearch adapter for version 8.0+ Add http filter for general reverse proxy usage, like proxy Kibana Add consumer_has_lag condition to check queue status Add record filter to play requests easier Add zstd compress to disk_queue, disabled by default Add disorder_bulk_indexing processor Add javascript filter Add prefix and suffix to when conditions Add indexing_merge processor  Bug fix #   Fix date_range_precision_tuning filter for complex range query Fix node availability initially check Fix basic_auth filter not asking user to input auth info in browser Fix null id not fixed in filter bulk_request_mutate and bulk_reshuffle Fix switch filter not forwarding when remove_prefix was disabled Fix buffer was not proper reset in flow_runner processor Fix entry not loading the pre-defined TLS certificates Fix set_basic_auth not proper reset previous user information Fix elapsed in request logging not correct Fix switch filter, use strings.TrimPrefix instead of strings.TrimLeft Fix the last query_string args can\u0026rsquo;t be deleted, parameter no_cache in get_cache filter fixed Fix s3 downloaded file corrupted  Improvements #   Handle http public address, remove prefix if that exists Refactor bulk_reshuffle filter and bulk_indexing processor Should not fetch nodes info when elasticsearch discovery disabled Seamless consume queue message across files Persist consumer offset to local store Add API to reset consumer offset Refactoring ORM framework Expose error of mapping put Refactoring pipeline framework Improve multi-instance check, multi-instance disabled by default Add CPU and memory metrics to stats api Seamless fetch queue files from s3 server Proper handle 409 version conflicts in bulk requests Allow memory queue to retry 1s when it is full Proper handle the cluster available check Proper handle the cluster partial failure check Exit bulk worker while no new messages returned Optimize bytes buffer usage, reduced memory usage  1.5.0 #  Breaking changes #  Features #   Add API to scroll messages from disk queue Prevent out of space, disk usage reserved for disk_queue Add context_filter and context_limiter for general purpose Add bulk_request_mutate filter Add basic_auth filter Add set_context filter Add context_regex_replace filter Add to_string property to request and response context  Bug fix #   Fix bulk response validate incorrectly caused by jsonParser Fix nil exception in request_path_limiter caused by refactoring Fix big size document out of order caused by bulk buffer  Improvements #   Fix TCP not keepalived in some case Add closing progress bar to pipeline module Add retry_delay_in_ms config to pipeline module Handle partial failure in bulk requests Optimize scroll performance of dump_hash processor Improve API directory  1.4.0 #  Breaking changes #   Rename flow config filter_v2 to filter, only support new syntax Rename pipeline config pipelines_v2 to pipeline, processors to processor, only support new syntax Rename filter request_logging to logging Merge dump filters to dump filter Response headers renamed, dashboard may broken Remove filter request_body_truncate and response_body_truncate  Features #   Add option to disable file logging output Add option compress to queue_consumer processor  Bug fix #   Fix invalid host header setting in elasticsearch reverse proxy Fix cluster available health check Fix gzip encoding issue for requests forwarding  Improvements #   Support string type in in condition  1.3.0 #  Breaking changes #   Switch to use pipelines_v2 syntax only Rename filter disk_enqueue to queue Rename processor disk_queue_consumer to queue_consumer Rename filter redis to redis_pubsub  Features #   Refactoring pipeline framework, support DAG based task schedule Add dump_hash and index_diffs processor Add redis output and redis queue adapter Add set_request_query_args filter Add ldap_auth filter Add retry_limiter filter Add request_body_json_set and request_body_json_del filter Add stats filter Add health_check config to elastic module Add API to pipeline framework, support _start and _stop pipelines  Bug fix #   Fix data race issue in bulk_reshuffle Fix fix_null_id always executed in bulk_reshuffle Auto handle big sized documents in bulk requests  Improvements #   Refactoring flow runner to service pipeline Optimize CPU and Memory usage Optimize index diff service, speedup and cross version compatibility Set the default max file size of queue files to 1 GB Proper handle elasticsearch failure during startup Support custom depth check to queue_has_lag condition Support multi hosts for elasticsearch configuration Add parameter auto_start to prevent pipeline running on start Add keep_running parameter to pipeline config Safety shutdown pipeline and entry service Support more complex routing pattern rules  1.2.0 #  Features #   Support alias in bulk_reshuffle filter. Support truncate in request_logging filter. Handle 429 retry in json_indexing service. Add forcemerge service. Add response_body_regex_replace filter. Add request_body_regex_replace filter. Add sleep filter. Add option to log slow requests only. Add cluster and bulk status to request logging. Add filter_v2 and support _ctx to access request context. Add dump_context filter. Add translog filter, support rotation and compression. Add set_response filter. Add set_request_header filter. Add set_hostname filter. Add set_basic_auth filter. Add set_response_header filter. Add elasticsearch_health_check filter. Add drop filter.  Bug fix #   Fix truncate body filter, correctly resize the body bytes. Fix cache filter. Fix floating_ip module. Fix dirty write in diskqueue. Fix compression enabled requests. Fix date_range_precision_tuning filter. Fix invalid indices status on closed indices #23. Fix document hash for elasticsearch 6.x. Fix floating_ip feature run with daemon mode. Fix async bulk to work with beats.  Improvements #   Optimize memory usage, fix memory leak.  Acknowledgement #  Thanks to the following enterprises and teams #   China Everbright Bank, China Citic Bank, BSG, Yogoo  Thanks to the following individual contributors #   MaQianghua, YangFan, Tanzi, FangLi  1.1.0 #   Request Logging and Dashboard. Support ARM Platform [armv5\\v6\\v7\\v8(arm64)]. Fix Elasticsearch Nodes Auto Discovery. Add Request Header Filter. Add Request Method Filter. Add Sample Filter. Request Logging Performance Optimized (100x speedup). Add Request Path Filter. Add Debug Filter. Add User Info to Logging Message. Support Routing Partial Traffic to Specify Processing Flow (by Ratio). Support Traffic Clone, Support Dual-Write or 1:N Write. Elasticsearch topology auto discovery, support filter by nodes,tags,roles. Backend failure auto detection, auto retry and select another available endpoint. Floating IP feature ready to use. Add bulk_reshuffle filter.  1.0.0 #   Rewritten for performance Index level request throttle Request caching Kibana MAGIC speedup Upstream auto discovery Weighted upstream selections Max connection limit per upstream  "});index.add({'id':66,'href':'/docs/latest/console/upgrade/','title':"版本更新",'section':"INFINI Console",'content':"版本更新 #  这里是 INFINI Console 版本更新的相关说明。\nFrom 0.2 to 0.3 #  Update template .infini #  PUT _template/.infini { \u0026quot;order\u0026quot;: 0, \u0026quot;index_patterns\u0026quot;: [ \u0026quot;.infini_*\u0026quot; ], \u0026quot;settings\u0026quot;: { \u0026quot;index\u0026quot;: { \u0026quot;max_result_window\u0026quot;: \u0026quot;10000000\u0026quot;, \u0026quot;mapping\u0026quot;: { \u0026quot;total_fields\u0026quot;: { \u0026quot;limit\u0026quot;: \u0026quot;20000\u0026quot; } }, \u0026quot;analysis\u0026quot;: { \u0026quot;analyzer\u0026quot;: { \u0026quot;suggest_text_search\u0026quot;: { \u0026quot;filter\u0026quot;: [ \u0026quot;word_delimiter\u0026quot; ], \u0026quot;tokenizer\u0026quot;: \u0026quot;classic\u0026quot; } } }, \u0026quot;number_of_shards\u0026quot;: \u0026quot;1\u0026quot; } }, \u0026quot;mappings\u0026quot;: { \u0026quot;dynamic_templates\u0026quot;: [ { \u0026quot;strings\u0026quot;: { \u0026quot;mapping\u0026quot;: { \u0026quot;ignore_above\u0026quot;: 256, \u0026quot;type\u0026quot;: \u0026quot;keyword\u0026quot; }, \u0026quot;match_mapping_type\u0026quot;: \u0026quot;string\u0026quot; } } ] }, \u0026quot;aliases\u0026quot;: {} } Close index .infini_cluster #  POST .infini_cluster/_close Update index settings of .infini_cluster #  PUT .infini_cluster/_settings { \u0026quot;analysis\u0026quot;: { \u0026quot;analyzer\u0026quot;: { \u0026quot;suggest_text_search\u0026quot;: { \u0026quot;filter\u0026quot;: [ \u0026quot;word_delimiter\u0026quot; ], \u0026quot;tokenizer\u0026quot;: \u0026quot;classic\u0026quot; } } } } Update index mappings of .infini_cluster #  PUT .infini_cluster/_mapping { \u0026quot;dynamic_templates\u0026quot;: [ { \u0026quot;strings\u0026quot;: { \u0026quot;match_mapping_type\u0026quot;: \u0026quot;string\u0026quot;, \u0026quot;mapping\u0026quot;: { \u0026quot;ignore_above\u0026quot;: 256, \u0026quot;type\u0026quot;: \u0026quot;keyword\u0026quot; } } } ], \u0026quot;properties\u0026quot;: { \u0026quot;basic_auth\u0026quot;: { \u0026quot;properties\u0026quot;: { \u0026quot;password\u0026quot;: { \u0026quot;type\u0026quot;: \u0026quot;keyword\u0026quot; }, \u0026quot;username\u0026quot;: { \u0026quot;type\u0026quot;: \u0026quot;keyword\u0026quot; } } }, \u0026quot;created\u0026quot;: { \u0026quot;type\u0026quot;: \u0026quot;date\u0026quot; }, \u0026quot;description\u0026quot;: { \u0026quot;type\u0026quot;: \u0026quot;text\u0026quot; }, \u0026quot;discovery\u0026quot;: { \u0026quot;properties\u0026quot;: { \u0026quot;refresh\u0026quot;: { \u0026quot;type\u0026quot;: \u0026quot;object\u0026quot; } } }, \u0026quot;enabled\u0026quot;: { \u0026quot;type\u0026quot;: \u0026quot;boolean\u0026quot; }, \u0026quot;endpoint\u0026quot;: { \u0026quot;type\u0026quot;: \u0026quot;keyword\u0026quot; }, \u0026quot;endpoints\u0026quot;: { \u0026quot;type\u0026quot;: \u0026quot;keyword\u0026quot; }, \u0026quot;host\u0026quot;: { \u0026quot;type\u0026quot;: \u0026quot;keyword\u0026quot;, \u0026quot;copy_to\u0026quot;: [ \u0026quot;search_text\u0026quot; ] }, \u0026quot;hosts\u0026quot;: { \u0026quot;type\u0026quot;: \u0026quot;keyword\u0026quot; }, \u0026quot;labels\u0026quot;: { \u0026quot;properties\u0026quot;: { \u0026quot;health_status\u0026quot;: { \u0026quot;type\u0026quot;: \u0026quot;keyword\u0026quot;, \u0026quot;ignore_above\u0026quot;: 256 } } }, \u0026quot;location\u0026quot;: { \u0026quot;properties\u0026quot;: { \u0026quot;dc\u0026quot;: { \u0026quot;type\u0026quot;: \u0026quot;keyword\u0026quot; }, \u0026quot;provider\u0026quot;: { \u0026quot;type\u0026quot;: \u0026quot;keyword\u0026quot; }, \u0026quot;rack\u0026quot;: { \u0026quot;type\u0026quot;: \u0026quot;keyword\u0026quot; }, \u0026quot;region\u0026quot;: { \u0026quot;type\u0026quot;: \u0026quot;keyword\u0026quot; } } }, \u0026quot;monitored\u0026quot;: { \u0026quot;type\u0026quot;: \u0026quot;boolean\u0026quot; }, \u0026quot;name\u0026quot;: { \u0026quot;type\u0026quot;: \u0026quot;keyword\u0026quot;, \u0026quot;fields\u0026quot;: { \u0026quot;text\u0026quot;: { \u0026quot;type\u0026quot;: \u0026quot;text\u0026quot; } } }, \u0026quot;order\u0026quot;: { \u0026quot;type\u0026quot;: \u0026quot;integer\u0026quot; }, \u0026quot;owner\u0026quot;: { \u0026quot;properties\u0026quot;: { \u0026quot;department\u0026quot;: { \u0026quot;type\u0026quot;: \u0026quot;keyword\u0026quot;, \u0026quot;copy_to\u0026quot;: [ \u0026quot;search_text\u0026quot; ] }, \u0026quot;id\u0026quot;: { \u0026quot;type\u0026quot;: \u0026quot;keyword\u0026quot; }, \u0026quot;name\u0026quot;: { \u0026quot;type\u0026quot;: \u0026quot;keyword\u0026quot;, \u0026quot;copy_to\u0026quot;: [ \u0026quot;search_text\u0026quot; ] } } }, \u0026quot;project\u0026quot;: { \u0026quot;type\u0026quot;: \u0026quot;keyword\u0026quot;, \u0026quot;copy_to\u0026quot;: [ \u0026quot;search_text\u0026quot; ] }, \u0026quot;schema\u0026quot;: { \u0026quot;type\u0026quot;: \u0026quot;keyword\u0026quot; }, \u0026quot;search_text\u0026quot;: { \u0026quot;type\u0026quot;: \u0026quot;text\u0026quot;, \u0026quot;analyzer\u0026quot;: \u0026quot;suggest_text_search\u0026quot;, \u0026quot;index_prefixes\u0026quot;: { \u0026quot;min_chars\u0026quot;: 2, \u0026quot;max_chars\u0026quot;: 5 }, \u0026quot;index_phrases\u0026quot;: true }, \u0026quot;tags\u0026quot;: { \u0026quot;type\u0026quot;: \u0026quot;keyword\u0026quot;, \u0026quot;copy_to\u0026quot;: [ \u0026quot;search_text\u0026quot; ] }, \u0026quot;traffic_control\u0026quot;: { \u0026quot;properties\u0026quot;: { \u0026quot;max_bytes_per_node\u0026quot;: { \u0026quot;type\u0026quot;: \u0026quot;keyword\u0026quot; }, \u0026quot;max_connection_per_node\u0026quot;: { \u0026quot;type\u0026quot;: \u0026quot;keyword\u0026quot; }, \u0026quot;max_qps_per_node\u0026quot;: { \u0026quot;type\u0026quot;: \u0026quot;keyword\u0026quot; }, \u0026quot;max_wait_time_in_ms\u0026quot;: { \u0026quot;type\u0026quot;: \u0026quot;keyword\u0026quot; } } }, \u0026quot;updated\u0026quot;: { \u0026quot;type\u0026quot;: \u0026quot;date\u0026quot; }, \u0026quot;version\u0026quot;: { \u0026quot;type\u0026quot;: \u0026quot;keyword\u0026quot;, \u0026quot;copy_to\u0026quot;: [ \u0026quot;search_text\u0026quot; ] } } } Open index .infini_cluster #  POST .infini_cluster/_open Update console.yml #  v0.3版本在v0.2版本上新增了 pipeline 配置：\n- name: metadata_ingest auto_start: true keep_running: true processor: - metadata: bulk_size_in_mb: 10 bulk_max_docs_count: 5000 fetch_max_messages: 1000 elasticsearch: \u0026quot;default\u0026quot; queues: type: metadata category: elasticsearch when: cluster_available: [ \u0026quot;default\u0026quot; ] - name: activity_ingest auto_start: true keep_running: true processor: - activity: bulk_size_in_mb: 10 bulk_max_docs_count: 5000 fetch_max_messages: 1000 elasticsearch: \u0026quot;default\u0026quot; queues: category: elasticsearch activity: true consumer: group: activity when: cluster_available: [ \u0026quot;default\u0026quot; ] 先停止 console 程序，再在console.yml 配置文件中的 pipeline 模块下添加上面面的配置，然后再启动 console 程序。\n给索引 .infini_alert-history 配置生命周期 #  v0.3 新增了告警功能，告警功能存储执行记录的索引数据量很大，所以需要配置一下 ILM 如下：\nPUT _template/.infini_alert-history-rollover { \u0026quot;order\u0026quot; : 100000, \u0026quot;index_patterns\u0026quot; : [ \u0026quot;.infini_alert-history*\u0026quot; ], \u0026quot;settings\u0026quot; : { \u0026quot;index\u0026quot; : { \u0026quot;format\u0026quot; : \u0026quot;7\u0026quot;, \u0026quot;lifecycle\u0026quot; : { \u0026quot;name\u0026quot; : \u0026quot;infini_metrics-30days-retention\u0026quot;, \u0026quot;rollover_alias\u0026quot; : \u0026quot;.infini_alert-history\u0026quot; }, \u0026quot;codec\u0026quot; : \u0026quot;best_compression\u0026quot;, \u0026quot;number_of_shards\u0026quot; : \u0026quot;1\u0026quot;, \u0026quot;translog.durability\u0026quot;:\u0026quot;async\u0026quot; } }, \u0026quot;mappings\u0026quot; : { \u0026quot;dynamic_templates\u0026quot; : [ { \u0026quot;strings\u0026quot; : { \u0026quot;mapping\u0026quot; : { \u0026quot;ignore_above\u0026quot; : 256, \u0026quot;type\u0026quot; : \u0026quot;keyword\u0026quot; }, \u0026quot;match_mapping_type\u0026quot; : \u0026quot;string\u0026quot; } } ] }, \u0026quot;aliases\u0026quot; : { } } DELETE .infini_alert-history DELETE .infini_alert-history-00001 PUT .infini_alert-history-00001 { \u0026quot;settings\u0026quot;: { \u0026quot;index.lifecycle.rollover_alias\u0026quot;:\u0026quot;.infini_alert-history\u0026quot; , \u0026quot;refresh_interval\u0026quot;: \u0026quot;5s\u0026quot; }, \u0026quot;aliases\u0026quot;:{ \u0026quot;.infini_alert-history\u0026quot;:{ \u0026quot;is_write_index\u0026quot;:true } }, \u0026quot;mappings\u0026quot;: { \u0026quot;properties\u0026quot; : { \u0026quot;condition\u0026quot; : { \u0026quot;properties\u0026quot; : { \u0026quot;items\u0026quot; : { \u0026quot;properties\u0026quot; : { \u0026quot;expression\u0026quot; : { \u0026quot;type\u0026quot; : \u0026quot;keyword\u0026quot;, \u0026quot;ignore_above\u0026quot; : 256 }, \u0026quot;minimum_period_match\u0026quot; : { \u0026quot;type\u0026quot; : \u0026quot;long\u0026quot; }, \u0026quot;operator\u0026quot; : { \u0026quot;type\u0026quot; : \u0026quot;keyword\u0026quot;, \u0026quot;ignore_above\u0026quot; : 256 }, \u0026quot;severity\u0026quot; : { \u0026quot;type\u0026quot; : \u0026quot;keyword\u0026quot;, \u0026quot;ignore_above\u0026quot; : 256 }, \u0026quot;values\u0026quot; : { \u0026quot;type\u0026quot; : \u0026quot;keyword\u0026quot;, \u0026quot;ignore_above\u0026quot; : 256 } } }, \u0026quot;operator\u0026quot; : { \u0026quot;type\u0026quot; : \u0026quot;keyword\u0026quot;, \u0026quot;ignore_above\u0026quot; : 256 } } }, \u0026quot;condition_result\u0026quot; : { \u0026quot;type\u0026quot; : \u0026quot;object\u0026quot;, \u0026quot;enabled\u0026quot; : false }, \u0026quot;context\u0026quot; : { \u0026quot;type\u0026quot; : \u0026quot;keyword\u0026quot;, \u0026quot;copy_to\u0026quot; : [ \u0026quot;search_text\u0026quot; ] }, \u0026quot;created\u0026quot; : { \u0026quot;type\u0026quot; : \u0026quot;date\u0026quot; }, \u0026quot;expression\u0026quot; : { \u0026quot;type\u0026quot; : \u0026quot;keyword\u0026quot;, \u0026quot;copy_to\u0026quot; : [ \u0026quot;search_text\u0026quot; ] }, \u0026quot;id\u0026quot; : { \u0026quot;type\u0026quot; : \u0026quot;keyword\u0026quot; }, \u0026quot;is_escalated\u0026quot; : { \u0026quot;type\u0026quot; : \u0026quot;boolean\u0026quot; }, \u0026quot;is_notified\u0026quot; : { \u0026quot;type\u0026quot; : \u0026quot;boolean\u0026quot; }, \u0026quot;message\u0026quot; : { \u0026quot;type\u0026quot; : \u0026quot;keyword\u0026quot;, \u0026quot;ignore_above\u0026quot; : 256 }, \u0026quot;objects\u0026quot; : { \u0026quot;type\u0026quot; : \u0026quot;keyword\u0026quot;, \u0026quot;copy_to\u0026quot; : [ \u0026quot;search_text\u0026quot; ] }, \u0026quot;resource_id\u0026quot; : { \u0026quot;type\u0026quot; : \u0026quot;keyword\u0026quot; }, \u0026quot;resource_name\u0026quot; : { \u0026quot;type\u0026quot; : \u0026quot;keyword\u0026quot; }, \u0026quot;rule_id\u0026quot; : { \u0026quot;type\u0026quot; : \u0026quot;keyword\u0026quot; }, \u0026quot;rule_name\u0026quot; : { \u0026quot;type\u0026quot; : \u0026quot;keyword\u0026quot; }, \u0026quot;search_text\u0026quot; : { \u0026quot;type\u0026quot; : \u0026quot;text\u0026quot;, \u0026quot;analyzer\u0026quot; : \u0026quot;suggest_text_search\u0026quot;, \u0026quot;index_prefixes\u0026quot; : { \u0026quot;min_chars\u0026quot; : 2, \u0026quot;max_chars\u0026quot; : 5 }, \u0026quot;index_phrases\u0026quot; : true }, \u0026quot;severity\u0026quot; : { \u0026quot;type\u0026quot; : \u0026quot;keyword\u0026quot; }, \u0026quot;state\u0026quot; : { \u0026quot;type\u0026quot; : \u0026quot;keyword\u0026quot;, \u0026quot;ignore_above\u0026quot; : 256 }, \u0026quot;title\u0026quot; : { \u0026quot;type\u0026quot; : \u0026quot;keyword\u0026quot; }, \u0026quot;updated\u0026quot; : { \u0026quot;type\u0026quot; : \u0026quot;date\u0026quot; } } } } 升级常见问题 #  问题描述1 #  重复的索引index数据\n解决方案 #   停止 console 删除索引.infini_index 启动 console  问题描述2 #  重复的节点node数据\n解决方案 #   停止 console 删除索引 .infini_node 启动 console  问题描述3 #  data节点有监控数据，非data节点（master、client等）没有监控数据，如下图非data节点所示：\n解决方案 #  建议升级到最新版。\n问题描述4 #  页面出现空白，JS报错。\n解决方案 #  建议升级到最新版，并将具体报错信息反馈给我们。\n反馈 #  如有其他任何问题和建议，请通过右侧的反馈功能或点击 这里提交给我们，我们将持续优化，感谢您的支持！\n"});index.add({'id':67,'href':'/docs/latest/gateway/references/processors/','title':"离线处理器",'section':"功能手册",'content':"服务管道 #  什么是服务管道 #  服务管道（Pipeline）是用于离线处理任务的功能组合，和在线请求的过滤器一样使用管道设计模式。 处理器（Processor）是服务管道的基础单位，每个处理组件一般专注做一件事情，根据需要灵活组装，灵活插拔。\n管道定义 #  一个典型的管道服务定义如下：\npipeline: - name: request_logging_index auto_start: true keep_running: true processor: - json_indexing: index_name: \u0026quot;gateway_requests\u0026quot; elasticsearch: \u0026quot;dev\u0026quot; input_queue: \u0026quot;request_logging\u0026quot; idle_timeout_in_seconds: 1 worker_size: 1 bulk_size_in_mb: 10 #in MB 上面的配置里面，定义了一个名为 request_logging_index 的处理管道，processor 参数定义了该管道的若干处理单元，依次执行。\n参数说明 #  管道定义的相关参数说明如下：\n   名称 类型 说明     name string 管道的名称，唯一不能重复   auto_start bool 是否随着网关自启动，也就是立即执行该任务   keep_running bool 网关执行完毕之后是否继续重头开始执行   retry_delay_in_ms int 该任务再次执行的最少等待时间，默认 5000 毫秒   processor array 该管道依次执行的处理器列表    处理器列表 #  任务调度 #    dag  索引写入 #    bulk_indexing  json_indexing  indexing_merge  queue_consumer  索引对比 #    dump_hash  index_diff  请求处理 #    flow_runner  请求重放 #    replay  "});index.add({'id':68,'href':'/docs/latest/console/reference/alerting/variables/','title':"模板变量",'section':"告警管理",'content':"模板变量 #  简介 #  自定义告警触发事件内容时，除了自己撰写的固定文案外，事件标题、事件内容等也支持模板语法。可以使用事件中的字段实现文案的渲染。\n模板变量 #  用于渲染字段的语法为{{ .字段名 }}，可用于模板内容渲染的变量字段如下：\n   变量字段名 字段类型 说明 示例     rule_id string rule uuid c9f663tath2e5a0vksjg   rule_name string rule name High CPU usage   resource_id string resource uuid c9f663tath2e5a0vksjg   resource_name string resource name es-v716   event_id string identifier for check details c9f663tath2e5a0vksjx   timestamp number Millisecond timestamp 1654595042399   first_group_value string The first value of group_values in results c9aikmhpdamkiurn1vq0   first_threshold string The first value of threshold in results 90   priority string The highest priority in results critical   title string event title Node ({{.first_group_value}}) disk used \u0026gt;= 90%   message string event content EventID：{{.event_id}}; Cluster：{{.resource_name}}   results array result of groups    ┗ threshold array  [\u0026ldquo;90\u0026rdquo;]   ┗ priority string  high   ┗ group_values array  [\u0026ldquo;cluster-xxx\u0026rdquo;, \u0026ldquo;node-xxx\u0026rdquo;]   ┗ issue_timestamp number Millisecond timestamp 1654595042399   ┗ result_value float  91.2   ┗ relation_values map  {a:100, b:91.2}    变量使用示例 #  示例1:\n{\u0026quot;content\u0026quot;:\u0026quot;【Alerting】Event ID: {{.event_id}}, Cluster：{{.resource_name}}\u0026quot;} 示例2(数组遍历):\n{{range .results}} Cluster ID: {{index .group_values 0}} {{end}} 模板函数 #  除了直接展示告警事件中的字段值外，还支持使用模板函数对字段值进行进一步处理，优化输出。\n函数支持额外参数，当无需或不传递参数时，可以直接使用以下语法进行使用：\n{{ \u0026lt;模板变量\u0026gt; | \u0026lt;模板函数\u0026gt; }}\n具体实例如下：\n模板函数不带参数：\n告警事件触发时间：{{ .timestamp | datetime }} 模板函数带参数：\n告警事件触发时间：{{ .timestamp | datetime_in_zone \u0026quot;Asia/Shanghai\u0026quot; }} 多个函数组合使用：\n字节类型的数值格式化后再转位大写：{{.result_value | format_bytes 2 ｜ to_upper}} 完整的模板函数列表如下：\n   模板函数 参数 说明     to_fixed 固定小数位数 float类型数值保留N位小数位\n示例：{{.result_value | to_fixed 2}}\n输出：10.35   format_bytes 固定小数位数 字节类型数值格式化\n示例：{{.result_value | format_bytes 2}}\n输出：10.35gb   date  时间戳转为UTC日期\n示例：{{.timestamp | date}}\n输出：2022-05-01   date_in_zone 时区 时间戳转为当前区域日期\n示例：{{.timestamp | date_in_zone \u0026quot;Asia/Shanghai\u0026quot;}}\n输出：2022-05-01   datetime  时间戳转为UTC时间\n示例：{{.timestamp | datetime}}\n输出：2022-05-01 10:10:10   datetime_in_zone 时区 时间戳转为当前区域时间\n示例：{{.timestamp | datetime_in_zone \u0026quot;Asia/Shanghai\u0026quot;}}\n输出：2022-05-01 10:10:10   to_lower  英文字符转为小写\n示例：{{.resource_name | to_lower }}\n输出：cluster   to_upper  英文字符转为大写\n示例：{{.resource_name | to_upper }}\n输出：CLUSTER   add 数值类型 数值相加\n示例：{{.result_value | add 1 }}\n输出：2   sub 数值类型 数值相减\n示例：{{sub .result_value 1 }}\n输出：0   mul 数值类型 数值相乘\n示例：{{mul .result_value 3 2 }}\n输出：6   div 数值类型 数值相除\n示例：{{div .result_value 2 }}\n输出：0.5    常用模板语法 #  array 数组遍历：\n{{range .results}} priority: {{.priority}} {{end}} 通过数组下标取值：\n示例:group_values = [\u0026quot;value1\u0026quot;,\u0026quot;value2\u0026quot;,\u0026quot;value3\u0026quot;]\n{{index .group_values 0}} #输出值为：value1 {{index .group_values 2}} 输出值为：value3 if 条件分支：\n{{if pipeline}} T1 {{else}} T0 {{end}} 示例:\n{{if eq .priority \u0026quot;critical\u0026quot;}} \u0026quot;#C91010\u0026quot; {{else if eq .priority \u0026quot;high\u0026quot;}} \u0026quot;#EB4C21\u0026quot; {{else}} \u0026quot;#FFB449\u0026quot; {{end}} 完整的比较运算符用法：\neq Returns the boolean truth of arg1 == arg2 ne Returns the boolean truth of arg1 != arg2 lt Returns the boolean truth of arg1 \u0026lt; arg2 le Returns the boolean truth of arg1 \u0026lt;= arg2 gt Returns the boolean truth of arg1 \u0026gt; arg2 ge Returns the boolean truth of arg1 \u0026gt;= arg2   Slack message 模板完整示例 ...  { \u0026quot;blocks\u0026quot;: [ { \u0026quot;type\u0026quot;: \u0026quot;section\u0026quot;, \u0026quot;text\u0026quot;: { \u0026quot;type\u0026quot;: \u0026quot;mrkdwn\u0026quot;, \u0026quot;text\u0026quot;: \u0026quot;【test201】Alerting:\\n\u0026lt;http://localhost:8000/#/alerting/alert/{{.event_id}}|{{.title}}\u0026gt; \u0026lt;@username\u0026gt;\u0026quot; } }, { \u0026quot;type\u0026quot;: \u0026quot;section\u0026quot;, \u0026quot;text\u0026quot;: { \u0026quot;type\u0026quot;: \u0026quot;mrkdwn\u0026quot;, \u0026quot;text\u0026quot;: \u0026quot;*Timestamp:* {{.issue_timestamp | datetime}}\u0026quot; } } ], \u0026quot;attachments\u0026quot;: [ {{range .results}} { \u0026quot;color\u0026quot;: {{if eq .priority \u0026quot;critical\u0026quot;}} \u0026quot;#C91010\u0026quot; {{else if eq .priority \u0026quot;high\u0026quot;}} \u0026quot;#EB4C21\u0026quot; {{else}} \u0026quot;#FFB449\u0026quot; {{end}}, \u0026quot;blocks\u0026quot;: [ { \u0026quot;type\u0026quot;: \u0026quot;section\u0026quot;, \u0026quot;fields\u0026quot;: [ { \u0026quot;type\u0026quot;: \u0026quot;mrkdwn\u0026quot;, \u0026quot;text\u0026quot;: \u0026quot;*Cluster:* {{index .group_values 0}}\u0026quot; }, { \u0026quot;type\u0026quot;: \u0026quot;mrkdwn\u0026quot;, \u0026quot;text\u0026quot;: \u0026quot;*Node:* {{index .group_values 1}}\u0026quot; }, { \u0026quot;type\u0026quot;: \u0026quot;mrkdwn\u0026quot;, \u0026quot;text\u0026quot;: \u0026quot;*Threshold:* {{index .threshold 0}}\u0026quot; }, { \u0026quot;type\u0026quot;: \u0026quot;mrkdwn\u0026quot;, \u0026quot;text\u0026quot;: \u0026quot;*Priority:* {{.priority}}\u0026quot; }, { \u0026quot;type\u0026quot;: \u0026quot;mrkdwn\u0026quot;, \u0026quot;text\u0026quot;: \u0026quot;*Monitoring value:* {{.result_value}}\u0026quot; }, { \u0026quot;type\u0026quot;: \u0026quot;mrkdwn\u0026quot;, \u0026quot;text\u0026quot;: \u0026quot;*Disk usage:* {{.relation_values.a | format_bytes 2 | to_upper}}\u0026quot; } ] } ] }, {{end}} ] } 更多模板语法点击查看\n   "});index.add({'id':69,'href':'/docs/latest/gateway/tutorial/es-hadoop_integration/','title':"与 Elasticsearch-Hadoop 集成",'section':"动手教程",'content':"与 Elasticsearch-Hadoop 集成 #  Elasticsearch-Hadoop 默认会通过某个种子节点拿到后端的所有 Elasticsearch 节点，可能存在热点和请求分配不合理的情况， 为了提高后端 Elasticsearch 节点的资源利用率，可以通过极限网关来实现后端 Elasticsearch 节点访问的精准路由。\n写入加速 #  如果是通过 Elasticsearch-Hadoop 来进行数据导入，可以通过修改 Elasticsearch-Hadoop 程序的以下参数来访问极限网关来提升写入吞吐，如下：\n   名称 类型 说明     es.nodes string 设置访问网关的地址列表，如：localhost:8000,localhost:8001   es.nodes.discovery bool 设置为 false，不采用 sniff 模式，只访问配置的后端节点列表   es.nodes.wan.only bool 设置为 true，代理模式，强制走网关地址   es.batch.size.entries int 适当调大批次文档数，提升吞吐，如 5000   es.batch.size.bytes string 适当调大批次传输大小，提升吞吐，如 20mb   es.batch.write.refresh bool 设置为 false，避免主动刷新，提升吞吐    相关链接 #    Elasticsearch-Hadoop 配置参数文档  "});index.add({'id':70,'href':'/docs/latest/gateway/tutorial/prometheus_integration/','title':"与 Prometheus 集成",'section':"动手教程",'content':"与 Prometheus 集成 #  极限网关支持将运行指标输出为 Prometheus 格式, 方便与 Prometheus 进行集成, 具体操作如下:\n统计信息接口 #  访问网关的 2900 接口,如下:\nhttp://localhost:2900/stats?format=prometheus ➜ ~ curl http://localhost:2900/stats\\?format\\=prometheus buffer_fasthttp_resbody_buffer_acquired{type=\u0026quot;gateway\u0026quot;, ip=\u0026quot;192.168.3.23\u0026quot;, name=\u0026quot;Orchid\u0026quot;, id=\u0026quot;cbvjphrq50kcnsu2a8v0\u0026quot;} 1 buffer_stats_acquired{type=\u0026quot;gateway\u0026quot;, ip=\u0026quot;192.168.3.23\u0026quot;, name=\u0026quot;Orchid\u0026quot;, id=\u0026quot;cbvjphrq50kcnsu2a8v0\u0026quot;} 7 buffer_stats_max_count{type=\u0026quot;gateway\u0026quot;, ip=\u0026quot;192.168.3.23\u0026quot;, name=\u0026quot;Orchid\u0026quot;, id=\u0026quot;cbvjphrq50kcnsu2a8v0\u0026quot;} 0 system_cpu{type=\u0026quot;gateway\u0026quot;, ip=\u0026quot;192.168.3.23\u0026quot;, name=\u0026quot;Orchid\u0026quot;, id=\u0026quot;cbvjphrq50kcnsu2a8v0\u0026quot;} 0 buffer_bulk_request_docs_acquired{type=\u0026quot;gateway\u0026quot;, ip=\u0026quot;192.168.3.23\u0026quot;, name=\u0026quot;Orchid\u0026quot;, id=\u0026quot;cbvjphrq50kcnsu2a8v0\u0026quot;} 1 buffer_fasthttp_resbody_buffer_inuse{type=\u0026quot;gateway\u0026quot;, ip=\u0026quot;192.168.3.23\u0026quot;, name=\u0026quot;Orchid\u0026quot;, id=\u0026quot;cbvjphrq50kcnsu2a8v0\u0026quot;} 0 stats_gateway_request_bytes{type=\u0026quot;gateway\u0026quot;, ip=\u0026quot;192.168.3.23\u0026quot;, name=\u0026quot;Orchid\u0026quot;, id=\u0026quot;cbvjphrq50kcnsu2a8v0\u0026quot;} 0 system_mem{type=\u0026quot;gateway\u0026quot;, ip=\u0026quot;192.168.3.23\u0026quot;, name=\u0026quot;Orchid\u0026quot;, id=\u0026quot;cbvjphrq50kcnsu2a8v0\u0026quot;} 31473664 ... 通过增加额外的参数 format=prometheus 即可返回 Prometheus 所需数据格式.\n配置 Prometheus 进行采集 #  修改配置文件: prometheus.yml\n# my global config global: scrape_interval: 15s # Set the scrape interval to every 15 seconds. Default is every 1 minute. evaluation_interval: 15s # Evaluate rules every 15 seconds. The default is every 1 minute. # scrape_timeout is set to the global default (10s). # Alertmanager configuration alerting: alertmanagers: - static_configs: - targets: # - alertmanager:9093 # Load rules once and periodically evaluate them according to the global 'evaluation_interval'. rule_files: # - \u0026quot;first_rules.yml\u0026quot; # - \u0026quot;second_rules.yml\u0026quot; # A scrape configuration containing exactly one endpoint to scrape: # Here it's Prometheus itself. scrape_configs: - job_name: \u0026quot;prometheus\u0026quot; scrape_interval: 5s # metrics_path defaults to '/metrics' metrics_path: /stats params: format: ['prometheus'] # scheme defaults to 'http'. static_configs: - targets: [\u0026quot;localhost:2900\u0026quot;] labels: group: 'infini' 启动 Prometheus #  启动之后,可以看到指标正常收集.\n然后就可以持续检测网关的运行状态了.\n"});index.add({'id':71,'href':'/docs/latest/gateway/tutorial/proxy_elasticsearch/','title':"为 Elasticsearch 无缝添加代理和基础安全",'section':"动手教程",'content':"为 Elasticsearch 无缝添加代理和基础安全 #  如果你的 Elasticsearch 版本比较多或者比较旧，或者没有设置 TLS 和身份信息，那么任何人都有可能直接访问 Elasticsearch，而使用极限网关可以快速的进行修复。\n使用 Elasticsearch 过滤器来转发请求 #  首先定义一个 Elasticsearch 的资源，如下：\nelasticsearch: - name: prod enabled: true endpoint: http://192.168.3.201:9200 然后可以使用如下的过滤器来转发请求到上面定义的 Elasticsearch 资源，名称为 prod：\n - elasticsearch: elasticsearch: prod 有关该过滤器的更多详情，请参考文档： elasticsearch filter\n添加一个简单的身份验证 #  我们进行添加一个基础的身份验证，来限制目标集群的访问\n - basic_auth: valid_users: medcl: passwd 开启 TLS #  如果设置了身份，但是没有设置 TLS 也是不行的，因为 HTTP 是明文传输协议，可以非常容易泄露密码，配置如下：\n - name: my_es_entry enabled: true router: my_router max_concurrency: 10000 network: binding: 0.0.0.0:8000 tls: enabled: true 通过地址 https://localhost:8000 就可以访问到 prod 的 Elasticsearch 集群。\n注意的是，这里监听的地址是 0.0.0.0，代表本机所有网卡上的 IP 都进行了监听， 为了安全起见，你可能需要修改为只监听本地地址或者指定的网卡 IP 地址。\n兼容 HTTP 访问 #  如果存在遗留的系统没有办法切换到新集群的，可以提供一个新的端口来进行 HTTP 的访问：\n - name: my_unsecure_es_entry enabled: true router: my_router max_concurrency: 10000 network: binding: 0.0.0.0:8001 tls: enabled: false 通过地址 http://localhost:8001 就可以访问到 prod 的 Elasticsearch 集群。\n完整配置如下 #  elasticsearch: - name: prod enabled: true endpoint: http://192.168.3.201:9200 entry: - name: my_es_entry enabled: true router: my_router max_concurrency: 10000 network: binding: 0.0.0.0:8000 tls: enabled: true - name: my_unsecure_es_entry enabled: true router: my_router max_concurrency: 10000 network: binding: 0.0.0.0:8001 tls: enabled: false flow: - name: default_flow filter: - basic_auth: valid_users: medcl: passwd - elasticsearch: elasticsearch: prod router: - name: my_router default_flow: default_flow 效果如下 #  现在使用网关来访问 Elasticsearch 就需要登陆了，如下：\n"});index.add({'id':72,'href':'/docs/latest/gateway/tutorial/proxy_kibana/','title':"为 Kibana 添加代理和基础安全",'section':"动手教程",'content':"为 Kibana 添加代理和基础安全 #  如果你的 Kibana 版本比较多或者比较旧，或者没有设置 TLS 和身份信息，那么任何人都有可能直接访问 Kibana，而使用极限网关可以快速的进行修复。\n使用 HTTP 过滤器来转发请求 #   - http: schema: \u0026quot;http\u0026quot; #https or http host: \u0026quot;192.168.3.188:5602\u0026quot; 添加身份验证 #   - basic_auth: valid_users: medcl: passwd 在路由里面可以替换静态资源 #   - method: - GET pattern: - \u0026quot;/plugins/kibanaReact/assets/illustration_integrations_lightmode.svg\u0026quot; flow: - replace_logo_flow 开启 TLS #   - name: my_es_entry enabled: true router: my_router max_concurrency: 10000 network: binding: 0.0.0.0:8000 tls: enabled: true 完整配置如下 #  entry: - name: my_es_entry enabled: true router: my_router max_concurrency: 10000 network: binding: 0.0.0.0:8000 skip_occupied_port: true tls: enabled: true flow: - name: logout_flow filter: - set_response: status: 401 body: \u0026quot;Success logout!\u0026quot; - drop: - name: replace_logo_flow filter: - redirect: uri: https://elasticsearch.cn/uploads/event/20211120/458c74ca3169260dbb2308dd06ef930a.png - name: default_flow filter: - basic_auth: valid_users: medcl: passwd - http: schema: \u0026quot;http\u0026quot; #https or http host: \u0026quot;192.168.3.188:5602\u0026quot; router: - name: my_router default_flow: default_flow rules: - method: - GET - POST pattern: - \u0026quot;/_logout\u0026quot; flow: - logout_flow - method: - GET pattern: - \u0026quot;/plugins/kibanaReact/assets/illustration_integrations_lightmode.svg\u0026quot; flow: - replace_logo_flow 效果如下 #  使用网关来访问 Kibana 就需要登陆了，如下：\n登陆之后，可以看到，Kibana 里面的资源也被替换掉了，如下：\n展望 #  通过极限网关，我们还可以挖掘更多玩法，比如可以替换 Kibana 里面的 Logo， 可以替换里面的 js，可以替换里面的 CSS 样式，通过 js 和 css 组合可以动态添加导航、页面、可视化等等。\n"});index.add({'id':73,'href':'/docs/latest/gateway/tutorial/path_rewrite_by_javascript/','title':"使用 JavaScript 脚本来进行复杂的查询改写",'section':"动手教程",'content':"使用 JavaScript 脚本来进行复杂的查询改写 #  有这么一个需求：\n 网关里怎样对跨集群搜索进行支持的呢？我想实现: 输入的搜索请求是 lp:9200/index1/_search 这个索引在3个集群上，需要跨集群检索，也就是网关能否改成 lp:9200/cluster01:index1,cluster02,index1,cluster03:index1/_search 呢？ 索引有一百多个，名称不一定是 app, 还可能多个索引一起的。\n 极限网关自带的过滤器 content_regex_replace 虽然可以实现字符正则替换，但是这个需求是带参数的变量替换，稍微复杂一点，没有办法直接用这个正则替换实现，有什么其他办法实现么？\n使用脚本过滤器 #  当然有的，上面的这个需求，理论上我们只需要将其中的索引 index1 匹配之后，替换为 cluster01:index1,cluster02,index1,cluster03:index1 就行了。\n答案就是使用自定义脚本来做，再复杂的业务逻辑都不是问题，都能通过自定义脚本来实现，一行脚本不行，那就两行。\n使用极限网关提供的 JavaScript 过滤器可以很灵活的实现这个功能，具体继续看。\n定义脚本 #  首先创建一个脚本文件，放在网关数据目录的 scripts 子目录下面，如下：\n➜ gateway ✗ tree data data └── gateway └── nodes └── c9bpg0ai4h931o4ngs3g ├── kvdb ├── queue ├── scripts │ └── index_path_rewrite.js └── stats 这个脚本的内容如下：\nfunction process(context) { var originalPath = context.Get(\u0026quot;_ctx.request.path\u0026quot;); var matches = originalPath.match(/\\/?(.*?)\\/_search/) var indexNames = []; if(matches \u0026amp;\u0026amp; matches.length \u0026gt; 1) { indexNames = matches[1].split(\u0026quot;,\u0026quot;) } var resultNames = [] var clusterNames = [\u0026quot;cluster01\u0026quot;, \u0026quot;cluster02\u0026quot;] if(indexNames.length \u0026gt; 0) { for(var i=0; i\u0026lt;indexNames.length; i++){ if(indexNames[i].length \u0026gt; 0) { for(var j=0; j\u0026lt;clusterNames.length; j++){ resultNames.push(clusterNames[j]+\u0026quot;:\u0026quot;+indexNames[i]) } } } } if (resultNames.length\u0026gt;0){ var newPath=\u0026quot;/\u0026quot;+resultNames.join(\u0026quot;,\u0026quot;)+\u0026quot;/_search\u0026quot;; context.Put(\u0026quot;_ctx.request.path\u0026quot;,newPath); } } 和普通的 JavaScript 一样，定义一个特定的函数 process 来处理请求里面的上下文信息，_ctx.request.path 是网关内置上下文的一个变量，用来获取请求的路径，通过 context.Get(\u0026quot;_ctx.request.path\u0026quot;) 在脚本里面进行访问。\n中间我们使用了 JavaScript 的正则匹配和字符处理，做了一些字符拼接，得到新的路径 newPath 变量，最后使用 context.Put(\u0026quot;_ctx.request.path\u0026quot;,newPath) 更新网关请求的路径信息，从而实现查询条件里面的参数替换。\n有关网关内置上下文的变量列表，请访问 Request Context\n定义网关 #  接下来，创建一个网关配置，并使用 javascript 过滤器调用该脚本，如下：\nentry: - name: my_es_entry enabled: true router: my_router max_concurrency: 10000 network: binding: 0.0.0.0:8000 flow: - name: default_flow filter: - dump: context: - _ctx.request.path - javascript: file: index_path_rewrite.js - dump: context: - _ctx.request.path - elasticsearch: elasticsearch: dev router: - name: my_router default_flow: default_flow elasticsearch: - name: dev enabled: true schema: http hosts: - 192.168.3.188:9206 上面的例子中，使用了一个 javascript 过滤器，并且指定了加载的脚本文件为 index_path_rewrite.js，并使用了两个 dump 过滤器来输出脚本运行前后的路径信息，最后再使用一个 elasticsearch 过滤器来转发请求给 Elasticsearch 进行查询。\n启动网关 #  我们启动网关测试一下，如下：\n➜ gateway ✗ ./bin/gateway ___ _ _____ __ __ __ _ / _ \\ /_\\ /__ \\/__\\/ / /\\ \\ \\/_\\ /\\_/\\ / /_\\///_\\\\ / /\\/_\\ \\ \\/ \\/ //_\\\\\\_ _/ / /_\\\\/ _ \\/ / //__ \\ /\\ / _ \\/ \\ \\____/\\_/ \\_/\\/ \\__/ \\/ \\/\\_/ \\_/\\_/ [GATEWAY] A light-weight, powerful and high-performance elasticsearch gateway. [GATEWAY] 1.0.0_SNAPSHOT, 2022-04-18 07:11:09, 2023-12-31 10:10:10, 8062c4bc6e57a3fefcce71c0628d2d4141e46953 [04-19 11:41:29] [INF] [app.go:174] initializing gateway. [04-19 11:41:29] [INF] [app.go:175] using config: /Users/medcl/go/src/infini.sh/gateway/gateway.yml. [04-19 11:41:29] [INF] [instance.go:72] workspace: /Users/medcl/go/src/infini.sh/gateway/data/gateway/nodes/c9bpg0ai4h931o4ngs3g [04-19 11:41:29] [INF] [app.go:283] gateway is up and running now. [04-19 11:41:30] [INF] [api.go:262] api listen at: http://0.0.0.0:2900 [04-19 11:41:30] [INF] [entry.go:312] entry [my_es_entry] listen at: http://0.0.0.0:8000 [04-19 11:41:30] [INF] [module.go:116] all modules are started [04-19 11:41:30] [INF] [actions.go:349] elasticsearch [dev] is available 执行测试 #  运行下面的查询来验证查询结果，如下：\ncurl localhost:8000/abc,efg/_search 可以看到网关通过 dump 过滤器输出的调试信息：\n---- DUMPING CONTEXT ---- _ctx.request.path : /abc,efg/_search ---- DUMPING CONTEXT ---- _ctx.request.path : /cluster01:abc,cluster02:abc,cluster01:efg,cluster02:efg/_search 查询条件按照我们的需求进行了改写，Nice！\n重写 DSL 查询语句 #  好吧，我们刚刚只是修改了查询的索引而已，那么查询请求的 DSL 呢？行不行？\n那自然是可以的嘛，瞧下面的例子:\nfunction process(context) { var originalDSL = context.Get(\u0026quot;_ctx.request.body\u0026quot;); if (originalDSL.length \u0026gt;0){ var jsonObj=JSON.parse(originalDSL); jsonObj.size=123; jsonObj.aggs= { \u0026quot;test1\u0026quot;: { \u0026quot;terms\u0026quot;: { \u0026quot;field\u0026quot;: \u0026quot;abc\u0026quot;, \u0026quot;size\u0026quot;: 10 } } } context.Put(\u0026quot;_ctx.request.body\u0026quot;,JSON.stringify(jsonObj)); } } 先是获取查询请求，然后转换成 JSON 对象，之后任意修改查询对象就行了，保存回去，搞掂。\n测试一下:\n curl -XPOST localhost:8000/abc,efg/_search -d'{\u0026quot;query\u0026quot;:{}}' 输出:\n---- DUMPING CONTEXT ---- _ctx.request.path : /abc,efg/_search _ctx.request.body : {\u0026quot;query\u0026quot;:{}} [04-19 18:14:24] [INF] [reverseproxy.go:255] elasticsearch [dev] hosts: [] =\u0026gt; [192.168.3.188:9206] ---- DUMPING CONTEXT ---- _ctx.request.path : /abc,efg/_search _ctx.request.body : {\u0026quot;query\u0026quot;:{},\u0026quot;size\u0026quot;:123,\u0026quot;aggs\u0026quot;:{\u0026quot;test1\u0026quot;:{\u0026quot;terms\u0026quot;:{\u0026quot;field\u0026quot;:\u0026quot;abc\u0026quot;,\u0026quot;size\u0026quot;:10}}}} 是不是感觉解锁了新的世界？\n结论 #  通过使用 Javascript 脚本过滤器，我们可以非常灵活的进行复杂逻辑的操作来满足我们的业务需求。\n"});index.add({'id':74,'href':'/docs/latest/console/resources/','title':"其它资源",'section':"INFINI Console",'content':"其它资源 #  这里是一些和 INFINI Console 有关的外部有用资源。\n文章 #    INFINI Console 最新的 0.3 版本正式发布！  视频 #    INFINI Console 首发版本 Demo 演示  INFINI Console v0.3 版本 Demo 演示  INFINI Console 安全功能简介  如何指定内置账户名和密码启动 INFINI Console  如何使用 INFINI Console 轻松创建一个 Elasticsearch “游客”账号  如何给不同 INFINI Console 账户分配不同 Elasticsearch 集群访问权限  如何给 INFINI Console 账户分配 Elasticsearch 索引级别权限  INFINI Console 的告警功能概览  如何监控 Elasticsearch 集群健康状态  如何监控 Elasticsearch 集群节点磁盘使用率  如何监控 Elasticsearch 集群节点的 CPU 使用率  "});index.add({'id':75,'href':'/docs/latest/gateway/resources/','title':"其它资源",'section':"INFINI Gateway",'content':"其它资源 #  这里是一些和极限网关有关的外部有用资源。\n项目 #    Elasticsearch INFINI Gateway On Kubernetes HA(高可用方案)  文章 #    Elasticsearch 极限网关测试版本发布  极限网关 INFINI Gateway 初体验  INFINI Gateway 的使用方法和使用心得分享  性能爆表！INFINI Gateway 性能与压力测试结果  四倍索引速度提升, 有点东西  使用极限网关来进行 Elasticsearch 跨集群跨版本查询及所有其它请求  Elasticsearch 容灾技术探讨和测试  使用极限网关解决ES集群架构的升级  使用极限网关来处置 Elasticsearch 的 Apache Log4j 漏洞  Elasticsearch 多种跨机房灾备方案对比与实战解读  INFINI Gateway：Elasticsearch 极限网关入门手册  极限网关初探（1）安装启动  极限网关初探（2）配置  极限网关无缝集成 LDAP  通过极限网关无缝复制业务集群数据  使用极限网关代替 Nginx 来访问 ECE  通过极限网关来控制索引写入  通过极限网关来加速索引写入速度  通过网关无缝复制 ELK 日志集群数据  自建 ES 集群通过极限网关无缝迁移到阿里云  视频 #    极限网关是什么  极限网关下载安装介绍  如何将极限网关安装为系统服务  极限网关配置说明  极限网关高可用设置  Elasticsearch 异地容灾方案  极限网关的配置动态加载  极限网关的模板化配置  "});index.add({'id':76,'href':'/docs/latest/gateway/tutorial/fix_count_in_search_response/','title':"兼容不同版本的响应 Count 结构",'section':"动手教程",'content':"兼容不同版本的查询响应结果的 Count 结构 #  Elasticsearch 在 7.0 之后的版本中，为了优化性能，搜索结果的命中数默认不进行精确的计数统计，同时对搜索结果的响应体进行了调整， 这样势必会造成已有代码的不兼容，如何快速修复呢？\n结构对比 #  首先来对比下前后差异：\n7 之前的搜索结构如下，total 显示的具体的数值：\n{ \u0026quot;took\u0026quot;: 53, \u0026quot;timed_out\u0026quot;: false, \u0026quot;_shards\u0026quot;: { \u0026quot;total\u0026quot;: 1, \u0026quot;successful\u0026quot;: 1, \u0026quot;skipped\u0026quot;: 0, \u0026quot;failed\u0026quot;: 0 }, \u0026quot;hits\u0026quot;: { \u0026quot;total\u0026quot;: 0, \u0026quot;max_score\u0026quot;: null, \u0026quot;hits\u0026quot;: [] } } 7 之后的搜索结构如下，total 变成了一组描述范围的对象：\n{ \u0026quot;took\u0026quot;: 3, \u0026quot;timed_out\u0026quot;: false, \u0026quot;_shards\u0026quot;: { \u0026quot;total\u0026quot;: 1, \u0026quot;successful\u0026quot;: 1, \u0026quot;skipped\u0026quot;: 0, \u0026quot;failed\u0026quot;: 0 }, \u0026quot;hits\u0026quot;: { \u0026quot;total\u0026quot;: { \u0026quot;value\u0026quot;: 10000, \u0026quot;relation\u0026quot;: \u0026quot;gte\u0026quot; }, \u0026quot;max_score\u0026quot;: 1, \u0026quot;hits\u0026quot;: [] } } Elasticsearch 提供的参数 #  不过在 7 里面，Elasticsearch 也提供了一个参数来控制是否进行精确计数，通过在查询请求的 url 参数里面加上 rest_total_hits_as_int=true 即可使用旧的行为方式，默认未开启。\n文档链接：https://www.elastic.co/guide/en/elasticsearch/reference/current/search-search.html\n不过需要修改程序来添加这个参数，可能需要调整后端代码和前端分页及展示的相关，改动量可能不小。\n使用极限网关来快速修复 #  如果不希望修改程序，可以使用极限网关来快速修复相应的查询，并主动为搜索查询添加相应的查询参数，同时还可以限定为哪些请求来源进行添加， 比如，只对特定的业务调用方来进行调整，这里以 curl 命令来进行举例，只对来自 curl 调试的查询进行添加，示例如下：\nentry: - name: es_entrypoint enabled: true router: default network: binding: 0.0.0.0:8000 router: - name: default default_flow: main_flow flow: - name: main_flow filter: - set_request_query_args: args: - rest_total_hits_as_int -\u0026gt; true when: and: - contains: _ctx.request.path: \u0026quot;_search\u0026quot; - equals: _ctx.request.header.User-Agent: \u0026quot;curl/7.54.0\u0026quot; - record: stdout: true - elasticsearch: elasticsearch: es-server - dump: response_body: true elasticsearch: - name: es-server enabled: true endpoints: - http://192.168.3.188:9206 最后效果如下：\n如图 1 表示走浏览器访问网关的搜索结果，2 表示走命令行 curl 命令返回的搜索结果，其中通过 User-Agent 头信息可以匹配到 curl 命令，同时只对搜索条件附加参数，避免影响其他的请求。\n"});index.add({'id':77,'href':'/docs/latest/gateway/tutorial/routing_to_cluser_by_index/','title':"在 Kibana 里统一访问来自不同集群的索引",'section':"动手教程",'content':"在 Kibana 里统一访问来自不同集群的索引 #  现在有这么一个需求，客户根据需要将数据按照业务维度划分，将索引分别存放在了不同的三个集群， 将一个大集群拆分成多个小集群有很多好处，比如降低了耦合，带来了集群可用性和稳定性方面的好处，也避免了单个业务的热点访问造成其他业务的影响， 尽管拆分集群是很常见的玩法，但是管理起来不是那么方便了，尤其是在查询的时候，可能要分别访问三套集群各自的 API，甚至要切换三套不同的 Kibana 来访问集群的数据， 那么有没有办法将他们无缝的联合在一起呢？\n极限网关! #  答案自然是有的，通过将 Kibana 访问 Elasticsearch 的地址切换为极限网关的地址，我们可以将请求按照索引来进行智能的路由， 也就是当访问不同的业务索引时会智能的路由到不同的集群，如下图：\n上图，我们分别有 3 个不同的索引：\n apm-* erp-* mall-*  分别对应不同的三套 Elasticsearch 集群:\n ES1-APM ES2-ERP ES3-MALL  接下来我们来看如何在极限网关里面进行相应的配置来满足这个业务需求。\n配置集群信息 #  首先配置 3 个集群的连接信息。\nelasticsearch: - name: es1-apm enabled: true endpoints: - http://192.168.3.188:9206 - name: es2-erp enabled: true endpoints: - http://192.168.3.188:9207 - name: es3-mall enabled: true endpoints: - http://192.168.3.188:9208 配置服务 Flow #  然后，我们定义 3 个 Flow，分别对应用来访问 3 个不同的 Elasticsearch 集群，如下：\nflow: - name: es1-flow filter: - elasticsearch: elasticsearch: es1-apm - name: es2-flow filter: - elasticsearch: elasticsearch: es2-erp - name: es3-flow filter: - elasticsearch: elasticsearch: es3-mall 然后再定义一个 flow 用来进行路径的判断和转发，如下：\n - name: default-flow filter: - switch: remove_prefix: false path_rules: - prefix: \u0026quot;apm-\u0026quot; flow: es1-flow - prefix: \u0026quot;erp-\u0026quot; flow: es2-flow - prefix: \u0026quot;mall-\u0026quot; flow: es3-flow - flow: #default flow flows: - es1-flow 根据请求路径里面的索引前缀来匹配不同的索引，并转发到不同的 Flow。\n配置路由信息 #  接下来，我们定义路由信息，具体配置如下：\nrouter: - name: my_router default_flow: default-flow 指向上面定义的默认 flow 来统一请求的处理。\n定义服务及关联路由 #  最后，我们定义一个监听为 8000 端口的服务，用来提供给 Kibana 来进行统一的入口访问，如下：\nentry: - name: es_entry enabled: true router: my_router max_concurrency: 10000 network: binding: 0.0.0.0:8000 完整配置 #  最后的完整配置如下：\npath.data: data path.logs: log entry: - name: es_entry enabled: true router: my_router max_concurrency: 10000 network: binding: 0.0.0.0:8000 flow: - name: default-flow filter: - switch: remove_prefix: false path_rules: - prefix: \u0026quot;apm-\u0026quot; flow: es1-flow - prefix: \u0026quot;erp-\u0026quot; flow: es2-flow - prefix: \u0026quot;mall-\u0026quot; flow: es3-flow - flow: #default flow flows: - es1-flow - name: es1-flow filter: - elasticsearch: elasticsearch: es1-apm - name: es2-flow filter: - elasticsearch: elasticsearch: es2-erp - name: es3-flow filter: - elasticsearch: elasticsearch: es3-mall router: - name: my_router default_flow: default-flow elasticsearch: - name: es1-apm enabled: true endpoints: - http://192.168.3.188:9206 - name: es2-erp enabled: true endpoints: - http://192.168.3.188:9207 - name: es3-mall enabled: true endpoints: - http://192.168.3.188:9208 启动网关 #  直接启动网关，如下：\n➜ gateway git:(master) ✗ ./bin/gateway -config sample-configs/elasticsearch-route-by-index.yml ___ _ _____ __ __ __ _ / _ \\ /_\\ /__ \\/__\\/ / /\\ \\ \\/_\\ /\\_/\\ / /_\\///_\\\\ / /\\/_\\ \\ \\/ \\/ //_\\\\\\_ _/ / /_\\\\/ _ \\/ / //__ \\ /\\ / _ \\/ \\ \\____/\\_/ \\_/\\/ \\__/ \\/ \\/\\_/ \\_/\\_/ [GATEWAY] A light-weight, powerful and high-performance elasticsearch gateway. [GATEWAY] 1.0.0_SNAPSHOT, 2022-04-20 08:23:56, 2023-12-31 10:10:10, 51650a5c3d6aaa436f3c8a8828ea74894c3524b9 [04-21 13:41:21] [INF] [app.go:174] initializing gateway. [04-21 13:41:21] [INF] [app.go:175] using config: /Users/medcl/go/src/infini.sh/gateway/sample-configs/elasticsearch-route-by-index.yml. [04-21 13:41:21] [INF] [instance.go:72] workspace: /Users/medcl/go/src/infini.sh/gateway/data/gateway/nodes/c9bpg0ai4h931o4ngs3g [04-21 13:41:21] [INF] [app.go:283] gateway is up and running now. [04-21 13:41:21] [INF] [api.go:262] api listen at: http://0.0.0.0:2900 [04-21 13:41:21] [INF] [reverseproxy.go:255] elasticsearch [es1-apm] hosts: [] =\u0026gt; [192.168.3.188:9206] [04-21 13:41:21] [INF] [reverseproxy.go:255] elasticsearch [es2-erp] hosts: [] =\u0026gt; [192.168.3.188:9207] [04-21 13:41:21] [INF] [reverseproxy.go:255] elasticsearch [es3-mall] hosts: [] =\u0026gt; [192.168.3.188:9208] [04-21 13:41:21] [INF] [actions.go:349] elasticsearch [es2-erp] is available [04-21 13:41:21] [INF] [actions.go:349] elasticsearch [es1-apm] is available [04-21 13:41:21] [INF] [entry.go:312] entry [es_entry] listen at: http://0.0.0.0:8000 [04-21 13:41:21] [INF] [module.go:116] all modules are started [04-21 13:41:21] [INF] [actions.go:349] elasticsearch [es3-mall] is available [04-21 13:41:55] [INF] [reverseproxy.go:255] elasticsearch [es1-apm] hosts: [] =\u0026gt; [192.168.3.188:9206] 网关启动成功之后，就可以通过网关的 IP+8000 端口来访问目标 Elasticsearch 集群了。\n测试访问 #  首先通过 API 来访问测试一下，如下：\n➜ ~ curl http://localhost:8000/apm-2022/_search -v * Trying 127.0.0.1... * TCP_NODELAY set * Connected to localhost (127.0.0.1) port 8000 (#0) \u0026gt; GET /apm-2022/_search HTTP/1.1 \u0026gt; Host: localhost:8000 \u0026gt; User-Agent: curl/7.54.0 \u0026gt; Accept: */* \u0026gt; \u0026lt; HTTP/1.1 200 OK \u0026lt; Date: Thu, 21 Apr 2022 05:45:44 GMT \u0026lt; content-type: application/json; charset=UTF-8 \u0026lt; Content-Length: 162 \u0026lt; X-elastic-product: Elasticsearch \u0026lt; X-Backend-Cluster: es1-apm \u0026lt; X-Backend-Server: 192.168.3.188:9206 \u0026lt; X-Filters: filters-\u0026gt;elasticsearch \u0026lt; * Connection #0 to host localhost left intact {\u0026quot;took\u0026quot;:142,\u0026quot;timed_out\u0026quot;:false,\u0026quot;_shards\u0026quot;:{\u0026quot;total\u0026quot;:1,\u0026quot;successful\u0026quot;:1,\u0026quot;skipped\u0026quot;:0,\u0026quot;failed\u0026quot;:0},\u0026quot;hits\u0026quot;:{\u0026quot;total\u0026quot;:{\u0026quot;value\u0026quot;:0,\u0026quot;relation\u0026quot;:\u0026quot;eq\u0026quot;},\u0026quot;max_score\u0026quot;:null,\u0026quot;hits\u0026quot;:[]}}% 可以看到 apm-2022 指向了后端的 es1-apm 集群。\n继续测试，erp 索引的访问，如下：\n➜ ~ curl http://localhost:8000/erp-2022/_search -v * Trying 127.0.0.1... * TCP_NODELAY set * Connected to localhost (127.0.0.1) port 8000 (#0) \u0026gt; GET /erp-2022/_search HTTP/1.1 \u0026gt; Host: localhost:8000 \u0026gt; User-Agent: curl/7.54.0 \u0026gt; Accept: */* \u0026gt; \u0026lt; HTTP/1.1 200 OK \u0026lt; Date: Thu, 21 Apr 2022 06:24:46 GMT \u0026lt; content-type: application/json; charset=UTF-8 \u0026lt; Content-Length: 161 \u0026lt; X-Backend-Cluster: es2-erp \u0026lt; X-Backend-Server: 192.168.3.188:9207 \u0026lt; X-Filters: filters-\u0026gt;switch-\u0026gt;filters-\u0026gt;elasticsearch-\u0026gt;skipped \u0026lt; * Connection #0 to host localhost left intact {\u0026quot;took\u0026quot;:12,\u0026quot;timed_out\u0026quot;:false,\u0026quot;_shards\u0026quot;:{\u0026quot;total\u0026quot;:1,\u0026quot;successful\u0026quot;:1,\u0026quot;skipped\u0026quot;:0,\u0026quot;failed\u0026quot;:0},\u0026quot;hits\u0026quot;:{\u0026quot;total\u0026quot;:{\u0026quot;value\u0026quot;:0,\u0026quot;relation\u0026quot;:\u0026quot;eq\u0026quot;},\u0026quot;max_score\u0026quot;:null,\u0026quot;hits\u0026quot;:[]}}% 继续测试，mall 索引的访问，如下：\n➜ ~ curl http://localhost:8000/mall-2022/_search -v * Trying 127.0.0.1... * TCP_NODELAY set * Connected to localhost (127.0.0.1) port 8000 (#0) \u0026gt; GET /mall-2022/_search HTTP/1.1 \u0026gt; Host: localhost:8000 \u0026gt; User-Agent: curl/7.54.0 \u0026gt; Accept: */* \u0026gt; \u0026lt; HTTP/1.1 200 OK \u0026lt; Date: Thu, 21 Apr 2022 06:25:08 GMT \u0026lt; content-type: application/json; charset=UTF-8 \u0026lt; Content-Length: 134 \u0026lt; X-Backend-Cluster: es3-mall \u0026lt; X-Backend-Server: 192.168.3.188:9208 \u0026lt; X-Filters: filters-\u0026gt;switch-\u0026gt;filters-\u0026gt;elasticsearch-\u0026gt;skipped \u0026lt; * Connection #0 to host localhost left intact {\u0026quot;took\u0026quot;:8,\u0026quot;timed_out\u0026quot;:false,\u0026quot;_shards\u0026quot;:{\u0026quot;total\u0026quot;:5,\u0026quot;successful\u0026quot;:5,\u0026quot;skipped\u0026quot;:0,\u0026quot;failed\u0026quot;:0},\u0026quot;hits\u0026quot;:{\u0026quot;total\u0026quot;:0,\u0026quot;max_score\u0026quot;:null,\u0026quot;hits\u0026quot;:[]}}% 完美转发。\n其他方式 #  除了使用 switch 过滤器，使用路由本身的规则也是可以实现，具体示例配置如下：\nflow: - name: default_flow filter: - echo: message: \u0026quot;hello world\u0026quot; - name: mall_flow filter: - echo: message: \u0026quot;hello mall indices\u0026quot; - name: apm_flow filter: - echo: message: \u0026quot;hello apm indices\u0026quot; - name: erp_flow filter: - echo: message: \u0026quot;hello erp indices\u0026quot; router: - name: my_router default_flow: default_flow rules: - method: - \u0026quot;*\u0026quot; pattern: - \u0026quot;/apm-{suffix:.*}/\u0026quot; - \u0026quot;/apm-{suffix:.*}/{any:.*}\u0026quot; flow: - apm_flow - method: - \u0026quot;*\u0026quot; pattern: - \u0026quot;/erp-{suffix:.*}/\u0026quot; - \u0026quot;/erp-{suffix:.*}/{any:.*}\u0026quot; flow: - erp_flow - method: - \u0026quot;*\u0026quot; pattern: - \u0026quot;/mall-{suffix:.*}/\u0026quot; - \u0026quot;/mall-{suffix:.*}/{any:.*}\u0026quot; flow: - mall_flow 极限网关功能强大，实现一个功能的方式可以有很多种，这里暂不展开。\n修改 Kibana 配置 #  修改 Kibana 的配置文件: kibana.yml，替换 Elasticsearch 的地址为网关地址(http://192.168.3.200:8000)，如下：\nelasticsearch.hosts: [\u0026quot;http://192.168.3.200:8000\u0026quot;] 重启 Kibana 让配置生效。\n效果如下 #  可以看到，在一个 Kibana 的开发者工具里面，我们已经可以像操作一个集群一样来同时读写实际上来自三个不同集群的索引数据了。\n展望 #  通过极限网关，我们还可以非常灵活的进行在线请求的流量编辑，动态组合不同集群的操作。\n"});index.add({'id':78,'href':'/docs/latest/gateway/references/config/','title':"其它配置",'section':"功能手册",'content':"其它配置 #  系统配置 #  系统配置主要用来设置极限网关的基础属性：\n   名称 类型 说明     path.data string 数据目录，默认为 data   path.logs string 日志目录，默认为 log   path.configs string 配置目录，默认为 config   log.level string 日志级别，默认为 info   log.debug bool 是否开启调试模式，当开启的时候，一旦出现异常程序直接退出，打印完整堆栈，仅用于调试定位故障点，默认为 false，生产环境不要开启，可能丢数据   log.disable_file_output bool 是否关闭本地文件的日志输出，默认为 false，容器环境不希望本地日志输出的可以开启本参数   allow_multi_instance bool 是否运行单个机器上面启动多个网关实例，默认为 false   skip_instance_detect bool 是否跳过网关的实例检测，默认为 false   max_num_of_instances int 网关实例的最大个数，默认为 5   configs.auto_reload bool 是否支持 path.configs 里面配置的动态加载    配置模板 #  示例：\nconfigs.template: - name: \u0026quot;es_gw1\u0026quot; path: ./sample-configs/config_template.tpl variable: name: \u0026quot;es_gw1\u0026quot; binding_host: \u0026quot;0.0.0.0:8000\u0026quot; tls_on_entry: true elasticsearch_endpoint: \u0026quot;http://localhost:9200\u0026quot;    名称 类型 说明     configs.template array 配置模板，可以指定多个模板和对应的参数   configs.template[].name string 配置的名称   configs.template[].path string 模板配置路径   configs.template[].variable map 模板的参数设置，变量在模板里面的用法：$[[变量名]]    配置本地磁盘队列 #  示例：\ndisk_queue: upload_to_s3: true s3: server: my_blob_store location: cn-beijing-001 bucket: infini-store max_bytes_per_file: 102400    名称 类型 说明     disk_queue.min_msg_size int 发送到队列单条消息的最小字节限制，默认 1   disk_queue.max_msg_size int 发送到队列单条消息的最大字节限制，默认 104857600，即 100MB   disk_queue.sync_every_records int 每隔多少条记录进行一次 sync 磁盘同步操作，默认 1000   disk_queue.sync_timeout_in_ms int 每隔多长时间进行一次 sync 磁盘同步操作，默认 1000 毫秒   disk_queue.max_bytes_per_file int 本地磁盘队列单个文件的最大值，超过此大小自动滚动新文件，默认 104857600，即 100MB   disk_queue.max_used_bytes int 本地磁盘队列可允许的最大存储使用空间大小   disk_queue.warning_free_bytes int 磁盘达到告警阈值的空闲存储空间大小，默认 10737418240 即 10GB   disk_queue.reserved_free_bytes int 磁盘空闲存储空间大小的保护值，达到会变成只读，不允许写，默认 5368709120 即 5GB   disk_queue.upload_to_s3 bool 是否将磁盘队列文件上传到 S3，默认 false   disk_queue.s3.async bool 是否异步上传到 S3 服务器   disk_queue.s3.server string S3 服务器 ID   disk_queue.s3.location string S3 服务器位置   disk_queue.s3.bucket string S3 服务器 Bucket   disk_queue.retention.max_num_of_local_files int 上传 s3 完的文件，按照最新的文件排序，保留在本地磁盘上的最大文件数，默认 10   disk_queue.compress.segment.enabled bool 是否开启文件级别的压缩，默认 false    配置 S3 服务器资源 #  示例：\ns3: my_blob_store: endpoint: \u0026quot;192.168.3.188:9000\u0026quot; access_key: \u0026quot;admin\u0026quot; access_secret: \u0026quot;gogoaminio\u0026quot;    名称 类型 说明     s3.[id].endpoint string S3 服务器地址   s3.[id].access_key string S3 服务器 Key   s3.[id].access_secret string S3 服务器秘钥   s3.[id].token string S3 服务器 Token 信息   s3.[id].ssl bool S3 服务器是否开启了 TLS   s3.[id].skip_insecure_verify bool 是否忽略 TLS 证书校验    "});index.add({'id':79,'href':'/docs/latest/gateway/references/filters/basic_auth/','title':"basic_auth",'section':"在线过滤器",'content':"basic_auth #  描述 #  basic_auth 过滤器用来验证请求的身份认证信息，适用于简单的身份认证。\n配置示例 #  一个简单的示例如下：\nflow: - name: basic_auth filter: - basic_auth: valid_users: medcl: passwd medcl1: abc ... 参数说明 #     名称 类型 说明     valid_users map 用户名和密码    "});index.add({'id':80,'href':'/docs/latest/gateway/references/processors/bulk_indexing/','title':"bulk_indexing",'section':"离线处理器",'content':"bulk_indexing #  描述 #  bulk_indexing 处理器用来异步消费队列里面的 bulk 请求。\n配置示例 #  一个简单的示例如下：\npipeline: - name: bulk_request_ingest auto_start: true keep_running: true processor: - bulk_indexing: bulk_size_in_mb: 1 queue_selector.labels: type: bulk_reshuffle level: cluster 参数说明 #     名称 类型 说明     elasticsearch string 默认的 Elasticsearch 集群 ID,如果队列 Labels 里面没有指定 elasticsearch 的话会使用这个参数   idle_timeout_in_seconds int 消费队列的超时时间，默认 1, 即 1s   max_connection_per_node int 目标节点允许的最大连接数，默认 1   max_worker_size int 最大允许同时运行的 worker 大小,默认 10   bulk.compress bool 是否开启请求压缩   bulk.batch_size_in_kb int 批次请求的单位大小，单位 KB   bulk.batch_size_in_mb int 批次请求的单位大小，单位 MB,默认 10   bulk.batch_size_in_docs int 批次请求的文档个数, 默认 1000   bulk.retry_delay_in_seconds int 请求重试的等待时间   bulk.reject_retry_delay_in_seconds int 请求拒绝的等待时间   bulk.max_retry_times int 最大重试次数   bulk.failure_queue string 因为后端故障而失败的请求队列   bulk.invalid_queue string 因为请求不合法的 4xx 请求队列   bulk.dead_letter_queue string 超过最大重试次数的请求队列   bulk.safety_parse bool 是否启用安全解析，即不采用 buffer 的方式，占用内存更高一点，默认为 true   bulk.doc_buffer_size bool 单次请求处理的最大文档 buff size，建议设置超过单个文档的最大大小，默认 256*1024   queue_selector.labels map 根据 Label 来过滤一组需要消费的队列, 同 queues 配置   queue_selector.ids array 指定要消费的队列的 UUID, 字符数组   queue_selector.keys array 指定要消费的队列的唯一 Key 路径, 字符数组   waiting_after array 是否等待指定队列消费完成才开始消费, 队列的 UUID, 字符数组   detect_active_queue bool 是否自动检测符合条件的新的队列,默认 true   detect_interval bool 自动检测符合条件的新的队列的时间间隔,单位毫秒, 默认 5000   num_of_slices int 并行消费单个队列的线程, 运行时最大的 slice 大小   slices array 允许的 slice 编号, int 数组   skip_info_missing bool 忽略不满足条件的队列，如节点、索引、分片信息不存在时则需等待信息获取后再消费，默认为 false，否则会随机挑选一个 es 节点来发送请求   skip_empty_queue bool 是否跳过空队列的消费, 默认 true   consumer.source string 消费者来源   consumer.id string 消费者唯一标识   consumer.name string 消费者名称   consumer.group string 消费者组名称   consumer.fetch_min_bytes int 拉取消息最小的字节大小, 默认 1   consumer.fetch_max_bytes int 拉取消息最大的字节大小, 默认 10485760, 即 10MB   consumer.fetch_max_messages int 拉取最大的消息个数, 默认 1   consumer.fetch_max_wait_ms int 拉取最大的等待时间, 单位毫秒, 默认 10000    "});index.add({'id':81,'href':'/docs/latest/gateway/references/filters/bulk_request_mutate/','title':"bulk_request_mutate",'section':"在线过滤器",'content':"bulk_request_mutate #  描述 #  bulk_request_mutate 过滤器用来干预 Elasticsearch 的 Bulk 请求。\n配置示例 #  一个简单的示例如下：\nflow: - name: bulk_request_mutate filter: - bulk_request_mutate: fix_null_id: true generate_enhanced_id: true # fix_null_type: true # default_type: m-type # default_index: m-index # index_rename: # \u0026quot;*\u0026quot;: index-new # index1: index-new # index2: index-new # index3: index3-new # index4: index3-new # medcl-dr3: index3-new # type_rename: # \u0026quot;*\u0026quot;: type-new # type1: type-new # type2: type-new # doc: type-new # doc1: type-new ... 参数说明 #     名称 类型 说明     fix_null_type bool 是否修复不带 _type 的请求，和参数 default_type 配合使用   fix_null_id bool 是否修复不带 _id 的请求，生成一个随机 id，如 c616rhkgq9s7q1h89ig0   remove_type bool 是否移除 _type 参数，Elasticsearch 8.0 之后不支持 _type 参数   generate_enhanced_id bool 是否生成一个增强的 id 类型，如 c616rhkgq9s7q1h89ig0-1635937734071093-10   default_index string 默认的索引名称，如果元数据里面没有指定，则使用该默认值   default_type string 默认的文档 type，如果没有元数据里面没有指定，则使用该默认值   index_rename map 将索引名称进行重命名，支持 * 来覆盖所有的索引名称   type_rename map 将 type 进行重命名，支持 * 来覆盖所有的 type 名称   pipeline string 指定 bulk 请求的 pipeline 参数   remove_pipeline bool 是否移除 bulk 请求中的 pipeline 参数   safety_parse bool 是否采用安全的 bulk 元数据解析方法，默认 true   doc_buffer_size int 当采用不安全的 bulk 元数据解析方法时，使用的 buffer 大小，默认 256 * 1024    "});index.add({'id':82,'href':'/docs/latest/gateway/references/filters/bulk_reshuffle/','title':"bulk_reshuffle",'section':"在线过滤器",'content':"bulk_reshuffle #  描述 #  bulk_reshuffle 可以分析 Elasticsearch 的批次请求，并按照文档进行解析，可以根据需要将文档分门别类，归档存储在队列中，通过先落地存储，业务端请求可以快速返回，从而解耦前端写入和后端 Elasticsearch 集群。bulk_reshuffle 需要离线管道消费任务来配合使用。\n通过 bulk_reshuffle 过滤器生成的队列，元数据会默认带上 \u0026quot;type\u0026quot;: \u0026quot;bulk_reshuffle\u0026quot; 以及 Elasticsearch 的集群信息，如：\u0026quot;elasticsearch\u0026quot;: \u0026quot;dev\u0026quot;，通过网关查看队列的 API 也可以查看，如下：\ncurl http://localhost:2900/queue/stats { \u0026quot;queue\u0026quot;: { \u0026quot;disk\u0026quot;: { \u0026quot;async_bulk-cluster##dev\u0026quot;: { \u0026quot;depth\u0026quot;: 0, \u0026quot;metadata\u0026quot;: { \u0026quot;source\u0026quot;: \u0026quot;dynamic\u0026quot;, \u0026quot;id\u0026quot;: \u0026quot;c71f7pqi4h92kki4qrvg\u0026quot;, \u0026quot;name\u0026quot;: \u0026quot;async_bulk-cluster##dev\u0026quot;, \u0026quot;label\u0026quot;: { \u0026quot;elasticsearch\u0026quot;: \u0026quot;dev\u0026quot;, \u0026quot;level\u0026quot;: \u0026quot;cluster\u0026quot;, \u0026quot;type\u0026quot;: \u0026quot;bulk_reshuffle\u0026quot; } } } } } } 节点级别的异步提交 #  极限网关可以本地计算每个索引文档对应后端 Elasticsearch 集群的目标存放位置，从而能够精准的进行请求定位，在一批 bulk 请求中，可能存在多个后端节点的数据，bulk_reshuffle 过滤器用来将正常的 bulk 请求打散，按照目标节点或者分片进行拆分重新组装，避免 Elasticsearch 节点收到请求之后再次进行请求分发， 从而降低 Elasticsearch 集群间的流量和负载，也能避免单个节点成为热点瓶颈，确保各个数据节点的处理均衡，从而提升集群总体的索引吞吐能力。\n定义流程 #  一个简单的示例如下：\nflow: - name: online_indexing_merge filter: - bulk_reshuffle: elasticsearch: prod level: node #cluster,node,shard,partition - elasticsearch: elasticsearch: prod refresh: enabled: true interval: 30s 以上配置表示会将 bulk 请求拆分，按照索引文档所对应的目标节点，重新拆组装，将数据先落地到本地磁盘队列，然后通过单独的任务来消费提交，分别提交到目标 Elasticsearch 节点。\n使用该 filter 的好处是，即使后端 Elasticsearch 集群出现故障也不会影响索引操作的正常进行，因为请求都已经存放在网关本地的磁盘队列，从而解耦了前端索引和后端集群的依赖。因此就算后端 Elasticsearch 集群出现故障、进行重启、或是版本升级都不会影响正常的索引操作。  配置消费管道 #  网关将请求落地磁盘之后，需要配置一个消费队列的管道来进行数据的提交，如下：\npipeline: - name: bulk_request_ingest auto_start: true processor: - bulk_indexing: bulk_size_in_mb: 10 #in MB queues: type: bulk_reshuffle level: node 这里使用了一个名为 bulk_request_ingest 的管道任务，并且设置要订阅的目标的队列的过滤条件为：type: bulk_reshuffle 和 level: node，还可以设置 bulk 提交的批次大小。 这样当极限网关收到的节点级别的请求会自动的发送到对应的 Elasticsearch 节点。\n分片级别的异步提交 #  分片级别的异步提交比较适合单个索引数据量很大，需要单独处理的场景，通过将索引拆分到分片为单位，然后让 bulk 请求以分片为单位进行提交，进一步提高后端 Elasticsearch 处理的效率。\n具体的配置如下：\n定义流程 #  flow: - name: online_indexing_merge filter: - bulk_reshuffle: elasticsearch: prod level: shard - elasticsearch: elasticsearch: prod refresh: enabled: true interval: 30s 将拆装的级别设置为分片类型。\n定义管道 #  pipeline: - name: bulk_request_ingest auto_start: true processor: - bulk_indexing: queues: type: bulk_reshuffle level: shard bulk_size_in_mb: 1 #in MB 相比前面节点级别的配置，这里主要修改了 level 参数用来监听分片级别类型的磁盘队列，如果索引很多的话本地磁盘队列太多会造成额外的开销，建议仅针对特定要优化吞吐的索引开启该模式。\n参数说明 #     名称 类型 说明     elasticsearch string Elasticsearch 集群实例名称   level string 请求的 shuffle 级别，默认为 cluster，也就是集群级别，还可以设置为 cluster、node、index 和 shard 级别   partition_size int 在 level 的基础上，会再次基于文档 _id 进行分区，通过此参数可以设置最大的分区大小   fix_null_id bool 如果 bulk 索引请求的文档里面没有指定文档 id，是否自动生成一个随机的 UUID，适合日志类型数据，默认 true   index_stats_analysis bool 是否记录索引名称统计信息到请求日志，默认 true   action_stats_analysis bool 是否记录批次操作统计信息到请求日志，默认 true   doc_buffer_size int 设置处理文档的缓冲大小，如果单个索引文档很大，本参数需大于文档大小，默认 262144 即 256 KB   shards array 字符数组类型，如 \u0026quot;0\u0026quot;，设置哪些索引的分片允许被处理，默认所有分片，可以开启只允许特定分片   tag_on_success array 将所有 bulk 请求处理完成之后，请求上下文打上指定标记    "});index.add({'id':83,'href':'/docs/latest/gateway/references/filters/bulk_response_process/','title':"bulk_response_process",'section':"在线过滤器",'content':"bulk_response_process #  描述 #  bulk_response_process 过滤器用来处理 Elasticsearch 的 Bulk 请求。\n配置示例 #  一个简单的示例如下：\nflow: - name: bulk_response_process filter: - bulk_response_process: success_queue: \u0026quot;success_queue\u0026quot; tag_on_success: [\u0026quot;commit_message_allowed\u0026quot;] 参数说明 #     名称 类型 说明     invalid_queue string 保存非法请求的队列名称，必填。   failure_queue string 保存失败请求的队列名称，必填。   save_partial_success_requests bool 是否保存 bulk 请求里面部分执行成功的请求，默认 false。   success_queue string 保存 bulk 请求里面部分执行成功的请求的队列。   doc_buffer_size int 处理单个文档的 buffer 大小，默认 25kb，即 262144   continue_on_error bool bulk 请求出错之后是否继续执行后面的 filter，默认 false   message_truncate_size int bulk 请求出错日志截断长度，默认 1024   safety_parse bool 是否采用安全的 bulk 元数据解析方法，默认 true   doc_buffer_size int 当采用不安全的 bulk 元数据解析方法时，使用的 buffer 大小，默认 256 * 1024   tag_on_success array 将所有 bulk 请求处理完成之后，请求上下文打上指定标记   tag_on_error array 请求出现错误的情况下，请求上下文打上指定标记   tag_on_partial array 部分请求执行成功的情况下，请求上下文打上指定标记   tag_on_failure array 部分请求出现失败（可重试）的情况下，请求上下文打上指定标记   tag_on_invalid array 出现不合法请求错误的情况下，请求上下文打上指定标记    "});index.add({'id':84,'href':'/docs/latest/gateway/references/filters/cache/','title':"cache",'section':"在线过滤器",'content':"cache #  描述 #  cache 过滤器由 get_cache 和 set_cache 两组过滤器组成，一般需要组合使用，可用于缓存加速查询，抵挡重复请求，降低后端集群查询压力。\nget_cache 过滤器 #  过滤器 get_cache 用来从缓存里面获取之前出现的消息，直接返回给客户端，避免访问后端 Elasticsearch，用于缓存热点数据。\n配置示例如下：\nflow: - name: get_cache filter: - get_cache: pass_patterns: [\u0026quot;_cat\u0026quot;,\u0026quot;scroll\u0026quot;, \u0026quot;scroll_id\u0026quot;,\u0026quot;_refresh\u0026quot;,\u0026quot;_cluster\u0026quot;,\u0026quot;_ccr\u0026quot;,\u0026quot;_count\u0026quot;,\u0026quot;_flush\u0026quot;,\u0026quot;_ilm\u0026quot;,\u0026quot;_ingest\u0026quot;,\u0026quot;_license\u0026quot;,\u0026quot;_migration\u0026quot;,\u0026quot;_ml\u0026quot;,\u0026quot;_rollup\u0026quot;,\u0026quot;_data_stream\u0026quot;,\u0026quot;_open\u0026quot;, \u0026quot;_close\u0026quot;] 参数说明 #     名称 类型 说明     pass_patterns string 设置忽略缓存的请求规则，URL 包含其中的任意关键字将跳过缓存    set_cache 过滤器 #  过滤器 set_cache 用来将后端查询拿到的返回结果存到缓存里面，可以设置过期时间。\n配置示例如下：\nflow: - name: get_cache filter: - set_cache: min_response_size: 100 max_response_size: 1024000 cache_ttl: 30s max_cache_items: 100000 参数说明 #     名称 类型 说明     cache_type string 缓存类型，支持 ristretto，ccache 和 redis，默认 ristretto   cache_ttl string 缓存的过期时间，默认 10s   async_search_cache_ttl string 异步请求结果的缓存过期时间，默认 10m   min_response_size int 最小符合缓存要求的消息体大小，默认 -1 表示不限制   max_response_size int 最大符合缓存要求的消息体大小，默认为 int 的最大值   max_cached_item int 最大的缓存消息总数，默认 1000000，当类型为 ccache有效   max_cached_size int 最大的缓存内存开销，默认 1000000000 即 1GB，当类型为 ristretto 有效   validated_status_code array 允许被缓存的请求状态码，默认 200,201,404,403,413,400,301    其它参数 #  如果希望主动忽略缓存，可以在 URL 的参数里面传递一个 no_cache 来让网关忽略缓存。如：\ncurl http://localhost:8000/_search?no_cache=true "});index.add({'id':85,'href':'/docs/latest/gateway/references/filters/clone/','title':"clone",'section':"在线过滤器",'content':"clone #  描述 #  clone 过滤器用来将流量克隆转发到另外的一个处理流程，可以实现双写、多写、多数据中心同步、集群升级、版本切换等需求。\n配置示例 #  一个简单的示例如下：\nflow: - name: double_write filter: - clone: flows: - write_to_region_a - write_to_region_b #last one's response will be output to client - name: write_to_region_a filter: - elasticsearch: elasticsearch: es1 - name: write_to_region_b filter: - elasticsearch: elasticsearch: es2 上面的例子可以将 Elasticsearch 的请求复制到两个不同的异地集群。\n参数说明 #     名称 类型 说明     flows array 指定多个流量处理的流程，依次同步执行，将最后一个流程处理的结果输出给客户端   continue bool 流量迁移出去之后，是否还继续执行之前的既定流程，设置成 false 则立即返回，默认 false。    "});index.add({'id':86,'href':'/docs/latest/gateway/references/filters/context_filter/','title':"context_filter",'section':"在线过滤器",'content':"context_filter #  描述 #  context_filter 过滤器用来按请求上下文来过滤流量。\n配置示例 #  一个简单的示例如下：\nflow: - name: test filter: - context_filter: context: _ctx.request.path message: \u0026quot;request not allowed.\u0026quot; status: 403 must: #must match all rules to continue prefix: - /medcl contain: - _search suffix: - _count - _refresh wildcard: - /*/_refresh regex: - ^/m[\\w]+dcl must_not: # any match will be filtered prefix: - /.kibana - /_security - /_security - /gateway_requests* - /.reporting - /_monitoring/bulk contain: - _search suffix: - _count - _refresh wildcard: - /*/_refresh regex: - ^/m[\\w]+dcl should: prefix: - /medcl contain: - _search - _async_search suffix: - _refresh wildcard: - /*/_refresh regex: - ^/m[\\w]+dcl 参数说明 #     名称 类型 说明     context string 上下文变量   exclude array 拒绝通过的请求的变量列表   include array 允许通过的请求的变量列表   must.* object 必须都满足所设置条件的情况下才能允许通过   must_not.* object 必须都不满足所设置条件的情况下才能通过   should.* object 满足任意所设置条件的情况下即可通过   *.prefix array 判断是否由特定字符开头   *.suffix array 判断是否由特定字符结尾   *.contain array 判断是否包含特定字符   *.wildcard array 判断是否符合通配符匹配规则   *.regex array 判断是否符合正则表达式匹配规则   action string 符合过滤条件之后的处理动作，可以是 deny 和 redirect_flow，默认为 deny   status int 自定义模式匹配之后返回的状态码   message string 自定义 deny 模式返回的消息文本   flow string 自定义 redirect_flow 模式执行的 flow ID    Note: 当仅设置了 should 条件的情况下，必须至少满足 should 设置的其中一种才能被允许通过。\n"});index.add({'id':87,'href':'/docs/latest/gateway/references/filters/context_limiter/','title':"context_limiter",'section':"在线过滤器",'content':"context_limiter #  描述 #  context_limiter 过滤器用来按照请求上下文来进行限速。\n配置示例 #  配置示例如下：\nflow: - name: default_flow filter: - context_limiter: max_requests: 1 action: drop context: - _ctx.request.path - _ctx.request.header.Host - _ctx.request.header.Env 上面的配置中，对 _ctx.request.path 、 _ctx.request.header.Host 和 _ctx.request.header.Env 这三个上下文变量来组成一个 bucket 进行限速。 允许的最大 qps 为 1每秒，达到限速直接拒绝范围外的后续请求。\n参数说明 #     名称 类型 说明     context array 设置上下文变量，依次组合成一个 bucket key   interval string 评估限速的单位时间间隔，默认为 1s   max_requests int 单位间隔内最大的请求次数限额   max_bytes int 单位间隔内最大的请求流量限额   action string 触发限速之后的处理动作，分为 retry 和 drop 两种，默认为 retry   status string 设置达到限速条件的返回状态码，默认 429   message string 设置达到限速条件的请求的拒绝返回消息   retry_interval int 限速重试的时间间隔，单位毫秒，默认 10，即 10 毫秒   max_retry_times int 限速重试的最大重试次数，默认 1000   failed_retry_message string 设置达到最大重试次数的请求的拒绝返回消息    "});index.add({'id':88,'href':'/docs/latest/gateway/references/filters/context_regex_replace/','title':"context_regex_replace",'section':"在线过滤器",'content':"context_regex_replace #  描述 #  context_regex_replace 过滤器用来通过正则表达式来替换修改请求上下文的相关信息。\n配置示例 #  一个简单的示例如下：\nflow: - name: test filter: - context_regex_replace: context: \u0026quot;_ctx.request.path\u0026quot; pattern: \u0026quot;^/\u0026quot; to: \u0026quot;/cluster:\u0026quot; when: contains: _ctx.request.path: /_search - dump: request: true 这个例子可以将请求 curl localhost:8000/abc/_search 替换为 curl localhost:8000/cluster:abc/_search\n参数说明 #     名称 类型 说明     context string 请求的上下文及对应的 Key   pattern string 用于匹配替换的正则表达式   to string 替换为目标的字符串内容    支持修改的上下文变量列表如下：\n   名称 类型 说明     _ctx.request.uri string 完整请求的 URL 地址   _ctx.request.path string 请求的路径   _ctx.request.host string 请求的主机   _ctx.request.body string 请求体   _ctx.request.body_json.[JSON_PATH] string JSON 请求对象的 Path   _ctx.request.query_args.[KEY] string URL 查询请求参数   _ctx.request.header.[KEY] string 请求头信息   _ctx.response.header.[KEY] string 返回头信息   _ctx.response.body string 返回响应体   _ctx.response.body_json.[JSON_PATH] string JSON 返回对象的 Path    "});index.add({'id':89,'href':'/docs/latest/gateway/references/processors/dag/','title':"dag",'section':"离线处理器",'content':"dag #  描述 #  dag 处理器用来管理任务的并行调度。\n配置示例 #  下面的这个例子，定义了一个名为 racing_example 的服务，auto_start 设置为自动启动，processor 设置依次执行的每个处理单元，其中 dag 处理器支持多个任务并行执行，支持 wait_all 和 first_win 两种聚合模式，如下：\npipeline: - name: racing_example auto_start: true processor: - echo: #ready, set, go message: read,set,go - dag: mode: wait_all #first_win, wait_all parallel: - echo: #player1 message: player1 - echo: #player2 message: player2 - echo: #player3 message: player3 end: - echo: #checking score message: checking score - echo: #announce champion message: 'announce champion' - echo: #done message: racing finished 上面的 echo 处理器非常简单，用来输出一个指定的消息，这个管道模拟的是一个赛跑的场景，palyer1、2、3 并行赛跑，全部跑完之后再进行算分和宣布比赛冠军，最后输出结束信息，程序运行输出如下：\n[10-12 14:59:22] [INF] [echo.go:36] message:read,set,go [10-12 14:59:22] [INF] [echo.go:36] message:player1 [10-12 14:59:22] [INF] [echo.go:36] message:player2 [10-12 14:59:22] [INF] [echo.go:36] message:player3 [10-12 14:59:22] [INF] [echo.go:36] message:checking score [10-12 14:59:22] [INF] [echo.go:36] message:announce champion [10-12 14:59:22] [INF] [echo.go:36] message:racing finished 参数说明 #     名称 类型 说明     mode string 任务结果的聚合模式，设置 first_win 表示并行里面的任意任务执行完就继续往下执行，而设置 wait_all 表示需要等待所有任务执行完毕才继续往后执行。   parallel array 任务数组列表，依次定义多个子任务   end array 任务数组列表，并行任务之后再执行的任务    "});index.add({'id':90,'href':'/docs/latest/gateway/references/filters/date_range_precision_tuning/','title':"date_range_precision_tuning",'section':"在线过滤器",'content':"date_range_precision_tuning #  描述 #  date_range_precision_tuning 过滤器用来重设时间范围查询的时间精度，通过调整精度，可以让短时间内邻近的重复请求更容易被缓存，对于有一些对于时间精度不那么高但是数据量非常大的场景，比如使用 Kibana 来做报表分析，通过缩减精度来缓存重复的查询请求，从而降低后端服务器压力，前端报表展现的提速非常明显。\n配置示例 #  一个简单的示例如下：\nflow: - name: test filter: - date_range_precision_tuning: time_precision: 4 - get_cache: - elasticsearch: elasticsearch: dev - set_cache: 精度说明 #  Kibana 默认发往 Elasticsearch 的查询，使用的是当前时间 Now，精度到毫秒，通过设置不同的精度来改写查询，以下面的查询为例：\n{\u0026quot;range\u0026quot;:{\u0026quot;@timestamp\u0026quot;:{\u0026quot;gte\u0026quot;:\u0026quot;2019-09-26T08:21:12.152Z\u0026quot;,\u0026quot;lte\u0026quot;:\u0026quot;2020-09-26T08:21:12.152Z\u0026quot;,\u0026quot;format\u0026quot;:\u0026quot;strict_date_optional_time\u0026quot;} 分别设置不同的精度，改写之后的查询结果如下：\n   精度 新的查询     0 {\u0026ldquo;range\u0026rdquo;:{\u0026quot;@timestamp\u0026quot;:{\u0026ldquo;gte\u0026rdquo;:\u0026ldquo;2019-09-26T00:00:00.000Z\u0026rdquo;,\u0026ldquo;lte\u0026rdquo;:\u0026ldquo;2020-09-26T23:59:59.999Z\u0026rdquo;,\u0026ldquo;format\u0026rdquo;:\u0026ldquo;strict_date_optional_time\u0026rdquo;}   1 {\u0026ldquo;range\u0026rdquo;:{\u0026quot;@timestamp\u0026quot;:{\u0026ldquo;gte\u0026rdquo;:\u0026ldquo;2019-09-26T00:00:00.000Z\u0026rdquo;,\u0026ldquo;lte\u0026rdquo;:\u0026ldquo;2020-09-26T09:59:59.999Z\u0026rdquo;,\u0026ldquo;format\u0026rdquo;:\u0026ldquo;strict_date_optional_time\u0026rdquo;}   2 {\u0026ldquo;range\u0026rdquo;:{\u0026quot;@timestamp\u0026quot;:{\u0026ldquo;gte\u0026rdquo;:\u0026ldquo;2019-09-26T08:00:00.000Z\u0026rdquo;,\u0026ldquo;lte\u0026rdquo;:\u0026ldquo;2020-09-26T08:59:59.999Z\u0026rdquo;,\u0026ldquo;format\u0026rdquo;:\u0026ldquo;strict_date_optional_time\u0026rdquo;}   3 {\u0026ldquo;range\u0026rdquo;:{\u0026quot;@timestamp\u0026quot;:{\u0026ldquo;gte\u0026rdquo;:\u0026ldquo;2019-09-26T08:20:00.000Z\u0026rdquo;,\u0026ldquo;lte\u0026rdquo;:\u0026ldquo;2020-09-26T08:29:59.999Z\u0026rdquo;,\u0026ldquo;format\u0026rdquo;:\u0026ldquo;strict_date_optional_time\u0026rdquo;}   4 {\u0026ldquo;range\u0026rdquo;:{\u0026quot;@timestamp\u0026quot;:{\u0026ldquo;gte\u0026rdquo;:\u0026ldquo;2019-09-26T08:21:00.000Z\u0026rdquo;,\u0026ldquo;lte\u0026rdquo;:\u0026ldquo;2020-09-26T08:21:59.999Z\u0026rdquo;,\u0026ldquo;format\u0026rdquo;:\u0026ldquo;strict_date_optional_time\u0026rdquo;}   5 {\u0026ldquo;range\u0026rdquo;:{\u0026quot;@timestamp\u0026quot;:{\u0026ldquo;gte\u0026rdquo;:\u0026ldquo;2019-09-26T08:21:10.000Z\u0026rdquo;,\u0026ldquo;lte\u0026rdquo;:\u0026ldquo;2020-09-26T08:21:19.999Z\u0026rdquo;,\u0026ldquo;format\u0026rdquo;:\u0026ldquo;strict_date_optional_time\u0026rdquo;}   6 {\u0026ldquo;range\u0026rdquo;:{\u0026quot;@timestamp\u0026quot;:{\u0026ldquo;gte\u0026rdquo;:\u0026ldquo;2019-09-26T08:21:12.000Z\u0026rdquo;,\u0026ldquo;lte\u0026rdquo;:\u0026ldquo;2020-09-26T08:21:12.999Z\u0026rdquo;,\u0026ldquo;format\u0026rdquo;:\u0026ldquo;strict_date_optional_time\u0026rdquo;}   7 {\u0026ldquo;range\u0026rdquo;:{\u0026quot;@timestamp\u0026quot;:{\u0026ldquo;gte\u0026rdquo;:\u0026ldquo;2019-09-26T08:21:12.100Z\u0026rdquo;,\u0026ldquo;lte\u0026rdquo;:\u0026ldquo;2020-09-26T08:21:12.199Z\u0026rdquo;,\u0026ldquo;format\u0026rdquo;:\u0026ldquo;strict_date_optional_time\u0026rdquo;}   8 {\u0026ldquo;range\u0026rdquo;:{\u0026quot;@timestamp\u0026quot;:{\u0026ldquo;gte\u0026rdquo;:\u0026ldquo;2019-09-26T08:21:12.150Z\u0026rdquo;,\u0026ldquo;lte\u0026rdquo;:\u0026ldquo;2020-09-26T08:21:12.159Z\u0026rdquo;,\u0026ldquo;format\u0026rdquo;:\u0026ldquo;strict_date_optional_time\u0026rdquo;}   9 {\u0026ldquo;range\u0026rdquo;:{\u0026quot;@timestamp\u0026quot;:{\u0026ldquo;gte\u0026rdquo;:\u0026ldquo;2019-09-26T08:21:12.152Z\u0026rdquo;,\u0026ldquo;lte\u0026rdquo;:\u0026ldquo;2020-09-26T08:21:12.152Z\u0026rdquo;,\u0026ldquo;format\u0026rdquo;:\u0026ldquo;strict_date_optional_time\u0026rdquo;}    参数说明 #     名称 类型 说明     time_precision int 时间的精度长度，对于时间呈现长度位数，默认为 4，有效范围 0 到 9   path_keywords array 只对包含所设置关键字的请求进行时间精度重置，避免对不必要的请求进行解析，默认 _search 和 _async_search    "});index.add({'id':91,'href':'/docs/latest/gateway/references/filters/drop/','title':"drop",'section':"在线过滤器",'content':"drop #  描述 #  drop 过滤器用来丢弃某个消息，提前结束请求的处理。\n配置示例 #  一个简单的示例如下：\nflow: - name: drop filter: - drop: "});index.add({'id':92,'href':'/docs/latest/gateway/references/filters/dump/','title':"dump",'section':"在线过滤器",'content':"dump #  描述 #  dump 过滤器是一个用于在终端打印 Dump 输出相关请求信息的过滤器，主要用于调试。\n配置示例 #  一个简单的示例如下：\nflow: - name: hello_world filter: - dump: uri: true request_header: true request_body: true response_body: true status_code: true 参数说明 #  dump 过滤器比较简单，在需要的流程处理阶段插入 dump 过滤器，即可在终端输出相应阶段的请求信息，方便调试。\n   名称 类型 说明     request bool 是否输出全部完整的请求信息   response bool 是否输出全部完整的返回信息   uri bool 是否输出请求的 URI 信息   query_args bool 是否输出请求的参数信息   user bool 是否输出请求的用户信息   api_key bool 是否输出请求的 APIKey 信息   request_header bool 是否输出请求的头信息   response_header bool 是否输出响应的头信息   status_code bool 是否输出响应的状态码   context array 输出自定义的上下文信息    输出上下文 #  可以使用 context 参数来调试请求上下文信息，示例配置文件：\nflow: - name: echo filter: - set_response: status: 201 content_type: \u0026quot;text/plain; charset=utf-8\u0026quot; body: \u0026quot;hello world\u0026quot; - set_response_header: headers: - Env -\u0026gt; Dev - dump: context: - _ctx.id - _ctx.tls - _ctx.remote_addr - _ctx.local_addr - _ctx.request.host - _ctx.request.method - _ctx.request.uri - _ctx.request.path - _ctx.request.body - _ctx.request.body_length - _ctx.request.query_args.from - _ctx.request.query_args.size - _ctx.request.header.Accept - _ctx.request.user - _ctx.response.status - _ctx.response.body - _ctx.response.content_type - _ctx.response.body_length - _ctx.response.header.Env 启动网关，执行如下命令：\ncurl http://localhost:8000/medcl/_search\\?from\\=1\\\u0026amp;size\\=100 -d'{search:query123}' -v -u 'medcl:123' 网关终端输出如下信息：\n---- dumping context ---- _ctx.id : 21474836481 _ctx.tls : false _ctx.remote_addr : 127.0.0.1:50925 _ctx.local_addr : 127.0.0.1:8000 _ctx.request.host : localhost:8000 _ctx.request.method : POST _ctx.request.uri : http://localhost:8000/medcl/_search?from=1\u0026amp;size=100 _ctx.request.path : /medcl/_search _ctx.request.body : {search:query123} _ctx.request.body_length : 17 _ctx.request.query_args.from : 1 _ctx.request.query_args.size : 100 _ctx.request.header.Accept : */* _ctx.request.user : medcl _ctx.response.status : 201 _ctx.response.body : hello world _ctx.response.content_type : text/plain; charset=utf-8 _ctx.response.body_length : 11 _ctx.response.header.Env : Dev "});index.add({'id':93,'href':'/docs/latest/gateway/references/processors/dump_hash/','title':"dump_hash",'section':"离线处理器",'content':"dump_hash #  描述 #  dump_hash 处理器用来导出集群的索引文档并计算 Hash。\n配置示例 #  一个简单的示例如下：\npipeline: - name: bulk_request_ingest auto_start: true keep_running: true processor: - dump_hash: #dump es1's doc indices: \u0026quot;medcl-dr3\u0026quot; scroll_time: \u0026quot;10m\u0026quot; elasticsearch: \u0026quot;source\u0026quot; query: \u0026quot;field1:elastic\u0026quot; fields: \u0026quot;doc_hash\u0026quot; output_queue: \u0026quot;source_docs\u0026quot; batch_size: 10000 slice_size: 5 参数说明 #     名称 类型 说明     elasticsearch string 目标集群的名称   scroll_time string Scroll 回话超时时间   batch_size int Scroll 批次大小，默认 5000   slice_size int Slice 大小，默认 1   sort_type string 文档排序类型，默认 asc   sort_field string 文档排序字段   indices string 索引   level string 请求处理级别，可以设置为 cluster 则表示请求不进行节点和分片级别的拆分，适用于 Elasticsearch 前有代理的情况   query string 查询过滤条件   fields string 要返回的字段列表   sort_document_fields bool hash 计算之前是否对 _source 里面的字段进行排序，默认 false   hash_func string hash 函数，可选 xxhash32、xxhash64、fnv1a，默认 xxhash32   output_queue string 输出结果的队列名称    "});index.add({'id':94,'href':'/docs/latest/gateway/references/filters/elasticsearch/','title':"elasticsearch",'section':"在线过滤器",'content':"elasticsearch #  描述 #  elasticsearch 过滤器是一个用于请求转发给后端 Elasticsearch 集群的过滤器。\n配置示例 #  使用 elasticsearch 过滤器之前，需要提前定义一个 Elasticsearch 的集群配置节点，如下：\nelasticsearch: - name: prod enabled: true endpoint: http://192.168.3.201:9200 流程的配置示例如下：\nflow: - name: cache_first filter: - elasticsearch: elasticsearch: prod 上面的例子即将请求转发给 prod 集群。\n自动更新 #  对于一个大规模的集群，可能存在很多的节点，不可能一一配置后端的所有节点，只需要先指定 Elasticsearch 模块允许自动发现后端节点，如下：\nelasticsearch: - name: prod enabled: true endpoint: http://192.168.3.201:9200 discovery: enabled: true refresh: enabled: true basic_auth: username: elastic password: pass 然后过滤器这边的配置也开启刷新，即可访问后端所有节点，且节点上下线也会自动更新，示例如下：\nflow: - name: cache_first filter: - elasticsearch: elasticsearch: prod refresh: enabled: true interval: 30s 设置权重 #  如果后端集群很多，极限网关支持对不同的节点设置不同的访问权重，配置示例如下：\nflow: - name: cache_first filter: - elasticsearch: elasticsearch: prod balancer: weight refresh: enabled: true interval: 30s weights: - host: 192.168.3.201:9200 weight: 10 - host: 192.168.3.202:9200 weight: 20 - host: 192.168.3.203:9200 weight: 30 上面的例子中，发往 Elasticsearch 集群的流量，将以 3：2：1 的比例分别发给 203、202 和 201 这三个节点。\n过滤节点 #  极限网关还支持按照节点的 IP、标签、角色来进行过滤，可以用来将请求避免发送给特定的节点，如 Master、冷节点等，配置示例如下：\nflow: - name: cache_first filter: - elasticsearch: elasticsearch: prod balancer: weight refresh: enabled: true interval: 30s filter: hosts: exclude: - 192.168.3.201:9200 include: - 192.168.3.202:9200 - 192.168.3.203:9200 tags: exclude: - temp: cold include: - disk: ssd roles: exclude: - master include: - data - ingest 参数说明 #     名称 类型 说明     elasticsearch string Elasticsearch 集群的名称   max_connection_per_node int 限制访问 Elasticsearch 集群每个节点的最大 TCP 连接数，默认 5000   max_response_size int 限制 Elasticsearch 请求返回的最大消息体大小，默认 100*1024*1024   max_retry_times int 限制 Elasticsearch 出错的重试次数，默认 0   max_conn_wait_timeout int 限制 Elasticsearch 等待空闲链接的超时时间，默认 10s   max_idle_conn_duration int 限制 Elasticsearch 连接的空闲时间，默认 0s   max_conn_duration int 限制 Elasticsearch 连接的持续时间，默认 0s   read_timeout int 限制 Elasticsearch 请求的读取超时时间，默认 0s   write_timeout int 限制 Elasticsearch 请求的写入超时时间，默认 0s   read_buffer_size int 设置 Elasticsearch 请求的读缓存大小，默认 4096*4   write_buffer_size int 设置 Elasticsearch 请求的写缓存大小，默认 4096*4   tls_insecure_skip_verify bool 是否忽略 Elasticsearch 集群的 TLS 证书校验，默认 true   balancer string 后端 Elasticsearch 节点的负载均衡算法，目前只有 weight 基于权重的算法   refresh.enable bool 是否开启节点状态变化的自动刷新，可感知后端 Elasticsearch 拓扑的变化   refresh.interval int 节点状态刷新的间隔时间   weights array 可以设置后端节点的优先级，权重高的转发请求的比例相应提高   filter object 后端 Elasticsearch 节点的过滤规则，可以将请求转发给特定的节点   filter.hosts object 按照 Elasticsearch 的访问地址来进行过滤   filter.tags object 按照 Elasticsearch 的标签来进行过滤   filter.roles object 按照 Elasticsearch 的角色来进行过滤   filter.*.exclude array 排除特定的条件，任何匹配的节点会被拒绝执行请求的代理   filter.*.include array 允许符合条件的 Elasticsearch 节点来代理请求，在 exclude 参数没有配置的情况下，如果配置了 include 条件，则必须要满足任意一个 include 条件，否则不允许进行请求的代理    "});index.add({'id':95,'href':'/docs/latest/gateway/references/filters/elasticsearch_health_check/','title':"elasticsearch_health_check",'section':"在线过滤器",'content':"elasticsearch_health_check #  描述 #  elasticsearch_health_check 过滤器用来以限速模式下主动探测 Elasticsearch 的健康情况， 当出现后端故障的情况下，可以触发一次主动的集群健康检查，而不用等待 Elasticsearch 默认的轮询检查结果，限速设置为最多每秒发送一次检查请求给后端 Elasticsearch。\n配置示例 #  一个简单的示例如下：\nflow: - name: elasticsearch_health_check filter: - elasticsearch_health_check: elasticsearch: dev 参数说明 #     名称 类型 说明     elasticsearch string 集群 ID   interval int 设置最少执行请求的时间间隔，单位秒，默认 1    "});index.add({'id':96,'href':'/docs/latest/gateway/references/filters/flow/','title':"flow",'section':"在线过滤器",'content':"flow #  描述 #  flow 过滤器用来跳转或执行某个或一系列其他流程。\n配置示例 #  一个简单的示例如下：\nflow: - name: flow filter: - flow: flows: - request_logging 使用上下文的动态 Flow:\nflow: - name: dns-flow filter: - flow: ignore_undefined_flow: true context_flow: context: _ctx.request.host context_parse_pattern: (?P\u0026lt;uuid\u0026gt;^[0-9a-z_\\-]+)\\. flow_id_template: flow_$[[uuid]] - set_response: status: 503 content_type: application/json body: '{\u0026quot;message\u0026quot;:\u0026quot;invalid HOST\u0026quot;}' 支持的上下文变量，请访问 上下文 .\n参数说明 #     名称 类型 说明     flow string 流程 ID，支持指定单个 flow 执行   flows array 流程 ID，数组格式，可以指定多个，依次执行   ignore_undefined_flow bool 是否忽略未知的 flow，继续执行   context_flow.context string 用来查找 flow_id 的上下文变量   context_flow.context_parse_pattern string 用来抽取变量的正则表达式   context_flow.flow_id_template string 用来生成 flow_id 的模版   context_flow.continue string 上下文映射的 Flow 执行完毕之后是否继续下一个过滤器，默认 false    "});index.add({'id':97,'href':'/docs/latest/gateway/references/processors/flow_runner/','title':"flow_runner",'section':"离线处理器",'content':"flow_runner #  描述 #  flow_runner 处理器用来异步消费队列里面的请求并使用异步用于在线请求的处理流程来进行消费处理。\n配置示例 #  一个简单的示例如下：\npipeline: - name: bulk_request_ingest auto_start: true keep_running: true processor: - flow_runner: input_queue: \u0026quot;primary_deadletter_requests\u0026quot; flow: primary-flow-post-processing when: cluster_available: [ \u0026quot;primary\u0026quot; ] 参数说明 #     名称 类型 说明     input_queue string 订阅的队列名称   flow string 以什么样的流程来消费队列里面的请求消息   commit_on_tag string 只有当前请求的上下文里面出现指定 tag 才会 commit 消息，默认为空表示执行完就 commit    "});index.add({'id':98,'href':'/docs/latest/gateway/references/filters/http/','title':"http",'section':"在线过滤器",'content':"http #  描述 #  http 过滤器用来将请求代理转发到指定的 http 服务器。\n配置示例 #  一个简单的示例如下：\nflow: - name: default_flow filter: - basic_auth: valid_users: medcl: passwd - http: schema: \u0026quot;http\u0026quot; #https or http #host: \u0026quot;192.168.3.98:5601\u0026quot; hosts: - \u0026quot;192.168.3.98:5601\u0026quot; - \u0026quot;192.168.3.98:5602\u0026quot; 参数说明 #     名称 类型 说明     schema string http 或是 https   host string 目标主机地址，带端口，如 localhost:9200   hosts array 主机地址列表，遇到故障，依次尝试   skip_failure_host bool 是否跳过不可以的主机，默认 true   max_connection_per_node int 主机的最大连接数，默认 5000   max_response_size int 支持的最大响应体大小   max_retry_times int 出错的最大重试次数，默认 0   retry_delay_in_ms int 重试的延迟，默认 1000   skip_cleanup_hop_headers bool 是否移除不兼容的 Hop-by-hop 头信息   max_conn_wait_timeout duration 建立连接的超时时间，默认 30s   max_idle_conn_duration duration 空闲连接的超时时间，默认 30s   max_conn_duration duration 长连接的超时时间，默认 0s   timeout duration 请求的超时时间，默认 30s   read_timeout duration 读请求的超时时间，默认 0s   write_timeout duration 写请求的超时时间，默认 0s   read_buffer_size int 读请求的缓冲区大小，默认 16384   write_buffer_size int 写请求的缓冲区大小，默认 16384   tls_insecure_skip_verify bool 是否忽略 TLS 的校验，默认 true    "});index.add({'id':99,'href':'/docs/latest/gateway/references/processors/index_diff/','title':"index_diff",'section':"离线处理器",'content':"index_diff #  描述 #  index_diff 处理器用来对两个结果集进行差异对比。\n配置示例 #  一个简单的示例如下：\npipeline: - name: bulk_request_ingest auto_start: true keep_running: true processor: - index_diff: diff_queue: \u0026quot;diff_result\u0026quot; buffer_size: 1 text_report: true #如果要存 es，这个开关关闭，开启 pipeline 的 diff_result_ingest 任务 source_queue: 'source_docs' target_queue: 'target_docs' 参数说明 #     名称 类型 说明     source_queue string 来源数据的名称   target_queue string 目标数据的名称   diff_queue string 存放 diff 结果的队列   buffer_size int 内存 buffer 大小   keep_source bool diff 结果里面是否包含文档 source 信息   text_report bool 是否输出文本格式的结果    "});index.add({'id':100,'href':'/docs/latest/gateway/references/processors/indexing_merge/','title':"indexing_merge",'section':"离线处理器",'content':"indexing_merge #  描述 #  indexing_merge 处理器用来消费队列里面的纯 JSON 文档，并合并成 Bulk 请求保存到指定的队列里面，需要配合 bulk_indexing 处理器进行消费，用批量写入代替单次请求来提高写入吞吐。\n配置示例 #  一个简单的示例如下：\npipeline: - name: indexing_merge auto_start: true keep_running: true processor: - indexing_merge: input_queue: \u0026quot;request_logging\u0026quot; elasticsearch: \u0026quot;logging-server\u0026quot; index_name: \u0026quot;infini_gateway_requests\u0026quot; output_queue: name: \u0026quot;gateway_requests\u0026quot; label: tag: \u0026quot;request_logging\u0026quot; worker_size: 1 bulk_size_in_mb: 10 - name: logging_requests auto_start: true keep_running: true processor: - bulk_indexing: bulk: compress: true batch_size_in_mb: 10 batch_size_in_docs: 5000 consumer: fetch_max_messages: 100 queues: type: indexing_merge when: cluster_available: [ \u0026quot;logging-server\u0026quot; ] 参数说明 #     名称 类型 说明     input_queue int 订阅的队列名称   worker_size int 并行执行消费任务的线程数，默认 1   idle_timeout_in_seconds int 消费队列的超时时间，默认 5，单位秒   bulk_size_in_kb int 批次请求的单位大小，单位 KB   bulk_size_in_mb int 批次请求的单位大小，单位 MB，默认 10   elasticsearch string 保存到目标集群的名称   index_name string 保存到目标集群的索引名称   type_name string 保存到目标集群的索引类型名称，默认根据集群版本来设置，v7 以前为 doc，之后为 _doc   output_queue.name string 保存到目标队列的名称   output_queue.label map 保存到目标队列的标签，内置 type:indexing_merge   failure_queue string 保存可重试的失败请求的队列名称   invalid_queue string 保存不合法的失败请求的队列名称    "});index.add({'id':101,'href':'/docs/latest/gateway/references/filters/javascript/','title':"javascript",'section':"在线过滤器",'content':"javascript #  描述 #  javascript 过滤器可用于通过用 javascript 编写脚本来执行您自己的处理逻辑，从而提供最大的灵活性。\n配置示例 #  一个简单的示例如下：\nflow: - name: test filter: - javascript: source: \u0026gt; function process(ctx) { var console = require('console'); console.log(\u0026quot;hello from javascript\u0026quot;); } 这个脚本里面的 process 是一个内置的函数，用来处理传进来的上下文信息，函数里面可以自定义业务逻辑。\n如果脚本比较复杂，也支持通过文件的方式从加载：\nflow: - name: test filter: - javascript: file: example.js 这里的 example.js 是文件的保存路径。\n参数说明 #     名称 类型 描述     source string 要执行的 Javascript 代码。   file string 要加载的脚本文件的路径。相对路径被解释为相对于网关实例数据目录的 scripts 子目录。   params map 一个参数字典，传递给脚本的 register 方法。    上下文 API #  传递给处理方法的上下文对象具有以下 API 可以被使用。有关上下文的更多信息，请查看 Request Context。\n   方法 描述     Get(string) 从上下文中获取一个值。如果字段不存在，则返回 null。 eg: var value = event.Get(key);   Put(string, value) 在上下文中输入一个值。如果字段已经设置，则返回以前的值。如果字段存在但不是对象无法设置，则会抛出异常。 eg: var old = event.Put(key, value);   Rename(string, string) 在上下文中重命名一个字段。目标键必须不存在。如果成功地将源键重命名为目标键，则返回 true。 eg: var success = event.Rename(\u0026quot;source\u0026quot;, \u0026quot;target\u0026quot;);   Delete(string) 从上下文中删除一个字段。成功时返回true。 eg: var deleted = event.Delete(\u0026quot;user.email\u0026quot;);   Tag(string) 如果 Tag 不存在，则将 Tag 追加到 Tag 字段。如果 Tag 存在但不是字符串或字符串列表，则抛出异常。 eg: event.Tag(\u0026quot;user_event\u0026quot;);   AppendTo(string, string) 一个专门的追加字段值的方法，它将现有值转换为数组，并在值不存在时追加该值。如果现有值不是字符串或字符串数组，则抛出异常。 eg: event.AppendTo(\u0026quot;error.message\u0026quot;, \u0026quot;invalid file hash\u0026quot;);    外部参数的使用 #  下面的例子，介绍了如何使用 params 来传递变量，脚本可以加载来自文件，方便复用程序脚本。\nflow: - name: test filter: - javascript: params: keyword: [ \u0026quot;hello\u0026quot;, \u0026quot;world\u0026quot;, \u0026quot;scripts\u0026quot; ] source: \u0026gt; var console = require('console'); var params = {keyword: []}; function register(scriptParams) { params = scriptParams; } function process(ctx) { console.info(\u0026quot;keyword comes from params: [%s]\u0026quot;, params.keyword); } register 是一个内置的函数，用来初始化外部参数。\n"});index.add({'id':102,'href':'/docs/latest/gateway/references/processors/json_indexing/','title':"json_indexing",'section':"离线处理器",'content':"json_indexing #  描述 #  json_indexing 处理器用来消费队列里面的纯 JSON 文档，并保存到指定的 Elasticsearch 服务器里面。\n配置示例 #  一个简单的示例如下：\npipeline: - name: request_logging_index auto_start: true keep_running: true processor: - json_indexing: index_name: \u0026quot;gateway_requests\u0026quot; elasticsearch: \u0026quot;dev\u0026quot; input_queue: \u0026quot;request_logging\u0026quot; idle_timeout_in_seconds: 1 worker_size: 1 bulk_size_in_mb: 10 参数说明 #     名称 类型 说明     input_queue int 订阅的队列名称   worker_size int 并行执行消费任务的线程数，默认 1   idle_timeout_in_seconds int 消费队列的超时时间，默认 5，单位秒   bulk_size_in_kb int 批次请求的单位大小，单位 KB   bulk_size_in_mb int 批次请求的单位大小，单位 MB   elasticsearch string 保存到目标集群的名称   index_name string 保存到目标集群的索引名称   type_name string 保存到目标集群的索引类型名称，默认根据集群版本来设置，v7 以前为 doc，之后为 _doc    "});index.add({'id':103,'href':'/docs/latest/gateway/references/filters/ldap_auth/','title':"ldap_auth",'section':"在线过滤器",'content':"ldap_auth #  描述 #  ldap_auth 过滤器用来设置基于 LDAP 的身份认证。\n配置示例 #  一个简单的示例如下：\nflow: - name: ldap_auth filter: - ldap_auth: host: \u0026quot;ldap.forumsys.com\u0026quot; port: 389 bind_dn: \u0026quot;cn=read-only-admin,dc=example,dc=com\u0026quot; bind_password: \u0026quot;password\u0026quot; base_dn: \u0026quot;dc=example,dc=com\u0026quot; user_filter: \u0026quot;(uid=%s)\u0026quot; 上面的配置使用的是在线的免费 LDAP 测试服务器，测试用户 tesla，密码 password。\n➜ curl http://127.0.0.1:8000/ -u tesla:password { \u0026quot;name\u0026quot; : \u0026quot;192.168.3.7\u0026quot;, \u0026quot;cluster_name\u0026quot; : \u0026quot;elasticsearch\u0026quot;, \u0026quot;cluster_uuid\u0026quot; : \u0026quot;ZGTwWtBfSLWRpsS1VKQDiQ\u0026quot;, \u0026quot;version\u0026quot; : { \u0026quot;number\u0026quot; : \u0026quot;7.8.0\u0026quot;, \u0026quot;build_flavor\u0026quot; : \u0026quot;default\u0026quot;, \u0026quot;build_type\u0026quot; : \u0026quot;tar\u0026quot;, \u0026quot;build_hash\u0026quot; : \u0026quot;757314695644ea9a1dc2fecd26d1a43856725e65\u0026quot;, \u0026quot;build_date\u0026quot; : \u0026quot;2020-06-14T19:35:50.234439Z\u0026quot;, \u0026quot;build_snapshot\u0026quot; : false, \u0026quot;lucene_version\u0026quot; : \u0026quot;8.5.1\u0026quot;, \u0026quot;minimum_wire_compatibility_version\u0026quot; : \u0026quot;6.8.0\u0026quot;, \u0026quot;minimum_index_compatibility_version\u0026quot; : \u0026quot;6.0.0-beta1\u0026quot; }, \u0026quot;tagline\u0026quot; : \u0026quot;You Know, for Search\u0026quot; } ➜ curl http://127.0.0.1:8000/ -u tesla:password1 Unauthorized% 参数说明 #     名称 类型 说明     host string LDAP 服务器地址   port int LDAP 服务器端口，默认 389   tls bool LDAP 服务器是否为 TLS 安全传输协议，默认 false   bind_dn string 执行 LDAP 查询的用户信息   bind_password string 执行 LDAP 查询的密码信息   base_dn string 过滤 LDAP 用户的根域   user_filter string 过滤 LDAP 用户的查询条件，默认 (uid=%s)   uid_attribute string 用于用户 ID 的属性，默认 uid   group_attribute string 用于用户组的属性，默认 cn   attribute array 指定 LDAP 查询返回的属性列表   max_cache_items int 最大的缓存格式，默认不限制   cache_ttl duration 缓存过期时间格式，默认 300s    "});index.add({'id':104,'href':'/docs/latest/gateway/references/filters/logging/','title':"logging",'section':"在线过滤器",'content':"logging #  描述 #  logging 过滤器用来按请求记录下来，通过异步记录到本地磁盘的方式，尽可能降低对请求的延迟影响，对于流量很大的场景，建议配合其它请求过滤器来降低日志的总量。\n配置示例 #  一个简单的示例如下：\nflow: - name: test filter: - logging: queue_name: request_logging 记录的请求日志样例如下：\n { \u0026quot;_index\u0026quot; : \u0026quot;gateway_requests\u0026quot;, \u0026quot;_type\u0026quot; : \u0026quot;doc\u0026quot;, \u0026quot;_id\u0026quot; : \u0026quot;EH5bG3gBsbC2s3iWFzCF\u0026quot;, \u0026quot;_score\u0026quot; : 1.0, \u0026quot;_source\u0026quot; : { \u0026quot;tls\u0026quot; : false, \u0026quot;@timestamp\u0026quot; : \u0026quot;2021-03-10T08:57:30.645Z\u0026quot;, \u0026quot;conn_time\u0026quot; : \u0026quot;2021-03-10T08:57:30.635Z\u0026quot;, \u0026quot;flow\u0026quot; : { \u0026quot;from\u0026quot; : \u0026quot;127.0.0.1\u0026quot;, \u0026quot;process\u0026quot; : [ \u0026quot;request_body_regex_replace\u0026quot;, \u0026quot;get_cache\u0026quot;, \u0026quot;date_range_precision_tuning\u0026quot;, \u0026quot;get_cache\u0026quot;, \u0026quot;elasticsearch\u0026quot;, \u0026quot;set_cache\u0026quot;, \u0026quot;||\u0026quot;, \u0026quot;request_logging\u0026quot; ], \u0026quot;relay\u0026quot; : \u0026quot;192.168.43.101-Quartz\u0026quot;, \u0026quot;to\u0026quot; : [ \u0026quot;localhost:9200\u0026quot; ] }, \u0026quot;id\u0026quot; : 3, \u0026quot;local_ip\u0026quot; : \u0026quot;127.0.0.1\u0026quot;, \u0026quot;remote_ip\u0026quot; : \u0026quot;127.0.0.1\u0026quot;, \u0026quot;request\u0026quot; : { \u0026quot;body_length\u0026quot; : 53, \u0026quot;body\u0026quot; : \u0026quot;\u0026quot;\u0026quot; { \u0026quot;query\u0026quot;: { \u0026quot;match_all\u0026quot;: {} },\u0026quot;size\u0026quot;: 100 } \u0026quot;\u0026quot;\u0026quot;, \u0026quot;header\u0026quot; : { \u0026quot;content-type\u0026quot; : \u0026quot;application/json\u0026quot;, \u0026quot;User-Agent\u0026quot; : \u0026quot;curl/7.54.0\u0026quot;, \u0026quot;Accept\u0026quot; : \u0026quot;*/*\u0026quot;, \u0026quot;Host\u0026quot; : \u0026quot;localhost:8000\u0026quot;, \u0026quot;content-length\u0026quot; : \u0026quot;53\u0026quot; }, \u0026quot;host\u0026quot; : \u0026quot;localhost:8000\u0026quot;, \u0026quot;local_addr\u0026quot; : \u0026quot;127.0.0.1:8000\u0026quot;, \u0026quot;method\u0026quot; : \u0026quot;POST\u0026quot;, \u0026quot;path\u0026quot; : \u0026quot;/myindex/_search\u0026quot;, \u0026quot;remote_addr\u0026quot; : \u0026quot;127.0.0.1:63309\u0026quot;, \u0026quot;started\u0026quot; : \u0026quot;2021-03-10T08:57:30.635Z\u0026quot;, \u0026quot;uri\u0026quot; : \u0026quot;http://localhost:8000/myindex/_search\u0026quot; }, \u0026quot;response\u0026quot; : { \u0026quot;body_length\u0026quot; : 441, \u0026quot;cached\u0026quot; : false, \u0026quot;elapsed\u0026quot; : 9.878, \u0026quot;status_code\u0026quot; : 200, \u0026quot;body\u0026quot; : \u0026quot;\u0026quot;\u0026quot;{\u0026quot;took\u0026quot;:0,\u0026quot;timed_out\u0026quot;:false,\u0026quot;_shards\u0026quot;:{\u0026quot;total\u0026quot;:1,\u0026quot;successful\u0026quot;:1,\u0026quot;skipped\u0026quot;:0,\u0026quot;failed\u0026quot;:0},\u0026quot;hits\u0026quot;:{\u0026quot;total\u0026quot;:1,\u0026quot;max_score\u0026quot;:1.0,\u0026quot;hits\u0026quot;:[{\u0026quot;_index\u0026quot;:\u0026quot;myindex\u0026quot;,\u0026quot;_type\u0026quot;:\u0026quot;doc\u0026quot;,\u0026quot;_id\u0026quot;:\u0026quot;c132mhq3r0otidqkac1g\u0026quot;,\u0026quot;_score\u0026quot;:1.0,\u0026quot;_source\u0026quot;:{\u0026quot;name\u0026quot;:\u0026quot;local\u0026quot;,\u0026quot;enabled\u0026quot;:true,\u0026quot;endpoint\u0026quot;:\u0026quot;http://localhost:9200\u0026quot;,\u0026quot;basic_auth\u0026quot;:{},\u0026quot;discovery\u0026quot;:{\u0026quot;refresh\u0026quot;:{}},\u0026quot;created\u0026quot;:\u0026quot;2021-03-08T21:48:55.687557+08:00\u0026quot;,\u0026quot;updated\u0026quot;:\u0026quot;2021-03-08T21:48:55.687557+08:00\u0026quot;}}]}}\u0026quot;\u0026quot;\u0026quot;, \u0026quot;header\u0026quot; : { \u0026quot;UPSTREAM\u0026quot; : \u0026quot;localhost:9200\u0026quot;, \u0026quot;process\u0026quot; : \u0026quot;request_body_regex_replace-\u0026gt;get_cache-\u0026gt;date_range_precision_tuning-\u0026gt;get_cache-\u0026gt;elasticsearch-\u0026gt;set_cache\u0026quot;, \u0026quot;content-length\u0026quot; : \u0026quot;441\u0026quot;, \u0026quot;content-type\u0026quot; : \u0026quot;application/json; charset=UTF-8\u0026quot;, \u0026quot;Server\u0026quot; : \u0026quot;INFINI\u0026quot;, \u0026quot;CLUSTER\u0026quot; : \u0026quot;dev\u0026quot; }, \u0026quot;local_addr\u0026quot; : \u0026quot;127.0.0.1:63310\u0026quot; } } } 参数说明 #     名称 类型 说明     queue_name string 将请求日志保存的本地磁盘的队列名称   format_header_keys bool 是否将 Header 标准化，都转成小写，默认 false   remove_authorization bool 是否将 Authorization 信息从 Header 里面移除，默认 true   max_request_body_size int 是否将过长的请求消息进行截断，默认 1024 ，即保留 1024 个字符   max_response_body_size int 是否将过长的返回消息进行截断，默认 1024 ，即保留 1024 个字符   min_elapsed_time_in_ms int 按照请求的响应时间进行过滤，最低超过多少 ms 的请求才会被记录下来   bulk_stats_details bool 是否记录 bulk 请求详细的按照索引的统计信息，默认 true    "});index.add({'id':105,'href':'/docs/latest/gateway/references/filters/queue/','title':"queue",'section':"在线过滤器",'content':"queue #  描述 #  queue 过滤器用来保存请求到消息队列。\n配置示例 #  一个简单的示例如下：\nflow: - name: queue filter: - queue: queue_name: queue_name 参数说明 #     名称 类型 说明     depth_threshold int 大于队列指定深度才能存入队列，默认为 0   queue_name string 消息队列名称    "});index.add({'id':106,'href':'/docs/latest/gateway/references/processors/queue_consumer/','title':"queue_consumer",'section':"离线处理器",'content':"queue_consumer #  描述 #  queue_consumer 处理器用来异步消费队列里面的请求到 Elasticsearch。\n配置示例 #  一个简单的示例如下：\npipeline: - name: bulk_request_ingest auto_start: true keep_running: true processor: - queue_consumer: input_queue: \u0026quot;backup\u0026quot; elasticsearch: \u0026quot;backup\u0026quot; waiting_after: [ \u0026quot;backup_failure_requests\u0026quot;] worker_size: 20 when: cluster_available: [ \u0026quot;backup\u0026quot; ] 参数说明 #     名称 类型 说明     input_queue int 订阅的队列名称   worker_size int 并行执行消费任务的线程数，默认 1   idle_timeout_in_seconds int 消费队列的超时时间，默认 1   elasticsearch string 保存到目标集群的名称   waiting_after array 需要先等将这些指定队列消费完才能开始消费主队列里面的数据   failure_queue string 因为后端故障执行失败的请求，默认为 %input_queue%-failure   invalid_queue string 状态码返回为 4xx 的请求，默认为 %input_queue%-invalid   compress bool 是否压缩请求，默认 false   safety_parse bool 是否启用安全解析，即不采用 buffer 的方式，占用内存更高一点，默认为 true   doc_buffer_size bool 单次请求处理的最大文档 buff size，建议设置超过单个文档的最大大小，默认 256*1024    "});index.add({'id':107,'href':'/docs/latest/gateway/references/filters/ratio/','title':"ratio",'section':"在线过滤器",'content':"ratio #  描述 #  ratio 过滤器用来将正常的流量按照比例迁移转发到另外的一个处理流程，可以实现灰度发布、流量迁移导出，或者将部分流量切换到不同版本集群用于测试的能力。\n配置示例 #  一个简单的示例如下：\nflow: - name: ratio_traffic_forward filter: - ratio: ratio: 0.1 flow: hello_world continue: true 参数说明 #     名称 类型 说明     ratio float 需要迁移的流量比例   flow string 指定新的流量处理流程   continue bool 流量迁移出去之后，是否还继续执行之前的既定流程，设置成 false 则立即返回，默认 false。    "});index.add({'id':108,'href':'/docs/latest/gateway/references/filters/record/','title':"record",'section':"在线过滤器",'content':"record #  描述 #  record 过滤器是一个记录请求的过滤器，输出的请求可以直接复制到 Kibana 的 Console 中用于调试。\n配置示例 #  一个简单的示例如下：\nflow: - name: request_logging filter: - record: stdout: true filename: requests.txt record 过滤器输出的请求日志，格式示例如下：\nGET /_cluster/state/version,master_node,routing_table,metadata/* GET /_alias GET /_cluster/health GET /_cluster/stats GET /_nodes/0NSvaoOGRs2VIeLv3lLpmA/stats 参数说明 #     名称 类型 说明     filename string 录制请求日志在 data 目录下保存的文件名   stdout bool 是否在终端也打印输出，默认为 false    "});index.add({'id':109,'href':'/docs/latest/gateway/references/filters/redirect/','title':"redirect",'section':"在线过滤器",'content':"redirect #  描述 #  redirect 过滤器用来跳转到一个指定的 URL。\n配置示例 #  一个简单的示例如下：\nflow: - name: redirect filter: - redirect: uri: https://infinilabs.com 参数说明 #     名称 类型 说明     uri string 需要跳转的完整目标 URI 地址   code int 状态码设置，默认 302    "});index.add({'id':110,'href':'/docs/latest/gateway/references/filters/redis_pubsub/','title':"redis_pubsub",'section':"在线过滤器",'content':"redis_pubsub #  描述 #  reids 过滤器用来将收到的请求和响应结果保存到 Redis 消息队列中。\n配置示例 #  一个简单的示例如下：\nflow: - name: redis_pubsub filter: - redis_pubsub: host: 127.0.0.1 port: 6379 channel: gateway response: true 参数说明 #     名称 类型 说明     host string Reids 主机名，默认 localhost   port int Reids 端口号，默认为 6379   password string Redis 密码   db int Redis 默认选择的数据库，默认为 0   channel string Redis 消息队列名称，必填，没有默认值   response bool 是否包含响应结果，默认为 true    "});index.add({'id':111,'href':'/docs/latest/gateway/references/processors/replay/','title':"replay",'section':"离线处理器",'content':"replay #  描述 #  replay 处理器用来重放 record 过滤器记录的请求。\n配置示例 #  一个简单的示例如下：\npipeline: - name: play_requests auto_start: true keep_running: false processor: - replay: filename: requests.txt schema: \u0026quot;http\u0026quot; host: \u0026quot;localhost:8000\u0026quot; 参数说明 #     名称 类型 说明     filename string 包含重放消息的文件名称   schema string 请求协议类型，http 或 https   host string 接受请求的目标服务器，格式 host:port    "});index.add({'id':112,'href':'/docs/latest/gateway/references/filters/request_api_key_filter/','title':"request_api_key_filter",'section':"在线过滤器",'content':"request_api_key_filter #  描述 #  当 Elasticsearch 是通过 API Key 方式来进行身份认证的时候，request_api_key_filter 过滤器可用来按请求的 API ID 来进行过滤。\n配置示例 #  一个简单的示例如下：\nflow: - name: test filter: - request_api_key_filter: message: \u0026quot;Request filtered!\u0026quot; exclude: - VuaCfGcBCdbkQm-e5aOx 上面的例子表示，来自 VuaCfGcBCdbkQm-e5aOx 的请求会被拒绝，如下。\n➜ ~ curl localhost:8000 -H \u0026quot;Authorization: ApiKey VnVhQ2ZHY0JDZGJrUW0tZTVhT3g6dWkybHAyYXhUTm1zeWFrdzl0dk5udw==\u0026quot; -v * Rebuilt URL to: localhost:8000/ * Trying 127.0.0.1... * TCP_NODELAY set * Connected to localhost (127.0.0.1) port 8000 (#0) \u0026gt; GET / HTTP/1.1 \u0026gt; Host: localhost:8000 \u0026gt; User-Agent: curl/7.54.0 \u0026gt; Accept: */* \u0026gt; Authorization: ApiKey VnVhQ2ZHY0JDZGJrUW0tZTVhT3g6dWkybHAyYXhUTm1zeWFrdzl0dk5udw== \u0026gt; \u0026lt; HTTP/1.1 403 Forbidden \u0026lt; Server: INFINI \u0026lt; Date: Mon, 12 Apr 2021 15:02:37 GMT \u0026lt; content-type: text/plain; charset=utf-8 \u0026lt; content-length: 17 \u0026lt; FILTERED: true \u0026lt; process: request_api_key_filter \u0026lt; * Connection #0 to host localhost left intact {\u0026quot;error\u0026quot;:true,\u0026quot;message\u0026quot;:\u0026quot;Request filtered!\u0026quot;}% ➜ ~ 参数说明 #     名称 类型 说明     exclude array 拒绝通过的请求的用户名列表   include array 允许通过的请求的用户名列表   action string 符合过滤条件之后的处理动作，可以是 deny 和 redirect_flow，默认为 deny   status int 自定义模式匹配之后返回的状态码   message string 自定义 deny 模式返回的消息文本   flow string 自定义 redirect_flow 模式执行的 flow ID    注意: 当设置了 include 条件的情况下，必须至少满足 include 设置的其中一种响应码才能被允许通过。 当仅设置了 exclude 条件的情况下，不符合 exclude 的任意请求都允许通过。  "});index.add({'id':113,'href':'/docs/latest/gateway/references/filters/request_api_key_limiter/','title':"request_api_key_limiter",'section':"在线过滤器",'content':"request_api_key_limiter #  描述 #  request_api_key_limiter 过滤器用来按照 API Key 来进行限速。\n配置示例 #  配置示例如下：\nflow: - name: rate_limit_flow filter: - request_api_key_limiter: id: - VuaCfGcBCdbkQm-e5aOx max_requests: 1 action: drop # retry or drop message: \u0026quot;your api_key reached our limit\u0026quot; 上面的配置中，对 VuaCfGcBCdbkQm-e5aOx 这个 API ID 进行限速，允许的最大 qps 为 1 每秒。\n➜ ~ curl localhost:8000 -H \u0026quot;Authorization: ApiKey VnVhQ2ZHY0JDZGJrUW0tZTVhT3g6dWkybHAyYXhUTm1zeWFrdzl0dk5udw==\u0026quot; -v * Rebuilt URL to: localhost:8000/ * Trying 127.0.0.1... * TCP_NODELAY set * Connected to localhost (127.0.0.1) port 8000 (#0) \u0026gt; GET / HTTP/1.1 \u0026gt; Host: localhost:8000 \u0026gt; User-Agent: curl/7.54.0 \u0026gt; Accept: */* \u0026gt; Authorization: ApiKey VnVhQ2ZHY0JDZGJrUW0tZTVhT3g6dWkybHAyYXhUTm1zeWFrdzl0dk5udw== \u0026gt; \u0026lt; HTTP/1.1 429 Too Many Requests \u0026lt; Server: INFINI \u0026lt; Date: Mon, 12 Apr 2021 15:14:52 GMT \u0026lt; content-type: text/plain; charset=utf-8 \u0026lt; content-length: 30 \u0026lt; process: request_api_key_limiter \u0026lt; * Connection #0 to host localhost left intact your api_key reached our limit% 参数说明 #     名称 类型 说明     id array 设置哪些 API ID 会参与限速，不设置表示所有 API Key 参与   interval string 评估限速的单位时间间隔，默认为 1s   max_requests int 单位间隔内最大的请求次数限额   max_bytes int 单位间隔内最大的请求流量限额   action string 触发限速之后的处理动作，分为 retry 和 drop 两种，默认为 retry   status string 设置达到限速条件的返回状态码，默认 429   message string 设置达到限速条件的请求的拒绝返回消息   retry_interval int 限速重试的时间间隔，单位毫秒，默认 10，即 10 毫秒   max_retry_times int 限速重试的最大重试次数，默认 1000   failed_retry_message string 设置达到最大重试次数的请求的拒绝返回消息    "});index.add({'id':114,'href':'/docs/latest/gateway/references/filters/request_body_json_del/','title':"request_body_json_del",'section':"在线过滤器",'content':"request_body_json_del #  描述 #  request_body_json_del 过滤器用来删除 JSON 格式的请求体里面的部分字段。\n配置示例 #  一个简单的示例如下：\nflow: - name: test filter: - request_body_json_del: path: - query.bool.should.[0] - query.bool.must 参数说明 #     名称 类型 说明     path array 需要删除的 JSON PATH 键值   ignore_missing bool 如果这个 JSON Path 不存在，是否忽略处理，默认 false    "});index.add({'id':115,'href':'/docs/latest/gateway/references/filters/request_body_json_set/','title':"request_body_json_set",'section':"在线过滤器",'content':"request_body_json_set #  描述 #  request_body_json_set 过滤器用来修改 JSON 格式的请求体。\n配置示例 #  一个简单的示例如下：\nflow: - name: test filter: - request_body_json_set: path: - aggs.total_num.terms.field -\u0026gt; \u0026quot;name\u0026quot; - aggs.total_num.terms.size -\u0026gt; 3 - size -\u0026gt; 0 参数说明 #     名称 类型 说明     path map 使用 -\u0026gt; 作为标识符的键值对， JSON PATH 和需要替换的值   ignore_missing bool 如果这个 JSON Path 不存在，是否忽略处理，默认 false    "});index.add({'id':116,'href':'/docs/latest/gateway/references/filters/request_body_regex_replace/','title':"request_body_regex_replace",'section':"在线过滤器",'content':"request_body_regex_replace #  描述 #  request_body_regex_replace 过滤器使用正则表达式来替换请求体正文的字符串内容。\n配置示例 #  一个简单的示例如下：\nflow: - name: test filter: - request_body_regex_replace: pattern: '\u0026quot;size\u0026quot;: 10000' to: '\u0026quot;size\u0026quot;: 100' - elasticsearch: elasticsearch: prod - dump: request_body: true 上面的示例将会替换发送给 Elasticsearch 请求体里面，size 设置为 10000 的部分修改为 100，可以用来动态修复错误或者不合理的查询。\n测试如下：\ncurl -XPOST \u0026quot;http://localhost:8000/myindex/_search\u0026quot; -H 'Content-Type: application/json' -d' { \u0026quot;query\u0026quot;: { \u0026quot;match_all\u0026quot;: {} },\u0026quot;size\u0026quot;: 10000 }' 实际发生的查询：\n { \u0026quot;_index\u0026quot; : \u0026quot;gateway_requests\u0026quot;, \u0026quot;_type\u0026quot; : \u0026quot;doc\u0026quot;, \u0026quot;_id\u0026quot; : \u0026quot;EH5bG3gBsbC2s3iWFzCF\u0026quot;, \u0026quot;_score\u0026quot; : 1.0, \u0026quot;_source\u0026quot; : { \u0026quot;tls\u0026quot; : false, \u0026quot;@timestamp\u0026quot; : \u0026quot;2021-03-10T08:57:30.645Z\u0026quot;, \u0026quot;conn_time\u0026quot; : \u0026quot;2021-03-10T08:57:30.635Z\u0026quot;, \u0026quot;flow\u0026quot; : { \u0026quot;from\u0026quot; : \u0026quot;127.0.0.1\u0026quot;, \u0026quot;process\u0026quot; : [ \u0026quot;request_body_regex_replace\u0026quot;, \u0026quot;get_cache\u0026quot;, \u0026quot;date_range_precision_tuning\u0026quot;, \u0026quot;get_cache\u0026quot;, \u0026quot;elasticsearch\u0026quot;, \u0026quot;set_cache\u0026quot;, \u0026quot;||\u0026quot;, \u0026quot;request_logging\u0026quot; ], \u0026quot;relay\u0026quot; : \u0026quot;192.168.43.101-Quartz\u0026quot;, \u0026quot;to\u0026quot; : [ \u0026quot;localhost:9200\u0026quot; ] }, \u0026quot;id\u0026quot; : 3, \u0026quot;local_ip\u0026quot; : \u0026quot;127.0.0.1\u0026quot;, \u0026quot;remote_ip\u0026quot; : \u0026quot;127.0.0.1\u0026quot;, \u0026quot;request\u0026quot; : { \u0026quot;body_length\u0026quot; : 53, \u0026quot;body\u0026quot; : \u0026quot;\u0026quot;\u0026quot; { \u0026quot;query\u0026quot;: { \u0026quot;match_all\u0026quot;: {} },\u0026quot;size\u0026quot;: 100 } \u0026quot;\u0026quot;\u0026quot;, \u0026quot;header\u0026quot; : { \u0026quot;content-type\u0026quot; : \u0026quot;application/json\u0026quot;, \u0026quot;User-Agent\u0026quot; : \u0026quot;curl/7.54.0\u0026quot;, \u0026quot;Accept\u0026quot; : \u0026quot;*/*\u0026quot;, \u0026quot;Host\u0026quot; : \u0026quot;localhost:8000\u0026quot;, \u0026quot;content-length\u0026quot; : \u0026quot;53\u0026quot; }, \u0026quot;host\u0026quot; : \u0026quot;localhost:8000\u0026quot;, \u0026quot;local_addr\u0026quot; : \u0026quot;127.0.0.1:8000\u0026quot;, \u0026quot;method\u0026quot; : \u0026quot;POST\u0026quot;, \u0026quot;path\u0026quot; : \u0026quot;/myindex/_search\u0026quot;, \u0026quot;remote_addr\u0026quot; : \u0026quot;127.0.0.1:63309\u0026quot;, \u0026quot;started\u0026quot; : \u0026quot;2021-03-10T08:57:30.635Z\u0026quot;, \u0026quot;uri\u0026quot; : \u0026quot;http://localhost:8000/myindex/_search\u0026quot; }, \u0026quot;response\u0026quot; : { \u0026quot;body_length\u0026quot; : 441, \u0026quot;cached\u0026quot; : false, \u0026quot;elapsed\u0026quot; : 9.878, \u0026quot;status_code\u0026quot; : 200, \u0026quot;body\u0026quot; : \u0026quot;\u0026quot;\u0026quot;{\u0026quot;took\u0026quot;:0,\u0026quot;timed_out\u0026quot;:false,\u0026quot;_shards\u0026quot;:{\u0026quot;total\u0026quot;:1,\u0026quot;successful\u0026quot;:1,\u0026quot;skipped\u0026quot;:0,\u0026quot;failed\u0026quot;:0},\u0026quot;hits\u0026quot;:{\u0026quot;total\u0026quot;:1,\u0026quot;max_score\u0026quot;:1.0,\u0026quot;hits\u0026quot;:[{\u0026quot;_index\u0026quot;:\u0026quot;myindex\u0026quot;,\u0026quot;_type\u0026quot;:\u0026quot;doc\u0026quot;,\u0026quot;_id\u0026quot;:\u0026quot;c132mhq3r0otidqkac1g\u0026quot;,\u0026quot;_score\u0026quot;:1.0,\u0026quot;_source\u0026quot;:{\u0026quot;name\u0026quot;:\u0026quot;local\u0026quot;,\u0026quot;enabled\u0026quot;:true,\u0026quot;endpoint\u0026quot;:\u0026quot;http://localhost:9200\u0026quot;,\u0026quot;basic_auth\u0026quot;:{},\u0026quot;discovery\u0026quot;:{\u0026quot;refresh\u0026quot;:{}},\u0026quot;created\u0026quot;:\u0026quot;2021-03-08T21:48:55.687557+08:00\u0026quot;,\u0026quot;updated\u0026quot;:\u0026quot;2021-03-08T21:48:55.687557+08:00\u0026quot;}}]}}\u0026quot;\u0026quot;\u0026quot;, \u0026quot;header\u0026quot; : { \u0026quot;UPSTREAM\u0026quot; : \u0026quot;localhost:9200\u0026quot;, \u0026quot;process\u0026quot; : \u0026quot;request_body_regex_replace-\u0026gt;get_cache-\u0026gt;date_range_precision_tuning-\u0026gt;get_cache-\u0026gt;elasticsearch-\u0026gt;set_cache\u0026quot;, \u0026quot;content-length\u0026quot; : \u0026quot;441\u0026quot;, \u0026quot;content-type\u0026quot; : \u0026quot;application/json; charset=UTF-8\u0026quot;, \u0026quot;Server\u0026quot; : \u0026quot;INFINI\u0026quot;, \u0026quot;CLUSTER\u0026quot; : \u0026quot;dev\u0026quot; }, \u0026quot;local_addr\u0026quot; : \u0026quot;127.0.0.1:63310\u0026quot; } } } 参数说明 #     名称 类型 说明     pattern string 用于匹配替换的正则表达式   to string 替换为目标的字符串内容    "});index.add({'id':117,'href':'/docs/latest/gateway/references/filters/request_client_ip_filter/','title':"request_client_ip_filter",'section':"在线过滤器",'content':"request_client_ip_filter #  描述 #  request_client_ip_filter 过滤器用来按请求的来源用户 IP 信息来过滤流量。\n配置示例 #  一个简单的示例如下：\nflow: - name: test filter: - request_client_ip_filter: exclude: - 192.168.3.67 上面的例子表示，来自 192.168.3.67 的请求不允许通过。\n路由跳转的例子:\nflow: - name: echo filter: - echo: message: hello stanger - name: default_flow filter: - request_client_ip_filter: action: redirect_flow flow: echo exclude: - 192.168.3.67 来自 192.168.3.67 会跳转到另外的 echo 流程。\n参数说明 #     名称 类型 说明     exclude array 拒绝通过的请求 IP 数组列表   include array 允许通过的请求 IP 数组列表   action string 符合过滤条件之后的处理动作，可以是 deny 和 redirect_flow，默认为 deny   status int 自定义模式匹配之后返回的状态码   message string 自定义 deny 模式返回的消息文本   flow string 自定义 redirect_flow 模式执行的 flow ID    注意: 当设置了 include 条件的情况下，必须至少满足 include 设置的其中一种响应码才能被允许通过。 当仅设置了 exclude 条件的情况下，不符合 exclude 的任意请求都允许通过。  "});index.add({'id':118,'href':'/docs/latest/gateway/references/filters/request_client_ip_limiter/','title':"request_client_ip_limiter",'section':"在线过滤器",'content':"request_client_ip_limiter #  描述 #  request_client_ip_limiter 过滤器用来按照请求客户端 IP 来进行限速。\n配置示例 #  配置示例如下：\nflow: - name: rate_limit_flow filter: - request_client_ip_limiter: ip: #only limit for specify ips - 127.0.0.1 max_requests: 256 # max_bytes: 102400 #100k action: retry # retry or drop # max_retry_times: 1000 # retry_interval: 500 #100ms message: \u0026quot;your ip reached our limit\u0026quot; 上面的配置中，对 127.0.0.1 这个 IP 进行限速，允许的最大 qps 为 256。\n参数说明 #     名称 类型 说明     ip array 设置哪些客户端 IP 会参与限速，不设置表示所有 IP 参与   interval string 评估限速的单位时间间隔，默认为 1s   max_requests int 单位间隔内最大的请求次数限额   max_bytes int 单位间隔内最大的请求流量限额   action string 触发限速之后的处理动作，分为 retry 和 drop 两种，默认为 retry   status string 设置达到限速条件的返回状态码，默认 429   message string 设置达到限速条件的请求的拒绝返回消息   retry_interval int 限速重试的时间间隔，单位毫秒，默认 10，即 10 毫秒   max_retry_times int 限速重试的最大重试次数，默认 1000   failed_retry_message string 设置达到最大重试次数的请求的拒绝返回消息    "});index.add({'id':119,'href':'/docs/latest/gateway/references/filters/request_header_filter/','title':"request_header_filter",'section':"在线过滤器",'content':"request_header_filter #  描述 #  request_header_filter 过滤器用来按请求的 Header 信息来过滤流量。\n配置示例 #  一个简单的示例如下：\nflow: - name: test filter: - request_header_filter: include: - TRACE: true 上面的例子表示，当 Header 里面包含 TRACE: true 的请求才被允许通过。\ncurl 192.168.3.4:8000 -v -H 'TRACE: true' 参数说明 #     名称 类型 说明     exclude array 拒绝通过的请求 Header 信息   include array 允许通过的请求 Header 信息   action string 符合过滤条件之后的处理动作，可以是 deny 和 redirect_flow，默认为 deny   status int 自定义模式匹配之后返回的状态码   message string 自定义 deny 模式返回的消息文本   flow string 自定义 redirect_flow 模式执行的 flow ID    注意: 当设置了 include 条件的情况下，必须至少满足 include 设置的其中一种响应码才能被允许通过。 当仅设置了 exclude 条件的情况下，不符合 exclude 的任意请求都允许通过。  "});index.add({'id':120,'href':'/docs/latest/gateway/references/filters/request_host_filter/','title':"request_host_filter",'section':"在线过滤器",'content':"request_host_filter #  描述 #  request_host_filter 过滤器主要用来按照指定的域名或者主机名来进行请求过滤，适合只有一个 IP 多个域名需要进行域名访问控制的场景。\n配置示例 #  一个简单的示例如下：\nflow: - name: test filter: - request_host_filter: include: - domain-test2.com:8000 上面的例子表示，只有访问的是这个域名 domain-test2.com:8000 的请求才被允许通过。\n示例如下： #  ✗ curl -k -u user:passwd http://domain-test4.com:8000/ -v * Trying 192.168.3.67... * TCP_NODELAY set * Connected to domain-test4.com (192.168.3.67) port 8000 (#0) * Server auth using Basic with user 'medcl' \u0026gt; GET / HTTP/1.1 \u0026gt; Host: domain-test4.com:8000 \u0026gt; Authorization: Basic 123= \u0026gt; User-Agent: curl/7.64.1 \u0026gt; Accept: */* \u0026gt; \u0026lt; HTTP/1.1 403 Forbidden \u0026lt; Server: INFINI \u0026lt; Date: Fri, 15 Jan 2021 13:53:01 GMT \u0026lt; Content-Length: 0 \u0026lt; FILTERED: true \u0026lt; * Connection #0 to host domain-test4.com left intact * Closing connection 0 ✗ curl -k -u user:passwd http://domain-test2.com:8000/ -v * Trying 192.168.3.67... * TCP_NODELAY set * Connected to domain-test2.com (192.168.3.67) port 8000 (#0) * Server auth using Basic with user 'medcl' \u0026gt; GET / HTTP/1.1 \u0026gt; Host: domain-test2.com:8000 \u0026gt; Authorization: Basic 123= \u0026gt; User-Agent: curl/7.64.1 \u0026gt; Accept: */* \u0026gt; \u0026lt; HTTP/1.1 200 OK \u0026lt; Server: INFINI \u0026lt; Date: Fri, 15 Jan 2021 13:52:53 GMT \u0026lt; Content-Type: application/json; charset=UTF-8 \u0026lt; Content-Length: 480 \u0026lt; UPSTREAM: 192.168.3.203:9200 \u0026lt; CACHE-HASH: a2902f950b4ade804b21a062257387ef \u0026lt; { \u0026quot;name\u0026quot; : \u0026quot;node3\u0026quot;, \u0026quot;cluster_name\u0026quot; : \u0026quot;pi\u0026quot;, \u0026quot;cluster_uuid\u0026quot; : \u0026quot;Z_HcN_6ESKWicV-eLsyU4g\u0026quot;, \u0026quot;version\u0026quot; : { \u0026quot;number\u0026quot; : \u0026quot;6.4.2\u0026quot;, \u0026quot;build_flavor\u0026quot; : \u0026quot;default\u0026quot;, \u0026quot;build_type\u0026quot; : \u0026quot;tar\u0026quot;, \u0026quot;build_hash\u0026quot; : \u0026quot;04711c2\u0026quot;, \u0026quot;build_date\u0026quot; : \u0026quot;2018-09-26T13:34:09.098244Z\u0026quot;, \u0026quot;build_snapshot\u0026quot; : false, \u0026quot;lucene_version\u0026quot; : \u0026quot;7.4.0\u0026quot;, \u0026quot;minimum_wire_compatibility_version\u0026quot; : \u0026quot;5.6.0\u0026quot;, \u0026quot;minimum_index_compatibility_version\u0026quot; : \u0026quot;5.0.0\u0026quot; }, \u0026quot;tagline\u0026quot; : \u0026quot;You Know, for Search\u0026quot; } * Connection #0 to host domain-test2.com left intact * Closing connection 0 参数说明 #     名称 类型 说明     exclude array 拒绝通过的请求的主机列表   include array 允许通过的请求的主机列表   action string 符合过滤条件之后的处理动作，可以是 deny 和 redirect_flow，默认为 deny   status int 自定义模式匹配之后返回的状态码   message string 自定义 deny 模式返回的消息文本   flow string 自定义 redirect_flow 模式执行的 flow ID    注意: 当设置了 include 条件的情况下，必须至少满足 include 设置的其中一种响应码才能被允许通过。 当仅设置了 exclude 条件的情况下，不符合 exclude 的任意请求都允许通过。  "});index.add({'id':121,'href':'/docs/latest/gateway/references/filters/request_host_limiter/','title':"request_host_limiter",'section':"在线过滤器",'content':"request_host_limiter #  描述 #  request_host_limiter 过滤器用来按照请求主机（域名）来进行限速。\n配置示例 #  配置示例如下：\nflow: - name: rate_limit_flow filter: - request_host_limiter: host: - api.elasticsearch.cn:8000 - logging.elasticsearch.cn:8000 max_requests: 256 # max_bytes: 102400 #100k action: retry # retry or drop # max_retry_times: 1000 # retry_interval: 500 #100ms message: \u0026quot;you reached our limit\u0026quot; 上面的配置中，对 api.elasticsearch.cn 和 logging.elasticsearch.cn 这两个访问域名进行限速，允许的最大 qps 为 256 每秒。\n参数说明 #     名称 类型 说明     host array 设置哪些主机域名会参与限速，不设置表示都参与，注意，如果访问的域名带端口号，这里也需包含端口号，如 localhost:8080   interval string 评估限速的单位时间间隔，默认为 1s   max_requests int 单位间隔内最大的请求次数限额   max_bytes int 单位间隔内最大的请求流量限额   action string 触发限速之后的处理动作，分为 retry 和 drop 两种，默认为 retry   status string 设置达到限速条件的返回状态码，默认 429   message string 设置达到限速条件的请求的拒绝返回消息   retry_interval int 限速重试的时间间隔，单位毫秒，默认 10，即 10 毫秒   max_retry_times int 限速重试的最大重试次数，默认 1000   failed_retry_message string 设置达到最大重试次数的请求的拒绝返回消息    "});index.add({'id':122,'href':'/docs/latest/gateway/references/filters/request_method_filter/','title':"request_method_filter",'section':"在线过滤器",'content':"request_method_filter #  描述 #  request_method_filter 过滤器用来按请求 Method 来过滤流量。\n配置示例 #  一个简单的示例如下：\nflow: - name: test filter: - request_method_filter: exclude: - PUT - POST include: - GET - HEAD - DELETE 参数说明 #     名称 类型 说明     exclude array 拒绝通过的请求 Method   include array 允许通过的请求 Method   action string 符合过滤条件之后的处理动作，可以是 deny 和 redirect_flow，默认为 deny   status int 自定义模式匹配之后返回的状态码   message string 自定义 deny 模式返回的消息文本   flow string 自定义 redirect_flow 模式执行的 flow ID    注意: 当设置了 include 条件的情况下，必须至少满足 include 设置的其中一种响应码才能被允许通过。 当仅设置了 exclude 条件的情况下，不符合 exclude 的任意请求都允许通过。  "});index.add({'id':123,'href':'/docs/latest/gateway/references/filters/request_path_filter/','title':"request_path_filter",'section':"在线过滤器",'content':"request_path_filter #  描述 #  request_path_filter 过滤器用来按请求的 Path 路径来过滤流量。\n配置示例 #  一个简单的示例如下：\nflow: - name: test filter: - request_path_filter: must: #must match all rules to continue prefix: - /medcl contain: - _search suffix: - _count - _refresh wildcard: - /*/_refresh regex: - ^/m[\\w]+dcl must_not: # any match will be filtered prefix: - /.kibana - /_security - /_security - /gateway_requests* - /.reporting - /_monitoring/bulk contain: - _search suffix: - _count - _refresh wildcard: - /*/_refresh regex: - ^/m[\\w]+dcl should: prefix: - /medcl contain: - _search - _async_search suffix: - _refresh wildcard: - /*/_refresh regex: - ^/m[\\w]+dcl 参数说明 #     名称 类型 说明     must.* object 必须都满足所设置条件的情况下才能允许通过   must_not.* object 必须都不满足所设置条件的情况下才能通过   should.* object 满足任意所设置条件的情况下即可通过   *.prefix array 判断是否由特定字符开头   *.suffix array 判断是否由特定字符结尾   *.contain array 判断是否包含特定字符   *.wildcard array 判断是否符合通配符匹配规则   *.regex array 判断是否符合正则表达式匹配规则   action string 符合过滤条件之后的处理动作，可以是 deny 和 redirect_flow，默认为 deny   status int 自定义模式匹配之后返回的状态码   message string 自定义 deny 模式返回的消息文本   flow string 自定义 redirect_flow 模式执行的 flow ID    Note: 当仅设置了 should 条件的情况下，必须至少满足 should 设置的其中一种才能被允许通过。\n"});index.add({'id':124,'href':'/docs/latest/gateway/references/filters/request_path_limiter/','title':"request_path_limiter",'section':"在线过滤器",'content':"request_path_limiter #  描述 #  request_path_limiter 过滤器用来定义请求的限速规则，可以实现索引级别的限速。\n配置示例 #  配置示例如下：\nflow: - name: rate_limit_flow filter: - request_path_limiter: message: \u0026quot;Hey, You just reached our request limit!\u0026quot; rules: - pattern: \u0026quot;/(?P\u0026lt;index_name\u0026gt;medcl)/_search\u0026quot; max_qps: 3 group: index_name - pattern: \u0026quot;/(?P\u0026lt;index_name\u0026gt;.*?)/_search\u0026quot; max_qps: 100 group: index_name 上面的配置中，对 medcl 这个索引执行查询，允许的最大 qps 为 3，而对其它的索引执行查询的 qps 为 100。\n参数说明 #     名称 类型 说明     message string 设置达到限速条件的请求的返回消息   rules array 设置限速的策略，支持多种规则，按照配置的先后顺序处理，先匹配的先执行   rules.pattern string 使用正则表达式来对 URL 的 Path 进行规则匹配，必须提供一个 group 名称，用于作为限速的 bucket key   rules.group string 正则表达式里面定义的 group 名称，将用于请求次数的统计，相同的 group 值视为一类请求   rules.max_qps int 定义每组请求的最大的 qps 参数，超过该值将触发限速行为    "});index.add({'id':125,'href':'/docs/latest/gateway/references/filters/request_user_filter/','title':"request_user_filter",'section':"在线过滤器",'content':"request_user_filter #  描述 #  当 Elasticsearch 是通过 Basic Auth 方式来进行身份认证的时候，request_user_filter 过滤器可用来按请求的用户名信息来进行过滤。\n配置示例 #  一个简单的示例如下：\nflow: - name: test filter: - request_user_filter: include: - \u0026quot;elastic\u0026quot; 上面的例子表示，只有来自 elastic 的请求才被允许通过。\n参数说明 #     名称 类型 说明     exclude array 拒绝通过的请求的用户名列表   include array 允许通过的请求的用户名列表   action string 符合过滤条件之后的处理动作，可以是 deny 和 redirect_flow，默认为 deny   status int 自定义模式匹配之后返回的状态码   message string 自定义 deny 模式返回的消息文本   flow string 自定义 redirect_flow 模式执行的 flow ID    注意: 当设置了 include 条件的情况下，必须至少满足 include 设置的其中一种响应码才能被允许通过。 当仅设置了 exclude 条件的情况下，不符合 exclude 的任意请求都允许通过。  "});index.add({'id':126,'href':'/docs/latest/gateway/references/filters/request_user_limiter/','title':"request_user_limiter",'section':"在线过滤器",'content':"request_user_limiter #  描述 #  request_user_limiter 过滤器用来按照用户名来进行限速。\n配置示例 #  配置示例如下：\nflow: - name: rate_limit_flow filter: - request_user_limiter: user: - elastic - medcl max_requests: 256 # max_bytes: 102400 #100k action: retry # retry or drop # max_retry_times: 1000 # retry_interval: 500 #100ms message: \u0026quot;you reached our limit\u0026quot; 上面的配置中，对 medcl 和 elastic 这两个用户进行限速，允许的最大 qps 为 256 每秒。\n参数说明 #     名称 类型 说明     user array 设置哪些用户会参与限速，不设置表示所有用户参与   interval string 评估限速的单位时间间隔，默认为 1s   max_requests int 单位间隔内最大的请求次数限额   max_bytes int 单位间隔内最大的请求流量限额   action string 触发限速之后的处理动作，分为 retry 和 drop 两种，默认为 retry   message string 设置达到限速条件的请求的拒绝返回消息   retry_interval int 限速重试的时间间隔，单位毫秒，默认 10，即 10 毫秒   max_retry_times int 限速重试的最大重试次数，默认 1000    "});index.add({'id':127,'href':'/docs/latest/gateway/references/filters/response_body_regex_replace/','title':"response_body_regex_replace",'section':"在线过滤器",'content':"response_body_regex_replace #  描述 #  response_body_regex_replace 过滤器使用正则表达式来替换请求响应内容的字符串。\n配置示例 #  一个简单的示例如下：\nflow: - name: test filter: - echo: message: \u0026quot;hello infini\\n\u0026quot; - response_body_regex_replace: pattern: infini to: world 上面的结果输出为 hello world。\n参数说明 #     名称 类型 说明     pattern string 用于匹配替换的正则表达式   to string 替换为目标的字符串内容    "});index.add({'id':128,'href':'/docs/latest/gateway/references/filters/response_header_filter/','title':"response_header_filter",'section':"在线过滤器",'content':"response_header_filter #  描述 #  response_header_filter 过滤器用来按请求响应的 Header 信息来过滤流量。\n配置示例 #  一个简单的示例如下：\nflow: - name: test filter: ... - response_header_filter: exclude: - INFINI-CACHE: CACHED 上面的例子表示，当 Header 信息里面出现 INFINI-CACHE: CACHED 的请求不允许通过。\n参数说明 #     名称 类型 说明     exclude array 拒绝通过的响应 Header 信息   include array 允许通过的响应 Header 信息   action string 符合过滤条件之后的处理动作，可以是 deny 和 redirect_flow，默认为 deny   status int 自定义模式匹配之后返回的状态码   message string 自定义 deny 模式返回的消息文本   flow string 自定义 redirect_flow 模式执行的 flow ID    注意: 当设置了 include 条件的情况下，必须至少满足 include 设置的其中一种响应码才能被允许通过。 当仅设置了 exclude 条件的情况下，不符合 exclude 的任意请求都允许通过。  "});index.add({'id':129,'href':'/docs/latest/gateway/references/filters/response_header_format/','title':"response_header_format",'section':"在线过滤器",'content':"response_header_format #  描述 #  response_header_format 过滤器用来将请求响应的 Header 信息里面的 Key 都转换成小写。\n配置示例 #  一个简单的示例如下：\nflow: - name: test filter: - response_header_format: "});index.add({'id':130,'href':'/docs/latest/gateway/references/filters/response_status_filter/','title':"response_status_filter",'section':"在线过滤器",'content':"response_status_filter #  描述 #  response_status_filter 过滤器用来按后端服务响应的状态码来进行过滤。\n配置示例 #  一个简单的示例如下：\nflow: - name: test filter: - response_status_filter: message: \u0026quot;Request filtered!\u0026quot; exclude: - 404 include: - 200 - 201 - 500 参数说明 #     名称 类型 说明     exclude array 拒绝通过的响应码   include array 允许通过的响应码   action string 符合过滤条件之后的处理动作，可以是 deny 和 redirect_flow，默认为 deny   status int 自定义模式匹配之后返回的状态码   message string 自定义 deny 模式返回的消息文本   flow string 自定义 redirect_flow 模式执行的 flow ID    注意: 当设置了 include 条件的情况下，必须至少满足 include 设置的其中一种响应码才能被允许通过。 当仅设置了 exclude 条件的情况下，不符合 exclude 的任意请求都允许通过。  "});index.add({'id':131,'href':'/docs/latest/gateway/references/filters/retry_limiter/','title':"retry_limiter",'section':"在线过滤器",'content':"retry_limiter #  描述 #  retry_limiter 过滤器用来判断一个请求是否达到最大重试次数，避免一个请求的无限重试。\n配置示例 #  一个简单的示例如下：\nflow: - name: retry_limiter filter: - retry_limiter: queue_name: \u0026quot;deadlock_messages\u0026quot; max_retry_times: 3 参数说明 #     名称 类型 说明     max_retry_times int 最大重试次数，默认为 3   queue_name string 达到重试最大次数后，输出消息到指定消息队列的名称   tag_on_success array 触发重试条件之后，请求上下文打上指定标记    "});index.add({'id':132,'href':'/docs/latest/gateway/references/filters/sample/','title':"sample",'section':"在线过滤器",'content':"sample #  描述 #  sample 过滤器用来将正常的流量按照比例采样，对于海量查询的场景，全流量收集日志需要耗费大量的资源，可以考虑进行抽样统计，对查询日志进行采样分析。\n配置示例 #  一个简单的示例如下：\nflow: - name: sample filter: - sample: ratio: 0.2 参数说明 #     名称 类型 说明     ratio float 采样比例    "});index.add({'id':133,'href':'/docs/latest/gateway/references/filters/set_basic_auth/','title':"set_basic_auth",'section':"在线过滤器",'content':"set_basic_auth #  描述 #  set_basic_auth 过滤器用来设置请求的身份认证信息，可以用于重置请求的身份信息。\n配置示例 #  一个简单的示例如下：\nflow: - name: set_basic_auth filter: - set_basic_auth: username: admin password: password 参数说明 #     名称 类型 说明     username string 用户名   password string 密码    "});index.add({'id':134,'href':'/docs/latest/gateway/references/filters/set_context/','title':"set_context",'section':"在线过滤器",'content':"set_context #  描述 #  set_context 过滤器用来设置请求上下文的相关信息。\n配置示例 #  一个简单的示例如下：\nflow: - name: test filter: - set_response: body: '{\u0026quot;message\u0026quot;:\u0026quot;hello world\u0026quot;}' - set_context: context: # _ctx.request.uri: http://baidu.com # _ctx.request.path: new_request_path # _ctx.request.host: api.infinilabs.com # _ctx.request.method: DELETE # _ctx.request.body: \u0026quot;hello world\u0026quot; # _ctx.request.body_json.explain: true # _ctx.request.query_args.from: 100 # _ctx.request.header.ENV: dev # _ctx.response.content_type: \u0026quot;application/json\u0026quot; # _ctx.response.header.TIMES: 100 # _ctx.response.status: 419 # _ctx.response.body: \u0026quot;new_body\u0026quot; _ctx.response.body_json.success: true - dump: request: true 参数说明 #     名称 类型 说明     context map 请求的上下文及对应的新值    支持的上下文变量列表如下：\n   名称 类型 说明     _ctx.request.uri string 完整请求的 URL 地址   _ctx.request.path string 请求的路径   _ctx.request.host string 请求的主机   _ctx.request.method string 请求 Method 类型   _ctx.request.body string 请求体   _ctx.request.body_json.[JSON_PATH] string JSON 请求对象的 Path   _ctx.request.query_args.[KEY] string URL 查询请求参数   _ctx.request.header.[KEY] string 请求头信息   _ctx.response.content_type string 请求体类型   _ctx.response.header.[KEY] string 返回头信息   _ctx.response.status int 返回状态码   _ctx.response.body string 返回响应体   _ctx.response.body_json.[JSON_PATH] string JSON 返回对象的 Path    "});index.add({'id':135,'href':'/docs/latest/gateway/references/filters/set_hostname/','title':"set_hostname",'section':"在线过滤器",'content':"set_hostname #  描述 #  set_hostname 过滤器用来设置请求 Header 关于要访问的主机或域名信息。\n配置示例 #  一个简单的示例如下：\nflow: - name: set_hostname filter: - set_hostname: hostname: api.infini.sh 为避免\n参数说明 #     名称 类型 说明     hostname string 主机信息    "});index.add({'id':136,'href':'/docs/latest/gateway/references/filters/set_request_header/','title':"set_request_header",'section':"在线过滤器",'content':"set_request_header #  描述 #  set_request_header 过滤器用来设置请求的 Header 头信息。\n配置示例 #  一个简单的示例如下：\nflow: - name: set_request_header filter: - set_request_header: headers: - Trial -\u0026gt; true - Department -\u0026gt; Engineering 为避免\n参数说明 #     名称 类型 说明     headers map 使用 -\u0026gt; 作为标识符的键值对，用于设置 Header 信息    "});index.add({'id':137,'href':'/docs/latest/gateway/references/filters/set_request_query_args/','title':"set_request_query_args",'section':"在线过滤器",'content':"set_request_query_args #  描述 #  set_request_query_args 过滤器用来设置请求的 QueryString 参数信息。\n配置示例 #  一个简单的示例如下：\nflow: - name: set_request_query_args filter: - set_request_query_args: args: - size -\u0026gt; 10 为避免\n参数说明 #     名称 类型 说明     args map 使用 -\u0026gt; 作为标识符的键值对，用于设置 QueryString 参数信息    "});index.add({'id':138,'href':'/docs/latest/gateway/references/filters/set_response/','title':"set_response",'section':"在线过滤器",'content':"set_response #  描述 #  set_response 过滤器用来设置请求响应返回信息。\n配置示例 #  一个简单的示例如下：\nflow: - name: set_response filter: - set_response: status: 200 content_type: application/json body: '{\u0026quot;message\u0026quot;:\u0026quot;hello world\u0026quot;}' 参数说明 #     名称 类型 说明     status int 请求状态码，默认 200   content_type string 设置请求返回的内容类型   body string 设置请求返回的结构体    "});index.add({'id':139,'href':'/docs/latest/gateway/references/filters/set_response_header/','title':"set_response_header",'section':"在线过滤器",'content':"set_response_header #  描述 #  set_response_header 过滤器用来设置请求响应的 Header 头信息。\n配置示例 #  一个简单的示例如下：\nflow: - name: set_response_header filter: - set_response_header: headers: - Trial -\u0026gt; true - Department -\u0026gt; Engineering 参数说明 #     名称 类型 说明     headers map 使用 -\u0026gt; 作为标识符的键值对，用于设置 Header 信息    "});index.add({'id':140,'href':'/docs/latest/gateway/references/filters/sleep/','title':"sleep",'section':"在线过滤器",'content':"sleep #  描述 #  sleep 过滤器用来添加一个固定的延迟到请求，可以人为降速。\n配置示例 #  一个简单的示例如下：\nflow: - name: slow_query_logging_test filter: - sleep: sleep_in_million_seconds: 1024 参数说明 #     名称 类型 说明     sleep_in_million_seconds int64 需要添加的延迟长度，单位为毫秒    "});index.add({'id':141,'href':'/docs/latest/gateway/references/filters/switch/','title':"switch",'section':"在线过滤器",'content':"switch #  描述 #  switch 过滤器用来将流量按照请求路径转发到另外的一个处理流程，可以方便的实现跨集群操作，且 Elasticsearch 集群不需要做任何修改，且各个集群内所有的 API 都可以访问，包括索引的读写和集群操作。\n配置示例 #  一个简单的示例如下：\nflow: - name: es1-flow filter: - elasticsearch: elasticsearch: es1 - name: es2-flow filter: - elasticsearch: elasticsearch: es2 - name: cross_cluste_search filter: - switch: path_rules: - prefix: \u0026quot;es1:\u0026quot; flow: es1-flow - prefix: \u0026quot;es2:\u0026quot; flow: es2-flow - elasticsearch: elasticsearch: dev #elasticsearch configure reference name 上面的例子中，以 es1: 开头的索引将转发给集群 es1 集群，以 es2: 开头的索引转发给 es2 集群，不匹配的转发给 dev 集群，在一个 Kibana 里面可以直接操作不同版本的集群了，如下：\n# GET es1:_cluster/health { \u0026quot;cluster_name\u0026quot; : \u0026quot;elasticsearch\u0026quot;, \u0026quot;status\u0026quot; : \u0026quot;yellow\u0026quot;, \u0026quot;timed_out\u0026quot; : false, \u0026quot;number_of_nodes\u0026quot; : 1, \u0026quot;number_of_data_nodes\u0026quot; : 1, \u0026quot;active_primary_shards\u0026quot; : 37, \u0026quot;active_shards\u0026quot; : 37, \u0026quot;relocating_shards\u0026quot; : 0, \u0026quot;initializing_shards\u0026quot; : 0, \u0026quot;unassigned_shards\u0026quot; : 9, \u0026quot;delayed_unassigned_shards\u0026quot; : 0, \u0026quot;number_of_pending_tasks\u0026quot; : 0, \u0026quot;number_of_in_flight_fetch\u0026quot; : 0, \u0026quot;task_max_waiting_in_queue_millis\u0026quot; : 0, \u0026quot;active_shards_percent_as_number\u0026quot; : 80.43478260869566 } # GET es2:_cluster/health { \u0026quot;cluster_name\u0026quot; : \u0026quot;elasticsearch\u0026quot;, \u0026quot;status\u0026quot; : \u0026quot;yellow\u0026quot;, \u0026quot;timed_out\u0026quot; : false, \u0026quot;number_of_nodes\u0026quot; : 1, \u0026quot;number_of_data_nodes\u0026quot; : 1, \u0026quot;active_primary_shards\u0026quot; : 6, \u0026quot;active_shards\u0026quot; : 6, \u0026quot;relocating_shards\u0026quot; : 0, \u0026quot;initializing_shards\u0026quot; : 0, \u0026quot;unassigned_shards\u0026quot; : 6, \u0026quot;delayed_unassigned_shards\u0026quot; : 0, \u0026quot;number_of_pending_tasks\u0026quot; : 0, \u0026quot;number_of_in_flight_fetch\u0026quot; : 0, \u0026quot;task_max_waiting_in_queue_millis\u0026quot; : 0, \u0026quot;active_shards_percent_as_number\u0026quot; : 50.0 } 通过命令行也同样可以：\nroot@infini:/opt/gateway# curl -v 192.168.3.4:8000/es1:_cat/nodes * Trying 192.168.3.4... * TCP_NODELAY set * Connected to 192.168.3.4 (192.168.3.4) port 8000 (#0) \u0026gt; GET /es1:_cat/nodes HTTP/1.1 \u0026gt; Host: 192.168.3.4:8000 \u0026gt; User-Agent: curl/7.58.0 \u0026gt; Accept: */* \u0026gt; \u0026lt; HTTP/1.1 200 OK \u0026lt; Server: INFINI \u0026lt; Date: Thu, 14 Oct 2021 10:37:39 GMT \u0026lt; content-type: text/plain; charset=UTF-8 \u0026lt; Content-Length: 45 \u0026lt; X-Backend-Cluster: dev1 \u0026lt; X-Backend-Server: 192.168.3.188:9299 \u0026lt; X-Filters: filters-\u0026gt;switch-\u0026gt;filters-\u0026gt;elasticsearch-\u0026gt;skipped \u0026lt; 192.168.3.188 48 38 5 cdhilmrstw * LENOVO * Connection #0 to host 192.168.3.4 left intact root@infini:/opt/gateway# curl -v 192.168.3.4:8000/es2:_cat/nodes * Trying 192.168.3.4... * TCP_NODELAY set * Connected to 192.168.3.4 (192.168.3.4) port 8000 (#0) \u0026gt; GET /es2:_cat/nodes HTTP/1.1 \u0026gt; Host: 192.168.3.4:8000 \u0026gt; User-Agent: curl/7.58.0 \u0026gt; Accept: */* \u0026gt; \u0026lt; HTTP/1.1 200 OK \u0026lt; Server: INFINI \u0026lt; Date: Thu, 14 Oct 2021 10:37:48 GMT \u0026lt; content-type: text/plain; charset=UTF-8 \u0026lt; Content-Length: 146 \u0026lt; X-elastic-product: Elasticsearch \u0026lt; Warning: 299 Elasticsearch-7.14.0-dd5a0a2acaa2045ff9624f3729fc8a6f40835aa1 \u0026quot;Elasticsearch built-in security features are not enabled. Without authentication, your cluster could be accessible to anyone. See https://www.elastic.co/guide/en/elasticsearch/reference/7.14/security-minimal-setup.html to enable security.\u0026quot; \u0026lt; X-Backend-Cluster: dev \u0026lt; X-Backend-Server: 192.168.3.188:9216 \u0026lt; X-Filters: filters-\u0026gt;switch-\u0026gt;filters-\u0026gt;elasticsearch-\u0026gt;skipped \u0026lt; 192.168.3.188 26 38 3 cdfhilmrstw - node-714-1 192.168.3.188 45 38 3 cdfhilmrstw * LENOVO 192.168.3.188 43 38 4 cdfhilmrstw - node-714-2 * Connection #0 to host 192.168.3.4 left intact 参数说明 #     名称 类型 说明     path_rules array 根据 URL 路径的匹配规则   path_rules.prefix string 匹配的不包含 /开头的前缀字符串，，建议以 : 结尾，匹配之后会移除该 URL 前缀转发给后面的 flow。   path_rules.flow string 匹配之后用于处理该请求的 flow 名称。   remove_prefix bool 转发请求之前，是否移除前缀匹配上的字符串，默认 true    "});index.add({'id':142,'href':'/docs/latest/gateway/references/filters/translog/','title':"translog",'section':"在线过滤器",'content':"translog #  描述 #  translog 过滤器用来将收到的请求保存到本地文件，并压缩存放，可记录部分或完整的请求日志，用于归档和请求重放。\n配置示例 #  一个简单的示例如下：\nflow: - name: translog filter: - translog: max_file_age: 7 max_file_count: 10 参数说明 #     名称 类型 说明     path string 日志存放根目录，默认为网关数据目录下的 translog 子目录   category string 区分不同日志的二级分类子目录，默认为 default   filename string 设置日志的文件名，默认为 translog.log   compress bool 文件滚动之后是否压缩归档，默认为 true   max_file_age int 最多保留的归档文件天数，默认为 30 天   max_file_count int 最多保留的归档文件个数，默认为 100 天   max_file_size_in_mb int 单个归档文件的最大字节数，默认为 1024 MB    "});})();